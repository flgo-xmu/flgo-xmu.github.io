{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#flgo","title":"FLGo","text":"<p>A research-oriented federated learning platform for fast developing and benchmarking FL algorithms.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Algorithm Development Friendly - highly integration, flexible APIs, and few codes. </li> <li>Comprehensive Benchmarks - 20+ built-in benchmarks across CV, NLP, Graph, and Tabular datasets. API for customizing personal datasets into federated ones.</li> <li>Real-world Simulation - arbitrarily customized simulation for scenarios like mobile, IoT, ...</li> <li>Experiment Tools - easy to manage experimental records and conduct analysis.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code># 1. update pip\npip install --upgrade pip\n\n# 2. install flgo through pip\npip install flgo\n</code></pre>"},{"location":"about/","title":"Contact us","text":"<p>Spatial Sensing and Computing Lab, Xiamen University</p> <p>zwang@stu.xmu.edu.cn</p> <p>fanxiaoliang@xmu.edu.cn</p>"},{"location":"getting_started/","title":"Get Started","text":""},{"location":"getting_started/#install-flgo","title":"Install FLGo","text":"<p>Install FLGo through pip. </p> <pre><code>pip install flgo\n</code></pre> <p>If the package is not found, please use the command below to update pip</p> <pre><code>pip install --upgrade pip\n</code></pre>"},{"location":"getting_started/#create-your-first-federated-task","title":"Create Your First Federated Task","text":"<p>Here we take the classical federated benchmark, Federated MNIST [1], as the example, where the MNIST dataset is splitted into 100 parts identically and independently.</p> <pre><code>import flgo\nimport os\n\n# the target path of the task\ntask_path = './my_first_task'\n\n# create task configuration\ntask_config = {'benchmark':{'name': 'flgo.benchmark.mnist_classification'}, 'partitioner':{'name':'IIDPartitioner', 'para':{'num_clients':100}}}\n\n# generate the task if the task doesn't exist\nif not os.path.exist(task_path):\n    flgo.gen_task(task_config, task_path)\n</code></pre> <p>After running the codes above, a federated dataset is successfully created in the <code>task_path</code>. The visualization of the task is stored in <code>task_path/res.png</code> as below </p>"},{"location":"getting_started/#run-fedavg-to-train-your-model","title":"Run FedAvg to Train Your Model","text":"<p>Now we are going to run the classical federated optimization algorithm, FedAvg [1], on the task created by us to train a model.</p> <pre><code>import flgo.algorithm.fedavg as fedavg\n# create fedavg runner on the task\nrunner = flgo.init(task, fedavg, {'gpu':[0,],'log_file':True, 'num_steps':5})\nrunner.run()\n</code></pre>"},{"location":"getting_started/#show-training-result","title":"Show Training Result","text":"<p>The training result is saved as a record under the dictionary of the task <code>task_path/record</code>. We use the built-in analyzer to read and show it.</p> <pre><code>import flgo.experiment.analyzer\n# create the analysis plan\nanalysis_plan = {\n    'Selector':{'task': task_path, 'header':['fedavg',], },\n    'Painter':{'Curve':[{'args':{'x':'communication_round', 'y':'val_loss'}}]},\n    'Table':{'min_value':[{'x':'val_loss'}]},\n}\n\nflgo.experiment.analyzer.show(analysis_plan)\n</code></pre> <p></p>"},{"location":"Docs/FLGo/","title":"FLGo","text":""},{"location":"Docs/FLGo/#flgo.VirtualCommunicator","title":"<code>VirtualCommunicator</code>","text":"<p>Communicator that simulates the communication phase between any two objects</p> Source code in <code>flgo\\__init__.py</code> <pre><code>class VirtualCommunicator:\n\"\"\"\n    Communicator that simulates the communication phase between any two objects\n    \"\"\"\n    def __init__(self, objects):\n        self.objects_map = {obj.id:obj for obj in objects}\n        self.objects = objects\n\n    def request(self, source, target, package):\n        # send package to the target object with `package` and `mtype`, and then listen from it\n        return self.objects_map[target].message_handler(package)\n</code></pre>"},{"location":"Docs/documents/","title":"Documents","text":""},{"location":"Docs/documents/#flgo.algorithm","title":"<code>flgo.algorithm</code>","text":""},{"location":"Docs/documents/#flgo.benchmark","title":"<code>flgo.benchmark</code>","text":"<p>This module is designed for fast creating federated tasks. For example, in FL, a commonly used benchmark is federated MNIST that splits MNIST into 100 shards and each shard contains data of two types of labels.</p> <p>In FLGo, three basic components are created to describe a general procedure that can easily convert various ML tasks into federated ones.</p> Components <ul> <li> <p><code>TaskGenerator</code></p> <ul> <li>load the original dataset</li> <li>partition the original dataset into local_movielens_recommendation data</li> </ul> </li> <li> <p><code>TaskPipe</code></p> <ul> <li>store the partition information of TaskGenerator into the disk     when generating federated tasks</li> <li>load the original dataset and the partition information to     create the federated scenario when optimizing models</li> </ul> </li> <li> <p><code>TaskCalculator</code></p> <ul> <li>support task-specific computation when optimizing models, such     as putting data into device, computing loss, evaluating models,     and creating the data loader</li> </ul> </li> </ul> <p>The architecture of a complete federate benchmark is shown as follows:</p> <pre><code>benchmark_name                  # benchmark folder\n\u251c\u2500 core.py                      # core file\n\u2502   \u251c\u2500 TaskGenerator            # class TaskGenerator(...)\n\u2502   \u251c\u2500 TaskPipe                 # class TaskPipe(...)\n\u2502   \u2514\u2500 TaskCalculator           # class TaskCalculator(...)\n\u2502\n\u251c\u2500  model                       # model folder (i.e. contains various types of models)\n\u2502   \u251c\u2500 model1_name.py           # model 1 (e.g. CNN)\n\u2502   \u251c\u2500 ...\n\u2502   \u2514\u2500 modelN_name.py           # model N (e.g. ResNet)\n\u2502       \u251c\u2500 init_local_module    # the function initializes personal models for parties\n\u2502       \u2514\u2500 init_global_module   # the function initializes the global models for parties\n\u2502\n\u2514\u2500 __init__.py                  # containing the variable default_model\n</code></pre> <p>Example: The architecture of MNIST is</p> <pre><code>\u251c\u2500 core.py\n\u2502   \u251c\u2500 TaskGenerator\n\u2502   \u251c\u2500 TaskPipe\n\u2502   \u2514\u2500 TaskCalculator\n\u251c\u2500  model\n\u2502   \u251c\u2500 cnn.py\n\u2502   \u2514\u2500 mlp.py\n\u2502       \u251c\u2500 init_local_module\n\u2502       \u2514\u2500 init_global_module\n\u2514\u2500 __init__.py\n</code></pre> <p>The details of implementing a customized benchmark are in Tutorial.3</p>"},{"location":"Docs/documents/#flgo.experiment","title":"<code>flgo.experiment</code>","text":"<p>This module is created for various experimental purposes</p>"},{"location":"Docs/documents/#flgo.simulator","title":"<code>flgo.simulator</code>","text":"<p>This module is to simulate arbitrary system heterogeneity that may occur in practice. We conclude four types of system heterogeneity from existing works.</p> System Heterogeneity Description <ol> <li> <p>Availability: the devices will be either available or unavailable at each moment, where only the                 available devices can be selected to participate in training.</p> </li> <li> <p>Responsiveness: the responsiveness describes the length of the period from the server broadcasting the                 gloabl model to the server receiving the locally trained model from a particular client.</p> </li> <li> <p>Completeness: since the server cannot fully control the behavior of devices,it's possible for devices to                 upload imcomplete model updates (i.e. only training for a few steps).</p> </li> <li> <p>Connectivity: the clients who promise to complete training may suffer accidients so that the server may lose                 connections with these client who will never return the currently trained local_movielens_recommendation model.</p> </li> </ol> <p>We build up a client state machine to simulate the four types of system heterogeneity, and provide high-level APIs to allow customized system heterogeneity simulation.</p> <p>Example: How to customize the system heterogeneity:</p> <pre><code>&gt;&gt;&gt; class MySimulator(flgo.simulator.base.BasicSimulator):\n...     def update_client_availability(self):\n...         # update the variable 'prob_available' and 'prob_unavailable' for all the clients\n...         self.set_variable(self.all_clients, 'prob_available', [0.9 for _ in self.all_clients])\n...         self.set_variable(self.all_clients, 'prob_unavailable', [0.1 for _ in self.all_clients])\n...\n...     def update_client_connectivity(self, client_ids):\n...         # update the variable 'prob_drop' for clients in client_ids\n...         self.set_variable(client_ids, 'prob_drop', [0.1 for _ in client_ids])\n...\n...     def update_client_responsiveness(self, client_ids, *args, **kwargs):\n...         # update the variable 'latency' for clients in client_ids\n...         self.set_variable(client_ids, 'latency', [np.random.randint(5,100) for _ in client_ids])\n...\n...     def update_client_completeness(self, client_ids, *args, **kwargs):\n...         # update the variable 'working_amount' for clients in client_ids\n...         self.set_variable(client_ids, 'working_amount',  [max(int(self.clients[cid].num_steps*np.random.rand()), 1) for cid in client_ids])\n&gt;&gt;&gt; r = flgo.init(task, algorithm=fedavg, Simulator=MySimulator)\n&gt;&gt;&gt; # The runner r will be runned under the customized system heterogeneity, where the clients' states will be flushed by\n&gt;&gt;&gt; # MySimulator.update_client_xxx at each moment of the virtual clock or particular events happen (i.e. a client was selected)\n</code></pre> <p>We also provide some preset Simulator like flgo.simulator.DefaultSimulator and flgo.simulator.</p>"},{"location":"Docs/documents/#flgo.utils","title":"<code>flgo.utils</code>","text":""},{"location":"Docs/empty/","title":"flgo.benchmark.toolkits.tabular","text":"<p>To be implemented...</p>"},{"location":"Docs/algorithm/","title":"Index","text":""},{"location":"Docs/algorithm/#flgo.algorithm","title":"<code>flgo.algorithm</code>","text":""},{"location":"Docs/algorithm/fedbase/","title":"flgo.algorithm.fedbase","text":""},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient","title":"<code>BasicClient</code>","text":"<p>         Bases: <code>BasicParty</code></p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>class BasicClient(BasicParty):\n    def __init__(self, option={}):\n        super().__init__()\n        self.id = None\n        # create local_movielens_recommendation dataset\n        self.data_loader = None\n        self.test_data = None\n        self.val_data = None\n        self.train_data = None\n        self.model = None\n        # local_movielens_recommendation calculator\n        self.device = self.gv.apply_for_device()\n        self.calculator = self.gv.TaskCalculator(self.device, option['optimizer'])\n        self._train_loader = None\n        # hyper-parameters for training\n        self.optimizer_name = option['optimizer']\n        self.learning_rate = option['learning_rate']\n        self.momentum = option['momentum']\n        self.weight_decay = option['weight_decay']\n        self.batch_size = option['batch_size']\n        self.num_steps = option['num_steps']\n        self.num_epochs = option['num_epochs']\n        self.clip_grad = option['clip_grad']\n        self.model = None\n        self.test_batch_size = option['test_batch_size']\n        self.loader_num_workers = option['num_workers']\n        self.current_steps = 0\n        # system setting\n        self._effective_num_steps = self.num_steps\n        self._latency = 0\n        # server\n        self.server = None\n        # actions of different message type\n        self.option = option\n        self.actions = {0: self.reply}\n\n    @fmodule.with_multi_gpus\n    def train(self, model):\nr\"\"\"\n        Standard local_movielens_recommendation training procedure. Train the transmitted model with\n        local_movielens_recommendation training dataset.\n\n        Args:\n            model (FModule): the global model\n        \"\"\"\n        model.train()\n        optimizer = self.calculator.get_optimizer(model, lr=self.learning_rate, weight_decay=self.weight_decay,\n                                                  momentum=self.momentum)\n        for iter in range(self.num_steps):\n            # get a batch of data\n            batch_data = self.get_batch_data()\n            model.zero_grad()\n            # calculate the loss of the model on batched dataset through task-specified calculator\n            loss = self.calculator.compute_loss(model, batch_data)['loss']\n            loss.backward()\n            if self.clip_grad&gt;0:torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=self.clip_grad)\n            optimizer.step()\n        return\n\n    @fmodule.with_multi_gpus\n    def test(self, model, flag='val'):\nr\"\"\"\n        Evaluate the model on the dataset owned by the client\n\n        Args:\n            model (flgo.utils.fmodule.FModule): the model need to be evaluated\n            flag (str): choose the data to evaluate the model\n\n        Returns:\n            metric (dict): the evaluating results (e.g. metric = {'loss':1.02})\n        \"\"\"\n        dataset = getattr(self, flag + '_data') if hasattr(self, flag + '_data') else None\n        if dataset is None: return {}\n        return self.calculator.test(model, dataset, min(self.test_batch_size, len(dataset)), self.option['num_workers'])\n\n    def unpack(self, received_pkg):\nr\"\"\"\n        Unpack the package received from the server\n\n        Args:\n            received_pkg (dict): a dict contains the global model as default\n\n        Returns:\n            the unpacked information\n        \"\"\"\n        # unpack the received package\n        return received_pkg['model']\n\n    def reply(self, svr_pkg):\nr\"\"\"\n        Reply a package to the server. The whole local_movielens_recommendation procedure should be defined here.\n        The standard form consists of three procedure: unpacking the\n        server_package to obtain the global model, training the global model,\n        and finally packing the updated model into client_package.\n\n        Args:\n            svr_pkg (dict): the package received from the server\n\n        Returns:\n            client_pkg (dict): the package to be send to the server\n        \"\"\"\n        model = self.unpack(svr_pkg)\n        self.train(model)\n        cpkg = self.pack(model)\n        return cpkg\n\n    def pack(self, model, *args, **kwargs):\nr\"\"\"\n        Packing the package to be send to the server. The operations of compression\n        of encryption of the package should be done here.\n\n        Args:\n            model: the locally trained model\n\n        Returns:\n            package: a dict that contains the necessary information for the server\n        \"\"\"\n        return {\n            \"model\": model,\n        }\n\n    def is_idle(self):\nr\"\"\"\n        Check if the client is available to participate training.\n\n        Returns:\n            True if the client is available according to the active_rate else False\n        \"\"\"\n        return self.gv.simulator.client_states[self.id] == 'idle'\n\n    def is_dropped(self):\nr\"\"\"\n        Check if the client drops out during communicating.\n\n        Returns:\n            True if the client was being dropped\n        \"\"\"\n        return self.gv.simulator.client_states[self.id] == 'dropped'\n\n    def is_working(self):\nr\"\"\"\n        Check if the client is training the model.\n\n        Returns:\n            True if the client is working\n        \"\"\"\n\n        return self.gv.simulator.client_states[self.id] == 'working'\n\n    def train_loss(self, model):\nr\"\"\"\n        Get the loss value of the model on local_movielens_recommendation training data\n\n        Args:\n            model (flgo.utils.fmodule.FModule|torch.nn.Module): model\n\n        Returns:\n            the training loss of model on self's training data\n        \"\"\"\n        return self.test(model, 'train')['loss']\n\n    def val_loss(self, model):\nr\"\"\"\n        Get the loss value of the model on local_movielens_recommendation validating data\n\n        Args:\n            model (flgo.utils.fmodule.FModule|torch.nn.Module): model\n\n        Returns:\n            the validation loss of model on self's validation data\n        \"\"\"\n        return self.test(model)['loss']\n\n    def register_server(self, server=None):\nr\"\"\"\n        Register the server to self.server\n        \"\"\"\n        self.register_objects([server], 'server_list')\n        if server is not None:\n            self.server = server\n\n    def set_local_epochs(self, epochs=None):\nr\"\"\"\n        Set local_movielens_recommendation training epochs\n        \"\"\"\n        if epochs is None: return\n        self.epochs = epochs\n        self.num_steps = self.epochs * math.ceil(len(self.train_data) / self.batch_size)\n        return\n\n    def set_batch_size(self, batch_size=None):\nr\"\"\"\n        Set local_movielens_recommendation training batch size\n\n        Args:\n            batch_size (int): the training batch size\n        \"\"\"\n        if batch_size is None: return\n        self.batch_size = batch_size\n\n    def set_learning_rate(self, lr=None):\n\"\"\"\n        Set the learning rate of local_movielens_recommendation training\n        Args:\n            lr (float): a real number\n        \"\"\"\n        self.learning_rate = lr if lr else self.learning_rate\n\n    def get_time_response(self):\n\"\"\"\n        Get the latency amount of the client\n\n        Returns:\n            self.latency_amount if client not dropping out\n        \"\"\"\n        return np.inf if self.dropped else self.time_response\n\n    def get_batch_data(self):\n\"\"\"\n        Get the batch of training data\n        Returns:\n            a batch of data\n        \"\"\"\n        if self._train_loader is None:\n            self._train_loader = self.calculator.get_dataloader(self.train_data, batch_size=self.batch_size,\n                                                                   num_workers=self.loader_num_workers,\n                                                                   pin_memory=self.option['pin_memory'])\n        try:\n            batch_data = next(self.data_loader)\n        except Exception as e:\n            self.data_loader = iter(self._train_loader)\n            batch_data = next(self.data_loader)\n        # clear local_movielens_recommendation DataLoader when finishing local_movielens_recommendation training\n        self.current_steps = (self.current_steps + 1) % self.num_steps\n        if self.current_steps == 0:\n            self.data_loader = None\n            self._train_loader = None\n        return batch_data\n\n    def update_device(self, dev):\n\"\"\"\n        Update running-time GPU device to dev\n\n        Args:\n            dev (torch.device): target dev\n        \"\"\"\n        self.device = dev\n        self.calculator = self.gv.TaskCalculator(dev, self.calculator.optimizer_name)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.get_batch_data","title":"<code>get_batch_data()</code>","text":"<p>Get the batch of training data</p> <p>Returns:</p> Type Description <p>a batch of data</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def get_batch_data(self):\n\"\"\"\n    Get the batch of training data\n    Returns:\n        a batch of data\n    \"\"\"\n    if self._train_loader is None:\n        self._train_loader = self.calculator.get_dataloader(self.train_data, batch_size=self.batch_size,\n                                                               num_workers=self.loader_num_workers,\n                                                               pin_memory=self.option['pin_memory'])\n    try:\n        batch_data = next(self.data_loader)\n    except Exception as e:\n        self.data_loader = iter(self._train_loader)\n        batch_data = next(self.data_loader)\n    # clear local_movielens_recommendation DataLoader when finishing local_movielens_recommendation training\n    self.current_steps = (self.current_steps + 1) % self.num_steps\n    if self.current_steps == 0:\n        self.data_loader = None\n        self._train_loader = None\n    return batch_data\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.get_time_response","title":"<code>get_time_response()</code>","text":"<p>Get the latency amount of the client</p> <p>Returns:</p> Type Description <p>self.latency_amount if client not dropping out</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def get_time_response(self):\n\"\"\"\n    Get the latency amount of the client\n\n    Returns:\n        self.latency_amount if client not dropping out\n    \"\"\"\n    return np.inf if self.dropped else self.time_response\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.is_dropped","title":"<code>is_dropped()</code>","text":"<p>Check if the client drops out during communicating.</p> <p>Returns:</p> Type Description <p>True if the client was being dropped</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def is_dropped(self):\nr\"\"\"\n    Check if the client drops out during communicating.\n\n    Returns:\n        True if the client was being dropped\n    \"\"\"\n    return self.gv.simulator.client_states[self.id] == 'dropped'\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.is_idle","title":"<code>is_idle()</code>","text":"<p>Check if the client is available to participate training.</p> <p>Returns:</p> Type Description <p>True if the client is available according to the active_rate else False</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def is_idle(self):\nr\"\"\"\n    Check if the client is available to participate training.\n\n    Returns:\n        True if the client is available according to the active_rate else False\n    \"\"\"\n    return self.gv.simulator.client_states[self.id] == 'idle'\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.is_working","title":"<code>is_working()</code>","text":"<p>Check if the client is training the model.</p> <p>Returns:</p> Type Description <p>True if the client is working</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def is_working(self):\nr\"\"\"\n    Check if the client is training the model.\n\n    Returns:\n        True if the client is working\n    \"\"\"\n\n    return self.gv.simulator.client_states[self.id] == 'working'\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.pack","title":"<code>pack(model, *args, **kwargs)</code>","text":"<p>Packing the package to be send to the server. The operations of compression of encryption of the package should be done here.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>the locally trained model</p> required <p>Returns:</p> Name Type Description <code>package</code> <p>a dict that contains the necessary information for the server</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def pack(self, model, *args, **kwargs):\nr\"\"\"\n    Packing the package to be send to the server. The operations of compression\n    of encryption of the package should be done here.\n\n    Args:\n        model: the locally trained model\n\n    Returns:\n        package: a dict that contains the necessary information for the server\n    \"\"\"\n    return {\n        \"model\": model,\n    }\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.register_server","title":"<code>register_server(server=None)</code>","text":"<p>Register the server to self.server</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def register_server(self, server=None):\nr\"\"\"\n    Register the server to self.server\n    \"\"\"\n    self.register_objects([server], 'server_list')\n    if server is not None:\n        self.server = server\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.reply","title":"<code>reply(svr_pkg)</code>","text":"<p>Reply a package to the server. The whole local_movielens_recommendation procedure should be defined here. The standard form consists of three procedure: unpacking the server_package to obtain the global model, training the global model, and finally packing the updated model into client_package.</p> <p>Parameters:</p> Name Type Description Default <code>svr_pkg</code> <code>dict</code> <p>the package received from the server</p> required <p>Returns:</p> Name Type Description <code>client_pkg</code> <code>dict</code> <p>the package to be send to the server</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def reply(self, svr_pkg):\nr\"\"\"\n    Reply a package to the server. The whole local_movielens_recommendation procedure should be defined here.\n    The standard form consists of three procedure: unpacking the\n    server_package to obtain the global model, training the global model,\n    and finally packing the updated model into client_package.\n\n    Args:\n        svr_pkg (dict): the package received from the server\n\n    Returns:\n        client_pkg (dict): the package to be send to the server\n    \"\"\"\n    model = self.unpack(svr_pkg)\n    self.train(model)\n    cpkg = self.pack(model)\n    return cpkg\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.set_batch_size","title":"<code>set_batch_size(batch_size=None)</code>","text":"<p>Set local_movielens_recommendation training batch size</p> <p>Parameters:</p> Name Type Description Default <code>batch_size</code> <code>int</code> <p>the training batch size</p> <code>None</code> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def set_batch_size(self, batch_size=None):\nr\"\"\"\n    Set local_movielens_recommendation training batch size\n\n    Args:\n        batch_size (int): the training batch size\n    \"\"\"\n    if batch_size is None: return\n    self.batch_size = batch_size\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.set_learning_rate","title":"<code>set_learning_rate(lr=None)</code>","text":"<p>Set the learning rate of local_movielens_recommendation training</p> <p>Parameters:</p> Name Type Description Default <code>lr</code> <code>float</code> <p>a real number</p> <code>None</code> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def set_learning_rate(self, lr=None):\n\"\"\"\n    Set the learning rate of local_movielens_recommendation training\n    Args:\n        lr (float): a real number\n    \"\"\"\n    self.learning_rate = lr if lr else self.learning_rate\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.set_local_epochs","title":"<code>set_local_epochs(epochs=None)</code>","text":"<p>Set local_movielens_recommendation training epochs</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def set_local_epochs(self, epochs=None):\nr\"\"\"\n    Set local_movielens_recommendation training epochs\n    \"\"\"\n    if epochs is None: return\n    self.epochs = epochs\n    self.num_steps = self.epochs * math.ceil(len(self.train_data) / self.batch_size)\n    return\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.test","title":"<code>test(model, flag='val')</code>","text":"<p>Evaluate the model on the dataset owned by the client</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>flgo.utils.fmodule.FModule</code> <p>the model need to be evaluated</p> required <code>flag</code> <code>str</code> <p>choose the data to evaluate the model</p> <code>'val'</code> <p>Returns:</p> Name Type Description <code>metric</code> <code>dict</code> <p>the evaluating results (e.g. metric = {'loss':1.02})</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>@fmodule.with_multi_gpus\ndef test(self, model, flag='val'):\nr\"\"\"\n    Evaluate the model on the dataset owned by the client\n\n    Args:\n        model (flgo.utils.fmodule.FModule): the model need to be evaluated\n        flag (str): choose the data to evaluate the model\n\n    Returns:\n        metric (dict): the evaluating results (e.g. metric = {'loss':1.02})\n    \"\"\"\n    dataset = getattr(self, flag + '_data') if hasattr(self, flag + '_data') else None\n    if dataset is None: return {}\n    return self.calculator.test(model, dataset, min(self.test_batch_size, len(dataset)), self.option['num_workers'])\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.train","title":"<code>train(model)</code>","text":"<p>Standard local_movielens_recommendation training procedure. Train the transmitted model with local_movielens_recommendation training dataset.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>FModule</code> <p>the global model</p> required Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>@fmodule.with_multi_gpus\ndef train(self, model):\nr\"\"\"\n    Standard local_movielens_recommendation training procedure. Train the transmitted model with\n    local_movielens_recommendation training dataset.\n\n    Args:\n        model (FModule): the global model\n    \"\"\"\n    model.train()\n    optimizer = self.calculator.get_optimizer(model, lr=self.learning_rate, weight_decay=self.weight_decay,\n                                              momentum=self.momentum)\n    for iter in range(self.num_steps):\n        # get a batch of data\n        batch_data = self.get_batch_data()\n        model.zero_grad()\n        # calculate the loss of the model on batched dataset through task-specified calculator\n        loss = self.calculator.compute_loss(model, batch_data)['loss']\n        loss.backward()\n        if self.clip_grad&gt;0:torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=self.clip_grad)\n        optimizer.step()\n    return\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.train_loss","title":"<code>train_loss(model)</code>","text":"<p>Get the loss value of the model on local_movielens_recommendation training data</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>flgo.utils.fmodule.FModule | torch.nn.Module</code> <p>model</p> required <p>Returns:</p> Type Description <p>the training loss of model on self's training data</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def train_loss(self, model):\nr\"\"\"\n    Get the loss value of the model on local_movielens_recommendation training data\n\n    Args:\n        model (flgo.utils.fmodule.FModule|torch.nn.Module): model\n\n    Returns:\n        the training loss of model on self's training data\n    \"\"\"\n    return self.test(model, 'train')['loss']\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.unpack","title":"<code>unpack(received_pkg)</code>","text":"<p>Unpack the package received from the server</p> <p>Parameters:</p> Name Type Description Default <code>received_pkg</code> <code>dict</code> <p>a dict contains the global model as default</p> required <p>Returns:</p> Type Description <p>the unpacked information</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def unpack(self, received_pkg):\nr\"\"\"\n    Unpack the package received from the server\n\n    Args:\n        received_pkg (dict): a dict contains the global model as default\n\n    Returns:\n        the unpacked information\n    \"\"\"\n    # unpack the received package\n    return received_pkg['model']\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.update_device","title":"<code>update_device(dev)</code>","text":"<p>Update running-time GPU device to dev</p> <p>Parameters:</p> Name Type Description Default <code>dev</code> <code>torch.device</code> <p>target dev</p> required Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def update_device(self, dev):\n\"\"\"\n    Update running-time GPU device to dev\n\n    Args:\n        dev (torch.device): target dev\n    \"\"\"\n    self.device = dev\n    self.calculator = self.gv.TaskCalculator(dev, self.calculator.optimizer_name)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicClient.val_loss","title":"<code>val_loss(model)</code>","text":"<p>Get the loss value of the model on local_movielens_recommendation validating data</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>flgo.utils.fmodule.FModule | torch.nn.Module</code> <p>model</p> required <p>Returns:</p> Type Description <p>the validation loss of model on self's validation data</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def val_loss(self, model):\nr\"\"\"\n    Get the loss value of the model on local_movielens_recommendation validating data\n\n    Args:\n        model (flgo.utils.fmodule.FModule|torch.nn.Module): model\n\n    Returns:\n        the validation loss of model on self's validation data\n    \"\"\"\n    return self.test(model)['loss']\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty","title":"<code>BasicParty</code>","text":"Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>class BasicParty:\n    def __init__(self, *args, **kwargs):\n        self.actions = {}  # the message-action map that is used to customize the communication process\n        self.id = None  # the id for communicating\n        self._object_map = {} # mapping objects according to their ids\n        self._data_names = []\n\n    def register_action_to_mtype(self, action_name: str, mtype):\nr\"\"\"\n        Register an existing method as the action corresponding to the message type.\n\n        Args:\n            action_name: the name of the instance method\n            mtype: the message type\n        \"\"\"\n        if action_name not in self.__dict__.keys():\n            raise NotImplementedError(\"There is no method named `{}` in the class instance.\".format(action_name))\n        self.actions[mtype] = self.__dict__[action_name]\n\n    def message_handler(self, package):\nr\"\"\"\n        Handling the received message by excuting the corresponding action.\n\n        Args:\n            package (dict): the package received from other parties (i.e. the content of the message)\n\n        Returns:\n            action_reult\n        \"\"\"\n        try:\n            mtype = package['__mtype__']\n        except:\n            raise KeyError(\"__mtype__ must be a key of the package\")\n        if mtype not in self.actions.keys():\n            raise NotImplementedError(\"There is no action corresponding to message type {}.\".format(mtype))\n        return self.actions[mtype](package)\n\n    def set_data(self, data, flag:str='train') -&gt; None:\nr\"\"\"\n        Set self's attibute 'xxx_data' to be data where xxx is the flag. For example,\n        after calling self.set_data([1,2,3], 'test'), self.test_data will be [1,2,3].\n        Particularly, If the flag is 'train', the batchsize and the num_steps will be\n        reset.\n\n        Args:\n            data: anything\n            flag (str): the name of the data\n        \"\"\"\n        setattr(self, flag + '_data', data)\n        if flag not in self._data_names:\n            self._data_names.append(flag)\n        if flag == 'train':\n            self.datavol = len(data)\n            if hasattr(self, 'batch_size'):\n                # reset batch_size\n                if self.batch_size &lt; 0:\n                    self.batch_size = len(self.get_data(flag))\n                elif self.batch_size &gt;= 1:\n                    self.batch_size = int(self.batch_size)\n                else:\n                    self.batch_size = int(self.datavol * self.batch_size)\n            # reset num_steps\n            if hasattr(self, 'num_steps') and hasattr(self, 'num_epochs'):\n                if self.num_steps &gt; 0:\n                    self.num_epochs = 1.0 * self.num_steps / (math.ceil(self.datavol / self.batch_size))\n                else:\n                    self.num_steps = self.num_epochs * math.ceil(self.datavol / self.batch_size)\n\n    def get_data(self, flag:str='val')-&gt;Any:\nr\"\"\"\n        Get self's attibute '{flag}_data' if this attribute exists.\n\n        Args:\n            flag (str): the name of the data\n\n        Returns:\n            flag_data (Any): self.{flag}_data\n        \"\"\"\n        dname = (flag+'_data')\n        if flag not in self._data_names: return None\n        else:\n            return getattr(self, dname)\n\n    def get_data_names(self)-&gt;list:\n\"\"\"\n        Get the names of data hold by self.\n\n        Returns:\n            data_names (list): the names of data hold by self\n        \"\"\"\n        return self._data_names\n\n    def get_classname(self)-&gt;str:\n\"\"\"\n        Get the class name of self.\n\n        Returns:\n            class_name (str): the class name\n        \"\"\"\n        return self.__class__.__name__\n\n    def set_model(self, model, model_name: str = 'model'):\nr\"\"\"\n        Set self's attibute 'model_name' to be model. For example,\n        after calling self.set_model(my_model, 'model'), self.model will be my_model.\n        \"\"\"\n        # set self.__dict__[model_name] = model\n        setattr(self, model_name, model)\n\n    def set_id(self, id=None):\nr\"\"\"\n        Set self's attibute 'id' to be id where self.id = id\n        \"\"\"\n        if id is not None:\n            self.id = id\n\n    def set_message(self, mtype:Any, package:dict={})-&gt;dict:\n\"\"\"Set the message type of a package.\n\n        Args:\n            mtype (Any): the message type\n            package (dict): a dict\n\n        Returns:\n            package_with_mtype (dict): a dict with the message type\n        \"\"\"\n        if type(package) is not dict:\n            raise TypeError('The type of the package should be dict')\n        package.update({'__mtype__': mtype})\n        return package\n\n    def register_objects(self, parties:list, parties_name='parties'):\nr\"\"\"\n        Set self's attribute party_names (e.g. parties as default) to be parties if\n        self has no attribute named party_names. Otherwise, parties will be extend to\n        the attribute party_names of self.\n\n        Args:\n            parties (list): a list of objects\n            parties_name (str): the name of attribute to store parties\n\n        Example:\n        ```python\n            &gt;&gt;&gt; a = BasicParty()\n            &gt;&gt;&gt; b = BasicParty()\n            &gt;&gt;&gt; c = BasicParty()\n            &gt;&gt;&gt; a.register_objects([b, c], 'parties')\n            &gt;&gt;&gt; a.parties # will be [b,c]\n            &gt;&gt;&gt; d = BasicParty()\n            &gt;&gt;&gt; a.register_objects([d], 'parties')\n            &gt;&gt;&gt; a.parties # will be [b,c,d]\n        ```\n        \"\"\"\n        if type(parties) is not list:\n            raise TypeError(\"parties should be a list\")\n        if not hasattr(self, parties_name):\n            setattr(self, parties_name, parties)\n        else:\n            tmp = getattr(self, parties_name)\n            if tmp is None: tmp = []\n            elif type(tmp) is not list: tmp = list(tmp)\n            tmp.extend(parties)\n            setattr(self, parties_name, tmp)\n        self._object_map.update({p.id:p for p in parties if p.id is not None})\n\n    def communicate_with(self, target_id, package={}):\nr\"\"\"\n        Send the package to target object according to its id, and receive the response from it\n\n        Args:\n            target_id (int): the id of the object to communicate with\n            package (dict): the package to be sended to the object\n        Returns:\n            client_package (dict): the reply from the target object and will be 'None' if losing connection\n        \"\"\"\n        return self.gv.communicator.request(self.id, target_id, package)\n\n    def initialize(self, *args, **kwargs):\nr\"\"\"API for customizing the initializing process of the object\"\"\"\n        return\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.communicate_with","title":"<code>communicate_with(target_id, package={})</code>","text":"<p>Send the package to target object according to its id, and receive the response from it</p> <p>Parameters:</p> Name Type Description Default <code>target_id</code> <code>int</code> <p>the id of the object to communicate with</p> required <code>package</code> <code>dict</code> <p>the package to be sended to the object</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>client_package</code> <code>dict</code> <p>the reply from the target object and will be 'None' if losing connection</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def communicate_with(self, target_id, package={}):\nr\"\"\"\n    Send the package to target object according to its id, and receive the response from it\n\n    Args:\n        target_id (int): the id of the object to communicate with\n        package (dict): the package to be sended to the object\n    Returns:\n        client_package (dict): the reply from the target object and will be 'None' if losing connection\n    \"\"\"\n    return self.gv.communicator.request(self.id, target_id, package)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.get_classname","title":"<code>get_classname()</code>","text":"<p>Get the class name of self.</p> <p>Returns:</p> Name Type Description <code>class_name</code> <code>str</code> <p>the class name</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def get_classname(self)-&gt;str:\n\"\"\"\n    Get the class name of self.\n\n    Returns:\n        class_name (str): the class name\n    \"\"\"\n    return self.__class__.__name__\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.get_data","title":"<code>get_data(flag='val')</code>","text":"<p>Get self's attibute '{flag}_data' if this attribute exists.</p> <p>Parameters:</p> Name Type Description Default <code>flag</code> <code>str</code> <p>the name of the data</p> <code>'val'</code> <p>Returns:</p> Name Type Description <code>flag_data</code> <code>Any</code> <p>self.{flag}_data</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def get_data(self, flag:str='val')-&gt;Any:\nr\"\"\"\n    Get self's attibute '{flag}_data' if this attribute exists.\n\n    Args:\n        flag (str): the name of the data\n\n    Returns:\n        flag_data (Any): self.{flag}_data\n    \"\"\"\n    dname = (flag+'_data')\n    if flag not in self._data_names: return None\n    else:\n        return getattr(self, dname)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.get_data_names","title":"<code>get_data_names()</code>","text":"<p>Get the names of data hold by self.</p> <p>Returns:</p> Name Type Description <code>data_names</code> <code>list</code> <p>the names of data hold by self</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def get_data_names(self)-&gt;list:\n\"\"\"\n    Get the names of data hold by self.\n\n    Returns:\n        data_names (list): the names of data hold by self\n    \"\"\"\n    return self._data_names\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.initialize","title":"<code>initialize(*args, **kwargs)</code>","text":"<p>API for customizing the initializing process of the object</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def initialize(self, *args, **kwargs):\nr\"\"\"API for customizing the initializing process of the object\"\"\"\n    return\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.message_handler","title":"<code>message_handler(package)</code>","text":"<p>Handling the received message by excuting the corresponding action.</p> <p>Parameters:</p> Name Type Description Default <code>package</code> <code>dict</code> <p>the package received from other parties (i.e. the content of the message)</p> required <p>Returns:</p> Type Description <p>action_reult</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def message_handler(self, package):\nr\"\"\"\n    Handling the received message by excuting the corresponding action.\n\n    Args:\n        package (dict): the package received from other parties (i.e. the content of the message)\n\n    Returns:\n        action_reult\n    \"\"\"\n    try:\n        mtype = package['__mtype__']\n    except:\n        raise KeyError(\"__mtype__ must be a key of the package\")\n    if mtype not in self.actions.keys():\n        raise NotImplementedError(\"There is no action corresponding to message type {}.\".format(mtype))\n    return self.actions[mtype](package)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.register_action_to_mtype","title":"<code>register_action_to_mtype(action_name, mtype)</code>","text":"<p>Register an existing method as the action corresponding to the message type.</p> <p>Parameters:</p> Name Type Description Default <code>action_name</code> <code>str</code> <p>the name of the instance method</p> required <code>mtype</code> <p>the message type</p> required Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def register_action_to_mtype(self, action_name: str, mtype):\nr\"\"\"\n    Register an existing method as the action corresponding to the message type.\n\n    Args:\n        action_name: the name of the instance method\n        mtype: the message type\n    \"\"\"\n    if action_name not in self.__dict__.keys():\n        raise NotImplementedError(\"There is no method named `{}` in the class instance.\".format(action_name))\n    self.actions[mtype] = self.__dict__[action_name]\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.register_objects","title":"<code>register_objects(parties, parties_name='parties')</code>","text":"<p>Set self's attribute party_names (e.g. parties as default) to be parties if self has no attribute named party_names. Otherwise, parties will be extend to the attribute party_names of self.</p> <p>Parameters:</p> Name Type Description Default <code>parties</code> <code>list</code> <p>a list of objects</p> required <code>parties_name</code> <code>str</code> <p>the name of attribute to store parties</p> <code>'parties'</code> <p>Example:</p> <pre><code>    &gt;&gt;&gt; a = BasicParty()\n    &gt;&gt;&gt; b = BasicParty()\n    &gt;&gt;&gt; c = BasicParty()\n    &gt;&gt;&gt; a.register_objects([b, c], 'parties')\n    &gt;&gt;&gt; a.parties # will be [b,c]\n    &gt;&gt;&gt; d = BasicParty()\n    &gt;&gt;&gt; a.register_objects([d], 'parties')\n    &gt;&gt;&gt; a.parties # will be [b,c,d]\n</code></pre> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def register_objects(self, parties:list, parties_name='parties'):\nr\"\"\"\n    Set self's attribute party_names (e.g. parties as default) to be parties if\n    self has no attribute named party_names. Otherwise, parties will be extend to\n    the attribute party_names of self.\n\n    Args:\n        parties (list): a list of objects\n        parties_name (str): the name of attribute to store parties\n\n    Example:\n    ```python\n        &gt;&gt;&gt; a = BasicParty()\n        &gt;&gt;&gt; b = BasicParty()\n        &gt;&gt;&gt; c = BasicParty()\n        &gt;&gt;&gt; a.register_objects([b, c], 'parties')\n        &gt;&gt;&gt; a.parties # will be [b,c]\n        &gt;&gt;&gt; d = BasicParty()\n        &gt;&gt;&gt; a.register_objects([d], 'parties')\n        &gt;&gt;&gt; a.parties # will be [b,c,d]\n    ```\n    \"\"\"\n    if type(parties) is not list:\n        raise TypeError(\"parties should be a list\")\n    if not hasattr(self, parties_name):\n        setattr(self, parties_name, parties)\n    else:\n        tmp = getattr(self, parties_name)\n        if tmp is None: tmp = []\n        elif type(tmp) is not list: tmp = list(tmp)\n        tmp.extend(parties)\n        setattr(self, parties_name, tmp)\n    self._object_map.update({p.id:p for p in parties if p.id is not None})\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.set_data","title":"<code>set_data(data, flag='train')</code>","text":"<p>Set self's attibute 'xxx_data' to be data where xxx is the flag. For example, after calling self.set_data([1,2,3], 'test'), self.test_data will be [1,2,3]. Particularly, If the flag is 'train', the batchsize and the num_steps will be reset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>anything</p> required <code>flag</code> <code>str</code> <p>the name of the data</p> <code>'train'</code> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def set_data(self, data, flag:str='train') -&gt; None:\nr\"\"\"\n    Set self's attibute 'xxx_data' to be data where xxx is the flag. For example,\n    after calling self.set_data([1,2,3], 'test'), self.test_data will be [1,2,3].\n    Particularly, If the flag is 'train', the batchsize and the num_steps will be\n    reset.\n\n    Args:\n        data: anything\n        flag (str): the name of the data\n    \"\"\"\n    setattr(self, flag + '_data', data)\n    if flag not in self._data_names:\n        self._data_names.append(flag)\n    if flag == 'train':\n        self.datavol = len(data)\n        if hasattr(self, 'batch_size'):\n            # reset batch_size\n            if self.batch_size &lt; 0:\n                self.batch_size = len(self.get_data(flag))\n            elif self.batch_size &gt;= 1:\n                self.batch_size = int(self.batch_size)\n            else:\n                self.batch_size = int(self.datavol * self.batch_size)\n        # reset num_steps\n        if hasattr(self, 'num_steps') and hasattr(self, 'num_epochs'):\n            if self.num_steps &gt; 0:\n                self.num_epochs = 1.0 * self.num_steps / (math.ceil(self.datavol / self.batch_size))\n            else:\n                self.num_steps = self.num_epochs * math.ceil(self.datavol / self.batch_size)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.set_id","title":"<code>set_id(id=None)</code>","text":"<p>Set self's attibute 'id' to be id where self.id = id</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def set_id(self, id=None):\nr\"\"\"\n    Set self's attibute 'id' to be id where self.id = id\n    \"\"\"\n    if id is not None:\n        self.id = id\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.set_message","title":"<code>set_message(mtype, package={})</code>","text":"<p>Set the message type of a package.</p> <p>Parameters:</p> Name Type Description Default <code>mtype</code> <code>Any</code> <p>the message type</p> required <code>package</code> <code>dict</code> <p>a dict</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>package_with_mtype</code> <code>dict</code> <p>a dict with the message type</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def set_message(self, mtype:Any, package:dict={})-&gt;dict:\n\"\"\"Set the message type of a package.\n\n    Args:\n        mtype (Any): the message type\n        package (dict): a dict\n\n    Returns:\n        package_with_mtype (dict): a dict with the message type\n    \"\"\"\n    if type(package) is not dict:\n        raise TypeError('The type of the package should be dict')\n    package.update({'__mtype__': mtype})\n    return package\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicParty.set_model","title":"<code>set_model(model, model_name='model')</code>","text":"<p>Set self's attibute 'model_name' to be model. For example, after calling self.set_model(my_model, 'model'), self.model will be my_model.</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def set_model(self, model, model_name: str = 'model'):\nr\"\"\"\n    Set self's attibute 'model_name' to be model. For example,\n    after calling self.set_model(my_model, 'model'), self.model will be my_model.\n    \"\"\"\n    # set self.__dict__[model_name] = model\n    setattr(self, model_name, model)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer","title":"<code>BasicServer</code>","text":"<p>         Bases: <code>BasicParty</code></p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>class BasicServer(BasicParty):\n    def __init__(self, option={}):\n        super().__init__()\n        self.test_data = None\n        self.val_data = None\n        self.train_data = None\n        self.model = None\n        self.clients = []\n        # basic configuration\n        self.task = option['task']\n        self.eval_interval = option['eval_interval']\n        self.num_parallels = option['num_parallels']\n        # server calculator\n        self.device = self.gv.apply_for_device() if not option['server_with_cpu'] else torch.device('cpu')\n        self.calculator = self.gv.TaskCalculator(self.device, optimizer_name=option['optimizer'])\n        # hyper-parameters during training process\n        self.num_rounds = option['num_rounds']\n        self.num_steps = option['num_steps']\n        self.num_epochs = option['num_epochs']\n        self.proportion = option['proportion']\n        self.decay_rate = option['learning_rate_decay']\n        self.lr_scheduler_type = option['lr_scheduler']\n        self.lr = option['learning_rate']\n        self.sample_option = option['sample']\n        self.aggregation_option = option['aggregate']\n        # systemic option\n        self.tolerance_for_latency = 999999\n        # algorithm-dependent parameters\n        self.algo_para = {}\n        self.current_round = 1\n        # all options\n        self.option = option\n        self.id = -1\n\n    def run(self):\n\"\"\"\n        Running the FL symtem where the global model is trained and evaluated iteratively.\n        \"\"\"\n        self.gv.logger.time_start('Total Time Cost')\n        if self.eval_interval&gt;0:\n            # evaluating initial model performance\n            self.gv.logger.info(\"--------------Initial Evaluation--------------\")\n            self.gv.logger.time_start('Eval Time Cost')\n            self.gv.logger.log_once()\n            self.gv.logger.time_end('Eval Time Cost')\n        while self.current_round &lt;= self.num_rounds:\n            self.gv.clock.step()\n            # iterate\n            updated = self.iterate()\n            # using logger to evaluate the model if the model is updated\n            if updated is True or updated is None:\n                self.gv.logger.info(\"--------------Round {}--------------\".format(self.current_round))\n                # check log interval\n                if self.gv.logger.check_if_log(self.current_round, self.eval_interval):\n                    self.gv.logger.time_start('Eval Time Cost')\n                    self.gv.logger.log_once()\n                    self.gv.logger.time_end('Eval Time Cost')\n                # check if early stopping\n                if self.gv.logger.early_stop(): break\n                self.current_round += 1\n                # decay learning rate\n                self.global_lr_scheduler(self.current_round)\n        self.gv.logger.info(\"=================End==================\")\n        self.gv.logger.time_end('Total Time Cost')\n        # save results as .json file\n        self.gv.logger.save_output_as_json()\n        return\n\n    def iterate(self):\n\"\"\"\n        The standard iteration of each federated communication round that contains three\n        necessary procedure in FL: client selection, communication and model aggregation.\n\n        Returns:\n            False if the global model is not updated in this iteration\n        \"\"\"\n        # sample clients: MD sampling as default\n        self.selected_clients = self.sample()\n        # training\n        models = self.communicate(self.selected_clients)['model']\n        # aggregate: pk = 1/K as default where K=len(selected_clients)\n        self.model = self.aggregate(models)\n        return len(models) &gt; 0\n\n    @ss.with_clock\n    def communicate(self, selected_clients, mtype=0, asynchronous=False):\n\"\"\"\n        The whole simulating communication procedure with the selected clients.\n        This part supports for simulating the client dropping out.\n\n        Args:\n            selected_clients (list of int): the clients to communicate with\n            mtype (anytype): type of message\n            asynchronous (bool): asynchronous communciation or synchronous communcation\n\n        Returns:\n            :the unpacked response from clients that is created ny self.unpack()\n        \"\"\"\n        packages_received_from_clients = []\n        received_package_buffer = {}\n        communicate_clients = list(set(selected_clients))\n        # prepare packages for clients\n        for client_id in communicate_clients:\n            received_package_buffer[client_id] = None\n        # communicate with selected clients\n        if self.num_parallels &lt;= 1:\n            # computing iteratively\n            for client_id in communicate_clients:\n                server_pkg = self.pack(client_id, mtype)\n                server_pkg['__mtype__'] = mtype\n                response_from_client_id = self.communicate_with(self.clients[client_id].id, package=server_pkg)\n                packages_received_from_clients.append(response_from_client_id)\n        else:\n            self.model = self.model.to(torch.device('cpu'))\n            # computing in parallel with torch.multiprocessing\n            pool = mp.Pool(self.num_parallels)\n            for client_id in communicate_clients:\n                server_pkg = self.pack(client_id, mtype)\n                server_pkg['__mtype__'] = mtype\n                self.clients[client_id].update_device(self.gv.apply_for_device())\n                args = (self.clients[client_id].id, server_pkg)\n                packages_received_from_clients.append(pool.apply_async(self.communicate_with, args=args))\n            pool.close()\n            pool.join()\n            packages_received_from_clients = list(map(lambda x: x.get(), packages_received_from_clients))\n            self.model = self.model.to(self.device)\n            for pkg in packages_received_from_clients:\n                for k,v in pkg.items():\n                    if hasattr(v, 'to'):\n                        try:\n                            pkg[k] = v.to(self.device)\n                        except:\n                            continue\n        for i, client_id in enumerate(communicate_clients): received_package_buffer[client_id] = packages_received_from_clients[i]\n        packages_received_from_clients = [received_package_buffer[cid] for cid in selected_clients if\n                                          received_package_buffer[cid]]\n        self.received_clients = selected_clients\n        return self.unpack(packages_received_from_clients)\n\n    def communicate_with(self, target_id, package={}):\nr\"\"\"Communicate with the object under system simulator that simulates the\n        network latency. Send the package to target object according to its id,\n        and receive the response from it\n\n        Args:\n            target_id (int): the id of the object to communicate with\n            package (dict): the package to be sended to the object\n\n        Returns:\n            client_package (dict): the reply from the target object and\n            will be 'None' if losing connection\n        \"\"\"\n        return super(BasicServer, self).communicate_with(target_id, package)\n\n    def pack(self, client_id, mtype=0, *args, **kwargs):\nr\"\"\"\n        Pack the necessary information for the client's local_movielens_recommendation training.\n        Any operations of compression or encryption should be done here.\n\n        Args:\n            client_id (int): the id of the client to communicate with\n            mtype: the message type\n\n        Returns:\n            a dict contains necessary information (e.g. a copy of the global model as default)\n        \"\"\"\n        return {\n            \"model\": copy.deepcopy(self.model),\n        }\n\n    def unpack(self, packages_received_from_clients):\nr\"\"\"\n        Unpack the information from the received packages. Return models and losses as default.\n\n        Args:\n            packages_received_from_clients (list): a list of packages\n\n        Returns:\n            res (dict): collections.defaultdict that contains several lists of the clients' reply\n        \"\"\"\n        if len(packages_received_from_clients) == 0: return collections.defaultdict(list)\n        res = {pname: [] for pname in packages_received_from_clients[0]}\n        for cpkg in packages_received_from_clients:\n            for pname, pval in cpkg.items():\n                res[pname].append(pval)\n        return res\n\n    def global_lr_scheduler(self, current_round):\nr\"\"\"\n        Control the step size (i.e. learning rate) of local_movielens_recommendation training\n        Args:\n            current_round (int): the current communication round\n        \"\"\"\n        if self.lr_scheduler_type == -1:\n            return\n        elif self.lr_scheduler_type == 0:\n\"\"\"eta_{round+1} = DecayRate * eta_{round}\"\"\"\n            self.lr *= self.decay_rate\n            for c in self.clients:\n                c.set_learning_rate(self.lr)\n        elif self.lr_scheduler_type == 1:\n\"\"\"eta_{round+1} = eta_0/(round+1)\"\"\"\n            self.lr = self.option['learning_rate'] * 1.0 / (current_round + 1)\n            for c in self.clients:\n                c.set_learning_rate(self.lr)\n\n    def sample(self):\nr\"\"\"\n        Sample the clients. There are three types of sampling manners:\n        full sample, uniform sample without replacement, and MDSample\n        with replacement. Particularly, if 'available' is in self.sample_option,\n        the server will only sample from currently available clients.\n\n        Returns:\n            a list of the ids of the selected clients\n\n        Example:\n        ```python\n            &gt;&gt;&gt; selected_clients=self.sample()\n            &gt;&gt;&gt; selected_clients\n            &gt;&gt;&gt; # The selected_clients is a list of clients' ids\n        ```\n        \"\"\"\n        all_clients = self.available_clients if 'available' in self.sample_option else [cid for cid in\n                                                                                        range(self.num_clients)]\n        # full sampling with unlimited communication resources of the server\n        if 'full' in self.sample_option:\n            return all_clients\n        # sample clients\n        elif 'uniform' in self.sample_option:\n            # original sample proposed by fedavg\n            selected_clients = list(\n                np.random.choice(all_clients, min(self.clients_per_round, len(all_clients)), replace=False)) if len(\n                all_clients) &gt; 0 else []\n        elif 'md' in self.sample_option:\n            # the default setting that is introduced by FedProx, where the clients are sampled with the probability in proportion to their local_movielens_recommendation data sizes\n            local_data_vols = [self.clients[cid].datavol for cid in all_clients]\n            total_data_vol = sum(local_data_vols)\n            p = np.array(local_data_vols) / total_data_vol\n            selected_clients = list(np.random.choice(all_clients, self.clients_per_round, replace=True, p=p)) if len(\n                all_clients) &gt; 0 else []\n        return selected_clients\n\n    def aggregate(self, models: list, *args, **kwargs):\nr\"\"\"\n        Aggregate the locally trained models into the new one. The aggregation\n        will be according to self.aggregate_option where\n\n        pk = nk/n where n=self.data_vol\n        K = |S_t|\n        N = |S|\n        -------------------------------------------------------------------------------------------------------------------------\n         weighted_scale                 |uniform (default)          |weighted_com (original fedavg)   |other\n        ==========================================================================================================================\n        N/K * \u03a3pk * model_k             |1/K * \u03a3model_k             |(1-\u03a3pk) * w_old + \u03a3pk * model_k  |\u03a3(pk/\u03a3pk) * model_k\n\n\n        Args:\n            models (list): a list of local_movielens_recommendation models\n\n        Returns:\n            the aggregated model\n\n        Example:\n        ```python\n            &gt;&gt;&gt; models = [m1, m2] # m1, m2 are models with the same architecture\n            &gt;&gt;&gt; m_new = self.aggregate(models)\n        ```\n        \"\"\"\n        if len(models) == 0: return self.model\n        local_data_vols = [c.datavol for c in self.clients]\n        total_data_vol = sum(local_data_vols)\n        if self.aggregation_option == 'weighted_scale':\n            p = [1.0 * local_data_vols[cid] / total_data_vol for cid in self.received_clients]\n            K = len(models)\n            N = self.num_clients\n            return fmodule._model_sum([model_k * pk for model_k, pk in zip(models, p)]) * N / K\n        elif self.aggregation_option == 'uniform':\n            return fmodule._model_average(models)\n        elif self.aggregation_option == 'weighted_com':\n            p = [1.0 * local_data_vols[cid] / total_data_vol for cid in self.received_clients]\n            w = fmodule._model_sum([model_k * pk for model_k, pk in zip(models, p)])\n            return (1.0 - sum(p)) * self.model + w\n        else:\n            p = [1.0 * local_data_vols[cid] / total_data_vol for cid in self.received_clients]\n            sump = sum(p)\n            p = [pk / sump for pk in p]\n            return fmodule._model_sum([model_k * pk for model_k, pk in zip(models, p)])\n\n    def global_test(self, model=None, flag:str='val'):\nr\"\"\"\n        Collect local_movielens_recommendation testing result of all the clients.\n\n        Args:\n            model (flgo.utils.fmodule.FModule|torch.nn.Module): the model to be sevaluated\n            flag (str): choose the data to evaluate the model\n\n        Returns:\n            metrics (dict): a dict contains key-value pairs like (metric_name,\n            the lists of metric results of the clients)\n        \"\"\"\n        if model is None: model=self.model\n        all_metrics = collections.defaultdict(list)\n        for c in self.clients:\n            client_metrics = c.test(model, flag)\n            for met_name, met_val in client_metrics.items():\n                all_metrics[met_name].append(met_val)\n        return all_metrics\n\n    def test(self, model=None, flag:str='test'):\nr\"\"\"\n        Evaluate the model on the test dataset owned by the server.\n\n        Args:\n            model (flgo.utils.fmodule.FModule): the model need to be evaluated\n            flag (str): choose the data to evaluate the model\n\n        Returns:\n            metrics (dict): the dict contains the evaluating results\n        \"\"\"\n        if model is None: model = self.model\n        dataset = getattr(self, flag+'_data') if hasattr(self, flag+'_data') else None\n        if dataset is None:\n            return {}\n        else:\n            return self.calculator.test(model, dataset, batch_size=min(self.option['test_batch_size'], len(dataset)),\n                                        num_workers=self.option['num_workers'], pin_memory=self.option['pin_memory'])\n\n    def init_algo_para(self, algo_para: dict):\n\"\"\"\n        Initialize the algorithm-dependent hyper-parameters for the server and all the clients.\n\n        Args:\n            algo_paras (dict): the dict that defines the hyper-parameters (i.e. name, value and type) for the algorithm.\n\n        Example:\n        ```python\n            &gt;&gt;&gt; # s is an instance of Server and s.clients are instances of Client\n            &gt;&gt;&gt; s.u # will raise error\n            &gt;&gt;&gt; [c.u for c in s.clients] # will raise errors too\n            &gt;&gt;&gt; s.init_algo_para({'u': 0.1})\n            &gt;&gt;&gt; s.u # will be 0.1\n            &gt;&gt;&gt; [c.u for c in s.clients] # will be [0.1, 0.1,..., 0.1]\n        ```\n        Note:\n            Once `option['algo_para']` is not `None`, the value of the pre-defined hyperparameters will be replaced by the list of values in `option['algo_para']`,\n            which requires the length of `option['algo_para']` is equal to the length of `algo_paras`\n        \"\"\"\n        self.algo_para = algo_para\n        if len(self.algo_para) == 0: return\n        # initialize algorithm-dependent hyperparameters from the input options\n        if self.option['algo_para'] is not None:\n            # assert len(self.algo_para) == len(self.option['algo_para'])\n            keys = list(self.algo_para.keys())\n            for i, pv in enumerate(self.option['algo_para']):\n                if i == len(self.option['algo_para']): break\n                para_name = keys[i]\n                try:\n                    self.algo_para[para_name] = type(self.algo_para[para_name])(pv)\n                except:\n                    self.algo_para[para_name] = pv\n        # register the algorithm-dependent hyperparameters as the attributes of the server and all the clients\n        for para_name, value in self.algo_para.items():\n            self.__setattr__(para_name, value)\n            for p in self._object_map.values():\n                p.__setattr__(para_name, value)\n        return\n\n    def get_tolerance_for_latency(self):\nr\"\"\"\n        Get the tolerance for latency of waiting for clients' responses\n\n        Returns:\n            a int number (i.e. self.tolerance_for_latency)\n        \"\"\"\n        return self.tolerance_for_latency\n\n    def set_tolerance_for_latency(self, tolerance:int):\nr\"\"\"\n        Set the tolerance for latency of waiting for clients' responses\n\n        Args:\n            tolerance (int): the amounts of virtual time units\n        \"\"\"\n        self.tolerance_for_latency = tolerance\n\n    def wait_time(self, t=1):\nr\"\"\"\n        Wait for the time of the virtual clock to pass t units\n        \"\"\"\n        ss.clock.step(t)\n        return\n\n    @property\n    def available_clients(self):\n\"\"\"\n        Return all the available clients at the current round.\n\n        Returns:\n            a list of indices of currently available clients\n        \"\"\"\n        return [cid for cid in range(self.num_clients) if self.clients[cid].is_idle()]\n\n    def register_clients(self, clients):\n\"\"\"\n        Regiser clients to self.clients, and update related attributes (e.g. self.num_clients)\n\n        Args:\n            clients (list): a list of objects\n        \"\"\"\n        self.register_objects(clients, 'clients')\n        self.num_clients = len(clients)\n        for cid, c in enumerate(self.clients):\n            c.client_id = cid\n        for c in self.clients: c.register_server(self)\n        self.clients_per_round = max(int(self.num_clients * self.proportion), 1)\n        self.selected_clients = []\n        self.dropped_clients = []\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.available_clients","title":"<code>available_clients</code>  <code>property</code>","text":"<p>Return all the available clients at the current round.</p> <p>Returns:</p> Type Description <p>a list of indices of currently available clients</p>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.aggregate","title":"<code>aggregate(models, *args, **kwargs)</code>","text":"<p>Aggregate the locally trained models into the new one. The aggregation will be according to self.aggregate_option where</p> <p>pk = nk/n where n=self.data_vol K = |S_t| N = |S|</p>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.aggregate--weighted_scale-uniform-default-weighted_com-original-fedavg-other","title":"weighted_scale                 |uniform (default)          |weighted_com (original fedavg)   |other","text":"<p>N/K * \u03a3pk * model_k             |1/K * \u03a3model_k             |(1-\u03a3pk) * w_old + \u03a3pk * model_k  |\u03a3(pk/\u03a3pk) * model_k</p> <p>Parameters:</p> Name Type Description Default <code>models</code> <code>list</code> <p>a list of local_movielens_recommendation models</p> required <p>Returns:</p> Type Description <p>the aggregated model</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; models = [m1, m2] # m1, m2 are models with the same architecture\n    &gt;&gt;&gt; m_new = self.aggregate(models)\n</code></pre> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def aggregate(self, models: list, *args, **kwargs):\nr\"\"\"\n    Aggregate the locally trained models into the new one. The aggregation\n    will be according to self.aggregate_option where\n\n    pk = nk/n where n=self.data_vol\n    K = |S_t|\n    N = |S|\n    -------------------------------------------------------------------------------------------------------------------------\n     weighted_scale                 |uniform (default)          |weighted_com (original fedavg)   |other\n    ==========================================================================================================================\n    N/K * \u03a3pk * model_k             |1/K * \u03a3model_k             |(1-\u03a3pk) * w_old + \u03a3pk * model_k  |\u03a3(pk/\u03a3pk) * model_k\n\n\n    Args:\n        models (list): a list of local_movielens_recommendation models\n\n    Returns:\n        the aggregated model\n\n    Example:\n    ```python\n        &gt;&gt;&gt; models = [m1, m2] # m1, m2 are models with the same architecture\n        &gt;&gt;&gt; m_new = self.aggregate(models)\n    ```\n    \"\"\"\n    if len(models) == 0: return self.model\n    local_data_vols = [c.datavol for c in self.clients]\n    total_data_vol = sum(local_data_vols)\n    if self.aggregation_option == 'weighted_scale':\n        p = [1.0 * local_data_vols[cid] / total_data_vol for cid in self.received_clients]\n        K = len(models)\n        N = self.num_clients\n        return fmodule._model_sum([model_k * pk for model_k, pk in zip(models, p)]) * N / K\n    elif self.aggregation_option == 'uniform':\n        return fmodule._model_average(models)\n    elif self.aggregation_option == 'weighted_com':\n        p = [1.0 * local_data_vols[cid] / total_data_vol for cid in self.received_clients]\n        w = fmodule._model_sum([model_k * pk for model_k, pk in zip(models, p)])\n        return (1.0 - sum(p)) * self.model + w\n    else:\n        p = [1.0 * local_data_vols[cid] / total_data_vol for cid in self.received_clients]\n        sump = sum(p)\n        p = [pk / sump for pk in p]\n        return fmodule._model_sum([model_k * pk for model_k, pk in zip(models, p)])\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.communicate","title":"<code>communicate(selected_clients, mtype=0, asynchronous=False)</code>","text":"<p>The whole simulating communication procedure with the selected clients. This part supports for simulating the client dropping out.</p> <p>Parameters:</p> Name Type Description Default <code>selected_clients</code> <code>list of int</code> <p>the clients to communicate with</p> required <code>mtype</code> <code>anytype</code> <p>type of message</p> <code>0</code> <code>asynchronous</code> <code>bool</code> <p>asynchronous communciation or synchronous communcation</p> <code>False</code> <p>Returns:</p> Type Description <p>the unpacked response from clients that is created ny self.unpack()</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>@ss.with_clock\ndef communicate(self, selected_clients, mtype=0, asynchronous=False):\n\"\"\"\n    The whole simulating communication procedure with the selected clients.\n    This part supports for simulating the client dropping out.\n\n    Args:\n        selected_clients (list of int): the clients to communicate with\n        mtype (anytype): type of message\n        asynchronous (bool): asynchronous communciation or synchronous communcation\n\n    Returns:\n        :the unpacked response from clients that is created ny self.unpack()\n    \"\"\"\n    packages_received_from_clients = []\n    received_package_buffer = {}\n    communicate_clients = list(set(selected_clients))\n    # prepare packages for clients\n    for client_id in communicate_clients:\n        received_package_buffer[client_id] = None\n    # communicate with selected clients\n    if self.num_parallels &lt;= 1:\n        # computing iteratively\n        for client_id in communicate_clients:\n            server_pkg = self.pack(client_id, mtype)\n            server_pkg['__mtype__'] = mtype\n            response_from_client_id = self.communicate_with(self.clients[client_id].id, package=server_pkg)\n            packages_received_from_clients.append(response_from_client_id)\n    else:\n        self.model = self.model.to(torch.device('cpu'))\n        # computing in parallel with torch.multiprocessing\n        pool = mp.Pool(self.num_parallels)\n        for client_id in communicate_clients:\n            server_pkg = self.pack(client_id, mtype)\n            server_pkg['__mtype__'] = mtype\n            self.clients[client_id].update_device(self.gv.apply_for_device())\n            args = (self.clients[client_id].id, server_pkg)\n            packages_received_from_clients.append(pool.apply_async(self.communicate_with, args=args))\n        pool.close()\n        pool.join()\n        packages_received_from_clients = list(map(lambda x: x.get(), packages_received_from_clients))\n        self.model = self.model.to(self.device)\n        for pkg in packages_received_from_clients:\n            for k,v in pkg.items():\n                if hasattr(v, 'to'):\n                    try:\n                        pkg[k] = v.to(self.device)\n                    except:\n                        continue\n    for i, client_id in enumerate(communicate_clients): received_package_buffer[client_id] = packages_received_from_clients[i]\n    packages_received_from_clients = [received_package_buffer[cid] for cid in selected_clients if\n                                      received_package_buffer[cid]]\n    self.received_clients = selected_clients\n    return self.unpack(packages_received_from_clients)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.communicate_with","title":"<code>communicate_with(target_id, package={})</code>","text":"<p>Communicate with the object under system simulator that simulates the network latency. Send the package to target object according to its id, and receive the response from it</p> <p>Parameters:</p> Name Type Description Default <code>target_id</code> <code>int</code> <p>the id of the object to communicate with</p> required <code>package</code> <code>dict</code> <p>the package to be sended to the object</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>client_package</code> <code>dict</code> <p>the reply from the target object and</p> <p>will be 'None' if losing connection</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def communicate_with(self, target_id, package={}):\nr\"\"\"Communicate with the object under system simulator that simulates the\n    network latency. Send the package to target object according to its id,\n    and receive the response from it\n\n    Args:\n        target_id (int): the id of the object to communicate with\n        package (dict): the package to be sended to the object\n\n    Returns:\n        client_package (dict): the reply from the target object and\n        will be 'None' if losing connection\n    \"\"\"\n    return super(BasicServer, self).communicate_with(target_id, package)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.get_tolerance_for_latency","title":"<code>get_tolerance_for_latency()</code>","text":"<p>Get the tolerance for latency of waiting for clients' responses</p> <p>Returns:</p> Type Description <p>a int number (i.e. self.tolerance_for_latency)</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def get_tolerance_for_latency(self):\nr\"\"\"\n    Get the tolerance for latency of waiting for clients' responses\n\n    Returns:\n        a int number (i.e. self.tolerance_for_latency)\n    \"\"\"\n    return self.tolerance_for_latency\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.global_lr_scheduler","title":"<code>global_lr_scheduler(current_round)</code>","text":"<p>Control the step size (i.e. learning rate) of local_movielens_recommendation training</p> <p>Parameters:</p> Name Type Description Default <code>current_round</code> <code>int</code> <p>the current communication round</p> required Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def global_lr_scheduler(self, current_round):\nr\"\"\"\n    Control the step size (i.e. learning rate) of local_movielens_recommendation training\n    Args:\n        current_round (int): the current communication round\n    \"\"\"\n    if self.lr_scheduler_type == -1:\n        return\n    elif self.lr_scheduler_type == 0:\n\"\"\"eta_{round+1} = DecayRate * eta_{round}\"\"\"\n        self.lr *= self.decay_rate\n        for c in self.clients:\n            c.set_learning_rate(self.lr)\n    elif self.lr_scheduler_type == 1:\n\"\"\"eta_{round+1} = eta_0/(round+1)\"\"\"\n        self.lr = self.option['learning_rate'] * 1.0 / (current_round + 1)\n        for c in self.clients:\n            c.set_learning_rate(self.lr)\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.global_test","title":"<code>global_test(model=None, flag='val')</code>","text":"<p>Collect local_movielens_recommendation testing result of all the clients.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>flgo.utils.fmodule.FModule | torch.nn.Module</code> <p>the model to be sevaluated</p> <code>None</code> <code>flag</code> <code>str</code> <p>choose the data to evaluate the model</p> <code>'val'</code> <p>Returns:</p> Name Type Description <code>metrics</code> <code>dict</code> <p>a dict contains key-value pairs like (metric_name,</p> <p>the lists of metric results of the clients)</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def global_test(self, model=None, flag:str='val'):\nr\"\"\"\n    Collect local_movielens_recommendation testing result of all the clients.\n\n    Args:\n        model (flgo.utils.fmodule.FModule|torch.nn.Module): the model to be sevaluated\n        flag (str): choose the data to evaluate the model\n\n    Returns:\n        metrics (dict): a dict contains key-value pairs like (metric_name,\n        the lists of metric results of the clients)\n    \"\"\"\n    if model is None: model=self.model\n    all_metrics = collections.defaultdict(list)\n    for c in self.clients:\n        client_metrics = c.test(model, flag)\n        for met_name, met_val in client_metrics.items():\n            all_metrics[met_name].append(met_val)\n    return all_metrics\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.init_algo_para","title":"<code>init_algo_para(algo_para)</code>","text":"<p>Initialize the algorithm-dependent hyper-parameters for the server and all the clients.</p> <p>Parameters:</p> Name Type Description Default <code>algo_paras</code> <code>dict</code> <p>the dict that defines the hyper-parameters (i.e. name, value and type) for the algorithm.</p> required <p>Example:</p> <pre><code>    &gt;&gt;&gt; # s is an instance of Server and s.clients are instances of Client\n    &gt;&gt;&gt; s.u # will raise error\n    &gt;&gt;&gt; [c.u for c in s.clients] # will raise errors too\n    &gt;&gt;&gt; s.init_algo_para({'u': 0.1})\n    &gt;&gt;&gt; s.u # will be 0.1\n    &gt;&gt;&gt; [c.u for c in s.clients] # will be [0.1, 0.1,..., 0.1]\n</code></pre> Note <p>Once <code>option['algo_para']</code> is not <code>None</code>, the value of the pre-defined hyperparameters will be replaced by the list of values in <code>option['algo_para']</code>, which requires the length of <code>option['algo_para']</code> is equal to the length of <code>algo_paras</code></p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def init_algo_para(self, algo_para: dict):\n\"\"\"\n    Initialize the algorithm-dependent hyper-parameters for the server and all the clients.\n\n    Args:\n        algo_paras (dict): the dict that defines the hyper-parameters (i.e. name, value and type) for the algorithm.\n\n    Example:\n    ```python\n        &gt;&gt;&gt; # s is an instance of Server and s.clients are instances of Client\n        &gt;&gt;&gt; s.u # will raise error\n        &gt;&gt;&gt; [c.u for c in s.clients] # will raise errors too\n        &gt;&gt;&gt; s.init_algo_para({'u': 0.1})\n        &gt;&gt;&gt; s.u # will be 0.1\n        &gt;&gt;&gt; [c.u for c in s.clients] # will be [0.1, 0.1,..., 0.1]\n    ```\n    Note:\n        Once `option['algo_para']` is not `None`, the value of the pre-defined hyperparameters will be replaced by the list of values in `option['algo_para']`,\n        which requires the length of `option['algo_para']` is equal to the length of `algo_paras`\n    \"\"\"\n    self.algo_para = algo_para\n    if len(self.algo_para) == 0: return\n    # initialize algorithm-dependent hyperparameters from the input options\n    if self.option['algo_para'] is not None:\n        # assert len(self.algo_para) == len(self.option['algo_para'])\n        keys = list(self.algo_para.keys())\n        for i, pv in enumerate(self.option['algo_para']):\n            if i == len(self.option['algo_para']): break\n            para_name = keys[i]\n            try:\n                self.algo_para[para_name] = type(self.algo_para[para_name])(pv)\n            except:\n                self.algo_para[para_name] = pv\n    # register the algorithm-dependent hyperparameters as the attributes of the server and all the clients\n    for para_name, value in self.algo_para.items():\n        self.__setattr__(para_name, value)\n        for p in self._object_map.values():\n            p.__setattr__(para_name, value)\n    return\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.iterate","title":"<code>iterate()</code>","text":"<p>The standard iteration of each federated communication round that contains three necessary procedure in FL: client selection, communication and model aggregation.</p> <p>Returns:</p> Type Description <p>False if the global model is not updated in this iteration</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def iterate(self):\n\"\"\"\n    The standard iteration of each federated communication round that contains three\n    necessary procedure in FL: client selection, communication and model aggregation.\n\n    Returns:\n        False if the global model is not updated in this iteration\n    \"\"\"\n    # sample clients: MD sampling as default\n    self.selected_clients = self.sample()\n    # training\n    models = self.communicate(self.selected_clients)['model']\n    # aggregate: pk = 1/K as default where K=len(selected_clients)\n    self.model = self.aggregate(models)\n    return len(models) &gt; 0\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.pack","title":"<code>pack(client_id, mtype=0, *args, **kwargs)</code>","text":"<p>Pack the necessary information for the client's local_movielens_recommendation training. Any operations of compression or encryption should be done here.</p> <p>Parameters:</p> Name Type Description Default <code>client_id</code> <code>int</code> <p>the id of the client to communicate with</p> required <code>mtype</code> <p>the message type</p> <code>0</code> <p>Returns:</p> Type Description <p>a dict contains necessary information (e.g. a copy of the global model as default)</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def pack(self, client_id, mtype=0, *args, **kwargs):\nr\"\"\"\n    Pack the necessary information for the client's local_movielens_recommendation training.\n    Any operations of compression or encryption should be done here.\n\n    Args:\n        client_id (int): the id of the client to communicate with\n        mtype: the message type\n\n    Returns:\n        a dict contains necessary information (e.g. a copy of the global model as default)\n    \"\"\"\n    return {\n        \"model\": copy.deepcopy(self.model),\n    }\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.register_clients","title":"<code>register_clients(clients)</code>","text":"<p>Regiser clients to self.clients, and update related attributes (e.g. self.num_clients)</p> <p>Parameters:</p> Name Type Description Default <code>clients</code> <code>list</code> <p>a list of objects</p> required Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def register_clients(self, clients):\n\"\"\"\n    Regiser clients to self.clients, and update related attributes (e.g. self.num_clients)\n\n    Args:\n        clients (list): a list of objects\n    \"\"\"\n    self.register_objects(clients, 'clients')\n    self.num_clients = len(clients)\n    for cid, c in enumerate(self.clients):\n        c.client_id = cid\n    for c in self.clients: c.register_server(self)\n    self.clients_per_round = max(int(self.num_clients * self.proportion), 1)\n    self.selected_clients = []\n    self.dropped_clients = []\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.run","title":"<code>run()</code>","text":"<p>Running the FL symtem where the global model is trained and evaluated iteratively.</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def run(self):\n\"\"\"\n    Running the FL symtem where the global model is trained and evaluated iteratively.\n    \"\"\"\n    self.gv.logger.time_start('Total Time Cost')\n    if self.eval_interval&gt;0:\n        # evaluating initial model performance\n        self.gv.logger.info(\"--------------Initial Evaluation--------------\")\n        self.gv.logger.time_start('Eval Time Cost')\n        self.gv.logger.log_once()\n        self.gv.logger.time_end('Eval Time Cost')\n    while self.current_round &lt;= self.num_rounds:\n        self.gv.clock.step()\n        # iterate\n        updated = self.iterate()\n        # using logger to evaluate the model if the model is updated\n        if updated is True or updated is None:\n            self.gv.logger.info(\"--------------Round {}--------------\".format(self.current_round))\n            # check log interval\n            if self.gv.logger.check_if_log(self.current_round, self.eval_interval):\n                self.gv.logger.time_start('Eval Time Cost')\n                self.gv.logger.log_once()\n                self.gv.logger.time_end('Eval Time Cost')\n            # check if early stopping\n            if self.gv.logger.early_stop(): break\n            self.current_round += 1\n            # decay learning rate\n            self.global_lr_scheduler(self.current_round)\n    self.gv.logger.info(\"=================End==================\")\n    self.gv.logger.time_end('Total Time Cost')\n    # save results as .json file\n    self.gv.logger.save_output_as_json()\n    return\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.sample","title":"<code>sample()</code>","text":"<p>Sample the clients. There are three types of sampling manners: full sample, uniform sample without replacement, and MDSample with replacement. Particularly, if 'available' is in self.sample_option, the server will only sample from currently available clients.</p> <p>Returns:</p> Type Description <p>a list of the ids of the selected clients</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; selected_clients=self.sample()\n    &gt;&gt;&gt; selected_clients\n    &gt;&gt;&gt; # The selected_clients is a list of clients' ids\n</code></pre> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def sample(self):\nr\"\"\"\n    Sample the clients. There are three types of sampling manners:\n    full sample, uniform sample without replacement, and MDSample\n    with replacement. Particularly, if 'available' is in self.sample_option,\n    the server will only sample from currently available clients.\n\n    Returns:\n        a list of the ids of the selected clients\n\n    Example:\n    ```python\n        &gt;&gt;&gt; selected_clients=self.sample()\n        &gt;&gt;&gt; selected_clients\n        &gt;&gt;&gt; # The selected_clients is a list of clients' ids\n    ```\n    \"\"\"\n    all_clients = self.available_clients if 'available' in self.sample_option else [cid for cid in\n                                                                                    range(self.num_clients)]\n    # full sampling with unlimited communication resources of the server\n    if 'full' in self.sample_option:\n        return all_clients\n    # sample clients\n    elif 'uniform' in self.sample_option:\n        # original sample proposed by fedavg\n        selected_clients = list(\n            np.random.choice(all_clients, min(self.clients_per_round, len(all_clients)), replace=False)) if len(\n            all_clients) &gt; 0 else []\n    elif 'md' in self.sample_option:\n        # the default setting that is introduced by FedProx, where the clients are sampled with the probability in proportion to their local_movielens_recommendation data sizes\n        local_data_vols = [self.clients[cid].datavol for cid in all_clients]\n        total_data_vol = sum(local_data_vols)\n        p = np.array(local_data_vols) / total_data_vol\n        selected_clients = list(np.random.choice(all_clients, self.clients_per_round, replace=True, p=p)) if len(\n            all_clients) &gt; 0 else []\n    return selected_clients\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.set_tolerance_for_latency","title":"<code>set_tolerance_for_latency(tolerance)</code>","text":"<p>Set the tolerance for latency of waiting for clients' responses</p> <p>Parameters:</p> Name Type Description Default <code>tolerance</code> <code>int</code> <p>the amounts of virtual time units</p> required Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def set_tolerance_for_latency(self, tolerance:int):\nr\"\"\"\n    Set the tolerance for latency of waiting for clients' responses\n\n    Args:\n        tolerance (int): the amounts of virtual time units\n    \"\"\"\n    self.tolerance_for_latency = tolerance\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.test","title":"<code>test(model=None, flag='test')</code>","text":"<p>Evaluate the model on the test dataset owned by the server.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>flgo.utils.fmodule.FModule</code> <p>the model need to be evaluated</p> <code>None</code> <code>flag</code> <code>str</code> <p>choose the data to evaluate the model</p> <code>'test'</code> <p>Returns:</p> Name Type Description <code>metrics</code> <code>dict</code> <p>the dict contains the evaluating results</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def test(self, model=None, flag:str='test'):\nr\"\"\"\n    Evaluate the model on the test dataset owned by the server.\n\n    Args:\n        model (flgo.utils.fmodule.FModule): the model need to be evaluated\n        flag (str): choose the data to evaluate the model\n\n    Returns:\n        metrics (dict): the dict contains the evaluating results\n    \"\"\"\n    if model is None: model = self.model\n    dataset = getattr(self, flag+'_data') if hasattr(self, flag+'_data') else None\n    if dataset is None:\n        return {}\n    else:\n        return self.calculator.test(model, dataset, batch_size=min(self.option['test_batch_size'], len(dataset)),\n                                    num_workers=self.option['num_workers'], pin_memory=self.option['pin_memory'])\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.unpack","title":"<code>unpack(packages_received_from_clients)</code>","text":"<p>Unpack the information from the received packages. Return models and losses as default.</p> <p>Parameters:</p> Name Type Description Default <code>packages_received_from_clients</code> <code>list</code> <p>a list of packages</p> required <p>Returns:</p> Name Type Description <code>res</code> <code>dict</code> <p>collections.defaultdict that contains several lists of the clients' reply</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def unpack(self, packages_received_from_clients):\nr\"\"\"\n    Unpack the information from the received packages. Return models and losses as default.\n\n    Args:\n        packages_received_from_clients (list): a list of packages\n\n    Returns:\n        res (dict): collections.defaultdict that contains several lists of the clients' reply\n    \"\"\"\n    if len(packages_received_from_clients) == 0: return collections.defaultdict(list)\n    res = {pname: [] for pname in packages_received_from_clients[0]}\n    for cpkg in packages_received_from_clients:\n        for pname, pval in cpkg.items():\n            res[pname].append(pval)\n    return res\n</code></pre>"},{"location":"Docs/algorithm/fedbase/#flgo.algorithm.fedbase.BasicServer.wait_time","title":"<code>wait_time(t=1)</code>","text":"<p>Wait for the time of the virtual clock to pass t units</p> Source code in <code>flgo\\algorithm\\fedbase.py</code> <pre><code>def wait_time(self, t=1):\nr\"\"\"\n    Wait for the time of the virtual clock to pass t units\n    \"\"\"\n    ss.clock.step(t)\n    return\n</code></pre>"},{"location":"Docs/algorithm/vflbase/","title":"flgo.algorithm.vflbase","text":""},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty","title":"<code>ActiveParty</code>","text":"<p>         Bases: <code>PassiveParty</code></p> <p>This is the implementation of the active party in vertival FL. The active party owns the data label information and may also own parts of data features. If a active party owns data features, it is also a passive party simultaneously.</p> <p>Parameters:</p> Name Type Description Default <code>option</code> <code>dict</code> <p>running-time option</p> required Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>class ActiveParty(PassiveParty):\nr\"\"\"\n    This is the implementation of the active party in vertival FL. The active party owns\n    the data label information and may also own parts of data features. If a active party owns\n    data features, it is also a passive party simultaneously.\n\n    Args:\n        option (dict): running-time option\n    \"\"\"\n    def __init__(self, option):\n        super().__init__(option)\n        self.actions = {0: self.forward, 1: self.backward,2:self.forward_test}\n        self.device = torch.device('cpu') if option['server_with_cpu'] else self.gv.apply_for_device()\n        self.calculator = self.gv.TaskCalculator(self.device, optimizer_name = option['optimizer'])\n        # basic configuration\n        self.task = option['task']\n        self.eval_interval = option['eval_interval']\n        self.num_parallels = option['num_parallels']\n        # hyper-parameters during training process\n        self.num_rounds = option['num_rounds']\n        self.proportion = option['proportion']\n        self.batch_size = option['batch_size']\n        self.decay_rate = option['learning_rate_decay']\n        self.lr_scheduler_type = option['lr_scheduler']\n        self.lr = option['learning_rate']\n        self.sample_option = option['sample']\n        self.aggregation_option = option['aggregate']\n        # systemic option\n        self.tolerance_for_latency = 999999\n        self.sending_package_buffer = [None for _ in range(9999)]\n        # algorithm-dependent parameters\n        self.algo_para = {}\n        self.current_round = 1\n        # all options\n        self.option = option\n        self.id = 0\n\n    def communicate(self, selected_clients, mtype=0, asynchronous=False):\n\"\"\"\n        The whole simulating communication procedure with the selected clients.\n        This part supports for simulating the client dropping out.\n        Args:\n            selected_clients: the clients to communicate with\n        Returns:\n            :the unpacked response from clients that is created ny self.unpack()\n        \"\"\"\n        packages_received_from_clients = []\n        received_package_buffer = {}\n        communicate_clients = list(set(selected_clients))\n        # prepare packages for clients\n        for cid in communicate_clients:\n            received_package_buffer[cid] = None\n        # communicate with selected clients\n        if self.num_parallels &lt;= 1:\n            # computing iteratively\n            for client_id in communicate_clients:\n                server_pkg = self.pack(client_id, mtype=mtype)\n                server_pkg['__mtype__'] = mtype\n                response_from_client_id = self.communicate_with(client_id, package=server_pkg)\n                packages_received_from_clients.append(response_from_client_id)\n        else:\n            # computing in parallel with torch.multiprocessing\n            pool = mp.Pool(self.num_parallels)\n            for client_id in communicate_clients:\n                server_pkg = self.pack(client_id, mtype=mtype)\n                server_pkg['__mtype__'] = mtype\n                self.clients[client_id].update_device(self.gv.apply_for_device())\n                args = (int(client_id), server_pkg)\n                packages_received_from_clients.append(pool.apply_async(self.communicate_with, args=args))\n            pool.close()\n            pool.join()\n            packages_received_from_clients = list(map(lambda x: x.get(), packages_received_from_clients))\n        for i,cid in enumerate(communicate_clients): received_package_buffer[cid] = packages_received_from_clients[i]\n        packages_received_from_clients = [received_package_buffer[cid] for cid in selected_clients if received_package_buffer[cid]]\n        self.received_clients = selected_clients\n        return self.unpack(packages_received_from_clients)\n\n    def unpack(self, packages_received_from_clients):\n\"\"\"\n        Unpack the information from the received packages. Return models and losses as default.\n        Args:\n            packages_received_from_clients (list of dict):\n        Returns:\n            res (dict): collections.defaultdict that contains several lists of the clients' reply\n        \"\"\"\n        if len(packages_received_from_clients)==0: return collections.defaultdict(list)\n        res = {pname:[] for pname in packages_received_from_clients[0]}\n        for cpkg in packages_received_from_clients:\n            for pname, pval in cpkg.items():\n                res[pname].append(pval)\n        return res\n\n    def run(self):\n\"\"\"\n        Start the federated learning symtem where the global model is trained iteratively.\n        \"\"\"\n        self.gv.logger.time_start('Total Time Cost')\n        self.gv.logger.info(\"--------------Initial Evaluation--------------\")\n        self.gv.logger.time_start('Eval Time Cost')\n        self.gv.logger.log_once()\n        self.gv.logger.time_end('Eval Time Cost')\n        while self.current_round &lt;= self.num_rounds:\n            # iterate\n            updated = self.iterate()\n            # using logger to evaluate the model if the model is updated\n            if updated is True or updated is None:\n                self.gv.logger.info(\"--------------Round {}--------------\".format(self.current_round))\n                # check log interval\n                if self.gv.logger.check_if_log(self.current_round, self.eval_interval):\n                    self.gv.logger.time_start('Eval Time Cost')\n                    self.gv.logger.log_once()\n                    self.gv.logger.time_end('Eval Time Cost')\n                self.current_round += 1\n        self.gv.logger.info(\"=================End==================\")\n        self.gv.logger.time_end('Total Time Cost')\n        # save results as .json file\n        self.gv.logger.save_output_as_json()\n        return\n\n    def iterate(self):\nr\"\"\"\n        The standard VFL process.\n\n         1. The active party first generates the batch information.\n\n         2. Then, it collects activations from all the passive parties.\n\n         3. Thirdly, it continues the forward passing and backward passing to update the decoder part of the model, and distributes the derivations to parties.\n\n         4. Finally, each passive party will update its local_movielens_recommendation modules accoring to the derivations and activations.\n\n        Returns:\n            updated (bool): whether the model is updated in this iteration\n        \"\"\"\n        self._data_type='train'\n        self.crt_batch = self.get_batch_data()\n        activations = self.communicate([p.id for p in self.parties], mtype=0)['activation']\n        self.defusions = self.update_global_module(activations, self.global_module)\n        _ = self.communicate([pid for pid in range(len(self.parties))], mtype=1)\n        return True\n\n    def pack(self, party_id, mtype=0):\nr\"\"\"\n        Pack the necessary information to parties into packages.\n\n        Args:\n            party_id (int): the id of the party\n            mtype (Any): the message type\n\n        Returns:\n            package (dict): the package\n        \"\"\"\n        if mtype==0:\n            return {'batch': self.crt_batch[2], 'data_type': self._data_type}\n        elif mtype==1:\n            return {'derivation': self.defusion[party_id]}\n        elif mtype==2:\n            return {'batch': self.crt_test_batch[2], 'data_type': self._data_type}\n\n    def get_batch_data(self):\n\"\"\"\n        Get the batch of data\n        Returns:\n            batch_data (Any): a batch of data\n        \"\"\"\n        try:\n            batch_data = next(self.data_loader)\n        except:\n            self.data_loader = iter(self.calculator.get_dataloader(self.train_data, batch_size=self.batch_size))\n            batch_data = next(self.data_loader)\n        return batch_data\n\n    def update_global_module(self, activations:list, model:torch.nn.Module|flgo.utils.fmodule.FModule):\nr\"\"\"\n        Update the global module by computing the forward passing and the backward passing. The attribute\n        self.defusion and self.fusion.grad will be changed after calling this method.\n\n        Args:\n            activations (list): a list of activations from all the passive parties\n            model (torch.nn.Module|flgo.utils.fmodule.FModule): the model\n        \"\"\"\n        self.fusion = self.fuse(activations)\n        self.fusion.requires_grad=True\n        optimizer = self.calculator.get_optimizer(self.global_module, lr=self.lr)\n        loss = self.calculator.compute_loss(model, (self.fusion, self.crt_batch[1]))['loss']\n        loss.backward()\n        optimizer.step()\n        self.defusion = self.defuse(self.fusion)\n\n    def fuse(self, activations:list):\nr\"\"\"\n        Fuse the activations into one.\n\n        Args:\n            activations (list): a list of activations from all the passive parties\n\n        Returns:\n            fusion (Any): the fused result\n        \"\"\"\n        return torch.stack(activations).mean(dim=0)\n\n    def defuse(self, fusion):\nr\"\"\"\n        Defuse the fusion into derivations.\n\n        Args:\n            fusion (Any): the fused result\n\n        Returns:\n            derivations (list): a list of derivations\n        \"\"\"\n        return [fusion.grad for _ in self.parties]\n\n    def test(self, flag:str='test') -&gt; dict:\nr\"\"\"\n        Test the performance of the model\n\n        Args:\n            flag (str): the type of dataset\n\n        Returns:\n            result (dict): a dict that contains the testing result\n        \"\"\"\n        self.set_model_mode('eval')\n        flag_dict = {'test':self.test_data, 'train':self.train_data, 'val':self.val_data}\n        dataset = flag_dict[flag]\n        self._data_type = flag\n        dataloader = self.calculator.get_dataloader(dataset, batch_size=128)\n        total_loss = 0.0\n        num_correct = 0\n        for batch_id, batch_data in enumerate(dataloader):\n            self.crt_test_batch = batch_data\n            activations = self.communicate([pid for pid in range(len(self.parties))], mtype=2)['activation']\n            fusion = self.fuse(activations)\n            outputs = self.global_module(fusion.to(self.device))\n            batch_mean_loss = self.calculator.criterion(outputs, batch_data[1].to(self.device)).item()\n            y_pred = outputs.data.max(1, keepdim=True)[1].cpu()\n            correct = y_pred.eq(batch_data[1].data.view_as(y_pred)).long().cpu().sum()\n            num_correct += correct.item()\n            total_loss += batch_mean_loss * len(batch_data[1])\n        self.set_model_mode('train')\n        return {'accuracy': 1.0 * num_correct / len(dataset), 'loss': total_loss / len(dataset)}\n\n    def set_model_mode(self,mode = 'train'):\nr\"\"\"\n        Set all the modes of the modules owned by all the parties.\n\n        Args:\n            mode (str): the mode of models\n        \"\"\"\n        for party in self.parties:\n            if hasattr(party, 'local_module') and party.local_module is not None:\n                if mode == 'train':\n                    party.local_module.train()\n                else:\n                    party.local_module.eval()\n            if hasattr(party, 'global_module') and party.global_module is not None:\n                if mode == 'train':\n                    party.global_module.train()\n                else:\n                    party.global_module.eval()\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.communicate","title":"<code>communicate(selected_clients, mtype=0, asynchronous=False)</code>","text":"<p>The whole simulating communication procedure with the selected clients. This part supports for simulating the client dropping out.</p> <p>Parameters:</p> Name Type Description Default <code>selected_clients</code> <p>the clients to communicate with</p> required <p>Returns:</p> Type Description <p>the unpacked response from clients that is created ny self.unpack()</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def communicate(self, selected_clients, mtype=0, asynchronous=False):\n\"\"\"\n    The whole simulating communication procedure with the selected clients.\n    This part supports for simulating the client dropping out.\n    Args:\n        selected_clients: the clients to communicate with\n    Returns:\n        :the unpacked response from clients that is created ny self.unpack()\n    \"\"\"\n    packages_received_from_clients = []\n    received_package_buffer = {}\n    communicate_clients = list(set(selected_clients))\n    # prepare packages for clients\n    for cid in communicate_clients:\n        received_package_buffer[cid] = None\n    # communicate with selected clients\n    if self.num_parallels &lt;= 1:\n        # computing iteratively\n        for client_id in communicate_clients:\n            server_pkg = self.pack(client_id, mtype=mtype)\n            server_pkg['__mtype__'] = mtype\n            response_from_client_id = self.communicate_with(client_id, package=server_pkg)\n            packages_received_from_clients.append(response_from_client_id)\n    else:\n        # computing in parallel with torch.multiprocessing\n        pool = mp.Pool(self.num_parallels)\n        for client_id in communicate_clients:\n            server_pkg = self.pack(client_id, mtype=mtype)\n            server_pkg['__mtype__'] = mtype\n            self.clients[client_id].update_device(self.gv.apply_for_device())\n            args = (int(client_id), server_pkg)\n            packages_received_from_clients.append(pool.apply_async(self.communicate_with, args=args))\n        pool.close()\n        pool.join()\n        packages_received_from_clients = list(map(lambda x: x.get(), packages_received_from_clients))\n    for i,cid in enumerate(communicate_clients): received_package_buffer[cid] = packages_received_from_clients[i]\n    packages_received_from_clients = [received_package_buffer[cid] for cid in selected_clients if received_package_buffer[cid]]\n    self.received_clients = selected_clients\n    return self.unpack(packages_received_from_clients)\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.defuse","title":"<code>defuse(fusion)</code>","text":"<p>Defuse the fusion into derivations.</p> <p>Parameters:</p> Name Type Description Default <code>fusion</code> <code>Any</code> <p>the fused result</p> required <p>Returns:</p> Name Type Description <code>derivations</code> <code>list</code> <p>a list of derivations</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def defuse(self, fusion):\nr\"\"\"\n    Defuse the fusion into derivations.\n\n    Args:\n        fusion (Any): the fused result\n\n    Returns:\n        derivations (list): a list of derivations\n    \"\"\"\n    return [fusion.grad for _ in self.parties]\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.fuse","title":"<code>fuse(activations)</code>","text":"<p>Fuse the activations into one.</p> <p>Parameters:</p> Name Type Description Default <code>activations</code> <code>list</code> <p>a list of activations from all the passive parties</p> required <p>Returns:</p> Name Type Description <code>fusion</code> <code>Any</code> <p>the fused result</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def fuse(self, activations:list):\nr\"\"\"\n    Fuse the activations into one.\n\n    Args:\n        activations (list): a list of activations from all the passive parties\n\n    Returns:\n        fusion (Any): the fused result\n    \"\"\"\n    return torch.stack(activations).mean(dim=0)\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.get_batch_data","title":"<code>get_batch_data()</code>","text":"<p>Get the batch of data</p> <p>Returns:</p> Name Type Description <code>batch_data</code> <code>Any</code> <p>a batch of data</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def get_batch_data(self):\n\"\"\"\n    Get the batch of data\n    Returns:\n        batch_data (Any): a batch of data\n    \"\"\"\n    try:\n        batch_data = next(self.data_loader)\n    except:\n        self.data_loader = iter(self.calculator.get_dataloader(self.train_data, batch_size=self.batch_size))\n        batch_data = next(self.data_loader)\n    return batch_data\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.iterate","title":"<code>iterate()</code>","text":"<p>The standard VFL process.</p> <ol> <li> <p>The active party first generates the batch information.</p> </li> <li> <p>Then, it collects activations from all the passive parties.</p> </li> <li> <p>Thirdly, it continues the forward passing and backward passing to update the decoder part of the model, and distributes the derivations to parties.</p> </li> <li> <p>Finally, each passive party will update its local_movielens_recommendation modules accoring to the derivations and activations.</p> </li> </ol> <p>Returns:</p> Name Type Description <code>updated</code> <code>bool</code> <p>whether the model is updated in this iteration</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def iterate(self):\nr\"\"\"\n    The standard VFL process.\n\n     1. The active party first generates the batch information.\n\n     2. Then, it collects activations from all the passive parties.\n\n     3. Thirdly, it continues the forward passing and backward passing to update the decoder part of the model, and distributes the derivations to parties.\n\n     4. Finally, each passive party will update its local_movielens_recommendation modules accoring to the derivations and activations.\n\n    Returns:\n        updated (bool): whether the model is updated in this iteration\n    \"\"\"\n    self._data_type='train'\n    self.crt_batch = self.get_batch_data()\n    activations = self.communicate([p.id for p in self.parties], mtype=0)['activation']\n    self.defusions = self.update_global_module(activations, self.global_module)\n    _ = self.communicate([pid for pid in range(len(self.parties))], mtype=1)\n    return True\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.pack","title":"<code>pack(party_id, mtype=0)</code>","text":"<p>Pack the necessary information to parties into packages.</p> <p>Parameters:</p> Name Type Description Default <code>party_id</code> <code>int</code> <p>the id of the party</p> required <code>mtype</code> <code>Any</code> <p>the message type</p> <code>0</code> <p>Returns:</p> Name Type Description <code>package</code> <code>dict</code> <p>the package</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def pack(self, party_id, mtype=0):\nr\"\"\"\n    Pack the necessary information to parties into packages.\n\n    Args:\n        party_id (int): the id of the party\n        mtype (Any): the message type\n\n    Returns:\n        package (dict): the package\n    \"\"\"\n    if mtype==0:\n        return {'batch': self.crt_batch[2], 'data_type': self._data_type}\n    elif mtype==1:\n        return {'derivation': self.defusion[party_id]}\n    elif mtype==2:\n        return {'batch': self.crt_test_batch[2], 'data_type': self._data_type}\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.run","title":"<code>run()</code>","text":"<p>Start the federated learning symtem where the global model is trained iteratively.</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def run(self):\n\"\"\"\n    Start the federated learning symtem where the global model is trained iteratively.\n    \"\"\"\n    self.gv.logger.time_start('Total Time Cost')\n    self.gv.logger.info(\"--------------Initial Evaluation--------------\")\n    self.gv.logger.time_start('Eval Time Cost')\n    self.gv.logger.log_once()\n    self.gv.logger.time_end('Eval Time Cost')\n    while self.current_round &lt;= self.num_rounds:\n        # iterate\n        updated = self.iterate()\n        # using logger to evaluate the model if the model is updated\n        if updated is True or updated is None:\n            self.gv.logger.info(\"--------------Round {}--------------\".format(self.current_round))\n            # check log interval\n            if self.gv.logger.check_if_log(self.current_round, self.eval_interval):\n                self.gv.logger.time_start('Eval Time Cost')\n                self.gv.logger.log_once()\n                self.gv.logger.time_end('Eval Time Cost')\n            self.current_round += 1\n    self.gv.logger.info(\"=================End==================\")\n    self.gv.logger.time_end('Total Time Cost')\n    # save results as .json file\n    self.gv.logger.save_output_as_json()\n    return\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.set_model_mode","title":"<code>set_model_mode(mode='train')</code>","text":"<p>Set all the modes of the modules owned by all the parties.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>the mode of models</p> <code>'train'</code> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def set_model_mode(self,mode = 'train'):\nr\"\"\"\n    Set all the modes of the modules owned by all the parties.\n\n    Args:\n        mode (str): the mode of models\n    \"\"\"\n    for party in self.parties:\n        if hasattr(party, 'local_module') and party.local_module is not None:\n            if mode == 'train':\n                party.local_module.train()\n            else:\n                party.local_module.eval()\n        if hasattr(party, 'global_module') and party.global_module is not None:\n            if mode == 'train':\n                party.global_module.train()\n            else:\n                party.global_module.eval()\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.test","title":"<code>test(flag='test')</code>","text":"<p>Test the performance of the model</p> <p>Parameters:</p> Name Type Description Default <code>flag</code> <code>str</code> <p>the type of dataset</p> <code>'test'</code> <p>Returns:</p> Name Type Description <code>result</code> <code>dict</code> <p>a dict that contains the testing result</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def test(self, flag:str='test') -&gt; dict:\nr\"\"\"\n    Test the performance of the model\n\n    Args:\n        flag (str): the type of dataset\n\n    Returns:\n        result (dict): a dict that contains the testing result\n    \"\"\"\n    self.set_model_mode('eval')\n    flag_dict = {'test':self.test_data, 'train':self.train_data, 'val':self.val_data}\n    dataset = flag_dict[flag]\n    self._data_type = flag\n    dataloader = self.calculator.get_dataloader(dataset, batch_size=128)\n    total_loss = 0.0\n    num_correct = 0\n    for batch_id, batch_data in enumerate(dataloader):\n        self.crt_test_batch = batch_data\n        activations = self.communicate([pid for pid in range(len(self.parties))], mtype=2)['activation']\n        fusion = self.fuse(activations)\n        outputs = self.global_module(fusion.to(self.device))\n        batch_mean_loss = self.calculator.criterion(outputs, batch_data[1].to(self.device)).item()\n        y_pred = outputs.data.max(1, keepdim=True)[1].cpu()\n        correct = y_pred.eq(batch_data[1].data.view_as(y_pred)).long().cpu().sum()\n        num_correct += correct.item()\n        total_loss += batch_mean_loss * len(batch_data[1])\n    self.set_model_mode('train')\n    return {'accuracy': 1.0 * num_correct / len(dataset), 'loss': total_loss / len(dataset)}\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.unpack","title":"<code>unpack(packages_received_from_clients)</code>","text":"<p>Unpack the information from the received packages. Return models and losses as default.</p> <p>Parameters:</p> Name Type Description Default <code>packages_received_from_clients</code> <code>list of dict</code> required <p>Returns:</p> Name Type Description <code>res</code> <code>dict</code> <p>collections.defaultdict that contains several lists of the clients' reply</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def unpack(self, packages_received_from_clients):\n\"\"\"\n    Unpack the information from the received packages. Return models and losses as default.\n    Args:\n        packages_received_from_clients (list of dict):\n    Returns:\n        res (dict): collections.defaultdict that contains several lists of the clients' reply\n    \"\"\"\n    if len(packages_received_from_clients)==0: return collections.defaultdict(list)\n    res = {pname:[] for pname in packages_received_from_clients[0]}\n    for cpkg in packages_received_from_clients:\n        for pname, pval in cpkg.items():\n            res[pname].append(pval)\n    return res\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.ActiveParty.update_global_module","title":"<code>update_global_module(activations, model)</code>","text":"<p>Update the global module by computing the forward passing and the backward passing. The attribute self.defusion and self.fusion.grad will be changed after calling this method.</p> <p>Parameters:</p> Name Type Description Default <code>activations</code> <code>list</code> <p>a list of activations from all the passive parties</p> required <code>model</code> <code>torch.nn.Module | flgo.utils.fmodule.FModule</code> <p>the model</p> required Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def update_global_module(self, activations:list, model:torch.nn.Module|flgo.utils.fmodule.FModule):\nr\"\"\"\n    Update the global module by computing the forward passing and the backward passing. The attribute\n    self.defusion and self.fusion.grad will be changed after calling this method.\n\n    Args:\n        activations (list): a list of activations from all the passive parties\n        model (torch.nn.Module|flgo.utils.fmodule.FModule): the model\n    \"\"\"\n    self.fusion = self.fuse(activations)\n    self.fusion.requires_grad=True\n    optimizer = self.calculator.get_optimizer(self.global_module, lr=self.lr)\n    loss = self.calculator.compute_loss(model, (self.fusion, self.crt_batch[1]))['loss']\n    loss.backward()\n    optimizer.step()\n    self.defusion = self.defuse(self.fusion)\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.PassiveParty","title":"<code>PassiveParty</code>","text":"<p>         Bases: <code>BasicParty</code></p> <p>This is the implementation of the passive party in vertival FL. The passive party owns only a part of data features without label information.</p> <p>Parameters:</p> Name Type Description Default <code>option</code> <code>dict</code> <p>running-time option</p> required Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>class PassiveParty(BasicParty):\nr\"\"\"This is the implementation of the passive party in vertival FL.\n    The passive party owns only a part of data features without label information.\n\n    Args:\n        option (dict): running-time option\n    \"\"\"\n    def __init__(self, option:dict):\n        super().__init__()\n        self.option = option\n        self.actions = {0: self.forward, 1:self.backward, 2:self.forward_test}\n        self.id = None\n        # create local_movielens_recommendation dataset\n        self.data_loader = None\n        # local_movielens_recommendation calculator\n        self.device = self.gv.apply_for_device()\n        self.calculator = self.gv.TaskCalculator(self.device, option['optimizer'])\n        # hyper-parameters for training\n        self.optimizer_name = option['optimizer']\n        self.lr = option['learning_rate']\n        self.momentum = option['momentum']\n        self.weight_decay = option['weight_decay']\n        self.batch_size = option['batch_size']\n        self.num_steps = option['num_steps']\n        self.num_epochs = option['num_epochs']\n        self.model = None\n        self.test_batch_size = option['test_batch_size']\n        self.loader_num_workers = option['num_workers']\n        self.current_steps = 0\n        # system setting\n        self._effective_num_steps = self.num_steps\n        self._latency = 0\n\n    def forward(self, package:dict={}):\nr\"\"\"\n        Local forward to computing the activations on local_movielens_recommendation features\n\n        Args:\n            package (dict): the package from the active party that contains batch information and the type of data\n\n        Returns:\n            passive_package (dict): the package that contains the activation to be sent to the active party\n        \"\"\"\n        batch_ids = package['batch']\n        tmp = {'train': self.train_data, 'val': self.val_data, 'test':self.test_data}\n        dataset = tmp[package['data_type']]\n        # select samples in batch\n        self.activation = self.local_module(dataset.get_batch_by_id(batch_ids)[0].to(self.device))\n        return {'activation': self.activation.clone().detach()}\n\n    def backward(self, package):\nr\"\"\"\n        Local backward to computing the gradients on local_movielens_recommendation modules\n\n        Args:\n            package (dict): the package from the active party that contains the derivations\n        \"\"\"\n        derivation = package['derivation']\n        self.update_local_module(derivation, self.activation)\n        return\n\n    def update_local_module(self, derivation, activation):\nr\"\"\"\n        Update local_movielens_recommendation modules according to the derivation and the activation\n\n        Args:\n            derivation (Any): the derivation from the active party\n            activation (Any): the local_movielens_recommendation computed activation\n        \"\"\"\n        optimizer = self.calculator.get_optimizer(self.local_module, self.lr)\n        loss_surrogat = (derivation*activation).sum()\n        loss_surrogat.backward()\n        optimizer.step()\n        return\n\n    def forward_test(self, package):\nr\"\"\"\n        Local forward to computing the activations on local_movielens_recommendation features for testing\n\n        Args:\n            package (dict): the package from the active party that contains batch information and the type of data\n\n        Returns:\n            passive_package (dict): the package that contains the activation to be sent to the active party\n        \"\"\"\n        batch_ids = package['batch']\n        tmp = {'train': self.train_data, 'val': self.val_data, 'test':self.test_data}\n        dataset = tmp[package['data_type']]\n        # select samples in batch\n        self.activation = self.local_module(dataset.get_batch_by_id(batch_ids)[0].to(self.device))\n        return {'activation': self.activation}\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.PassiveParty.backward","title":"<code>backward(package)</code>","text":"<p>Local backward to computing the gradients on local_movielens_recommendation modules</p> <p>Parameters:</p> Name Type Description Default <code>package</code> <code>dict</code> <p>the package from the active party that contains the derivations</p> required Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def backward(self, package):\nr\"\"\"\n    Local backward to computing the gradients on local_movielens_recommendation modules\n\n    Args:\n        package (dict): the package from the active party that contains the derivations\n    \"\"\"\n    derivation = package['derivation']\n    self.update_local_module(derivation, self.activation)\n    return\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.PassiveParty.forward","title":"<code>forward(package={})</code>","text":"<p>Local forward to computing the activations on local_movielens_recommendation features</p> <p>Parameters:</p> Name Type Description Default <code>package</code> <code>dict</code> <p>the package from the active party that contains batch information and the type of data</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>passive_package</code> <code>dict</code> <p>the package that contains the activation to be sent to the active party</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def forward(self, package:dict={}):\nr\"\"\"\n    Local forward to computing the activations on local_movielens_recommendation features\n\n    Args:\n        package (dict): the package from the active party that contains batch information and the type of data\n\n    Returns:\n        passive_package (dict): the package that contains the activation to be sent to the active party\n    \"\"\"\n    batch_ids = package['batch']\n    tmp = {'train': self.train_data, 'val': self.val_data, 'test':self.test_data}\n    dataset = tmp[package['data_type']]\n    # select samples in batch\n    self.activation = self.local_module(dataset.get_batch_by_id(batch_ids)[0].to(self.device))\n    return {'activation': self.activation.clone().detach()}\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.PassiveParty.forward_test","title":"<code>forward_test(package)</code>","text":"<p>Local forward to computing the activations on local_movielens_recommendation features for testing</p> <p>Parameters:</p> Name Type Description Default <code>package</code> <code>dict</code> <p>the package from the active party that contains batch information and the type of data</p> required <p>Returns:</p> Name Type Description <code>passive_package</code> <code>dict</code> <p>the package that contains the activation to be sent to the active party</p> Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def forward_test(self, package):\nr\"\"\"\n    Local forward to computing the activations on local_movielens_recommendation features for testing\n\n    Args:\n        package (dict): the package from the active party that contains batch information and the type of data\n\n    Returns:\n        passive_package (dict): the package that contains the activation to be sent to the active party\n    \"\"\"\n    batch_ids = package['batch']\n    tmp = {'train': self.train_data, 'val': self.val_data, 'test':self.test_data}\n    dataset = tmp[package['data_type']]\n    # select samples in batch\n    self.activation = self.local_module(dataset.get_batch_by_id(batch_ids)[0].to(self.device))\n    return {'activation': self.activation}\n</code></pre>"},{"location":"Docs/algorithm/vflbase/#flgo.algorithm.vflbase.PassiveParty.update_local_module","title":"<code>update_local_module(derivation, activation)</code>","text":"<p>Update local_movielens_recommendation modules according to the derivation and the activation</p> <p>Parameters:</p> Name Type Description Default <code>derivation</code> <code>Any</code> <p>the derivation from the active party</p> required <code>activation</code> <code>Any</code> <p>the local_movielens_recommendation computed activation</p> required Source code in <code>flgo\\algorithm\\vflbase.py</code> <pre><code>def update_local_module(self, derivation, activation):\nr\"\"\"\n    Update local_movielens_recommendation modules according to the derivation and the activation\n\n    Args:\n        derivation (Any): the derivation from the active party\n        activation (Any): the local_movielens_recommendation computed activation\n    \"\"\"\n    optimizer = self.calculator.get_optimizer(self.local_module, self.lr)\n    loss_surrogat = (derivation*activation).sum()\n    loss_surrogat.backward()\n    optimizer.step()\n    return\n</code></pre>"},{"location":"Docs/benchmark/","title":"Index","text":""},{"location":"Docs/benchmark/#flgo.benchmark","title":"<code>flgo.benchmark</code>","text":"<p>This module is designed for fast creating federated tasks. For example, in FL, a commonly used benchmark is federated MNIST that splits MNIST into 100 shards and each shard contains data of two types of labels.</p> <p>In FLGo, three basic components are created to describe a general procedure that can easily convert various ML tasks into federated ones.</p> Components <ul> <li> <p><code>TaskGenerator</code></p> <ul> <li>load the original dataset</li> <li>partition the original dataset into local_movielens_recommendation data</li> </ul> </li> <li> <p><code>TaskPipe</code></p> <ul> <li>store the partition information of TaskGenerator into the disk     when generating federated tasks</li> <li>load the original dataset and the partition information to     create the federated scenario when optimizing models</li> </ul> </li> <li> <p><code>TaskCalculator</code></p> <ul> <li>support task-specific computation when optimizing models, such     as putting data into device, computing loss, evaluating models,     and creating the data loader</li> </ul> </li> </ul> <p>The architecture of a complete federate benchmark is shown as follows:</p> <pre><code>benchmark_name                  # benchmark folder\n\u251c\u2500 core.py                      # core file\n\u2502   \u251c\u2500 TaskGenerator            # class TaskGenerator(...)\n\u2502   \u251c\u2500 TaskPipe                 # class TaskPipe(...)\n\u2502   \u2514\u2500 TaskCalculator           # class TaskCalculator(...)\n\u2502\n\u251c\u2500  model                       # model folder (i.e. contains various types of models)\n\u2502   \u251c\u2500 model1_name.py           # model 1 (e.g. CNN)\n\u2502   \u251c\u2500 ...\n\u2502   \u2514\u2500 modelN_name.py           # model N (e.g. ResNet)\n\u2502       \u251c\u2500 init_local_module    # the function initializes personal models for parties\n\u2502       \u2514\u2500 init_global_module   # the function initializes the global models for parties\n\u2502\n\u2514\u2500 __init__.py                  # containing the variable default_model\n</code></pre> <p>Example: The architecture of MNIST is</p> <pre><code>\u251c\u2500 core.py\n\u2502   \u251c\u2500 TaskGenerator\n\u2502   \u251c\u2500 TaskPipe\n\u2502   \u2514\u2500 TaskCalculator\n\u251c\u2500  model\n\u2502   \u251c\u2500 cnn.py\n\u2502   \u2514\u2500 mlp.py\n\u2502       \u251c\u2500 init_local_module\n\u2502       \u2514\u2500 init_global_module\n\u2514\u2500 __init__.py\n</code></pre> <p>The details of implementing a customized benchmark are in Tutorial.3</p>"},{"location":"Docs/benchmark/base/","title":"flgo.benchmark.base","text":""},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskCalculator","title":"<code>AbstractTaskCalculator</code>","text":"<p>Abstract Task Calculator</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>class AbstractTaskCalculator(metaclass=ABCMeta):\nr\"\"\"\n    Abstract Task Calculator\n    \"\"\"\n    @abstractmethod\n    def to_device(self, *args, **kwargs):\n\"\"\"Put the data into the gpu device\"\"\"\n        pass\n\n    @abstractmethod\n    def get_dataloader(self, *args, **kwargs):\n\"\"\"Return a data loader that splits the input data into batches\"\"\"\n        pass\n\n    @abstractmethod\n    def test(self, model, data, *args, **kwargs):\n\"\"\"Evaluate the model on the data\"\"\"\n        pass\n\n    @abstractmethod\n    def compute_loss(self, model, data, *args, **kwargs):\n\"\"\"Compute the loss of the model on the data to complete the forward process\"\"\"\n        pass\n\n    @abstractmethod\n    def get_optimizer(self, model, *args, **kwargs):\n\"\"\"Return the optimizer on the parameters of the model\"\"\"\n        pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskCalculator.compute_loss","title":"<code>compute_loss(model, data, *args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Compute the loss of the model on the data to complete the forward process</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef compute_loss(self, model, data, *args, **kwargs):\n\"\"\"Compute the loss of the model on the data to complete the forward process\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskCalculator.get_dataloader","title":"<code>get_dataloader(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return a data loader that splits the input data into batches</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef get_dataloader(self, *args, **kwargs):\n\"\"\"Return a data loader that splits the input data into batches\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskCalculator.get_optimizer","title":"<code>get_optimizer(model, *args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Return the optimizer on the parameters of the model</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef get_optimizer(self, model, *args, **kwargs):\n\"\"\"Return the optimizer on the parameters of the model\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskCalculator.test","title":"<code>test(model, data, *args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Evaluate the model on the data</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef test(self, model, data, *args, **kwargs):\n\"\"\"Evaluate the model on the data\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskCalculator.to_device","title":"<code>to_device(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Put the data into the gpu device</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef to_device(self, *args, **kwargs):\n\"\"\"Put the data into the gpu device\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskGenerator","title":"<code>AbstractTaskGenerator</code>","text":"<p>Abstract Task Generator</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>class AbstractTaskGenerator(metaclass=ABCMeta):\nr\"\"\"\n    Abstract Task Generator\n    \"\"\"\n    @abstractmethod\n    def load_data(self, *args, **kwarg):\n\"\"\"Load the original data into memory that can be partitioned\"\"\"\n        pass\n\n    @abstractmethod\n    def partition(self, *args, **kwarg):\n\"\"\"Partition the loaded data into subsets of data owned by clients\n        and the test data owned by the server\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def generate(self, *args, **kwarg):\n\"\"\"Load and partition the data, and then generate the necessary\n        information about the federated task (e.g. path, partition way, ...)\"\"\"\n        pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskGenerator.generate","title":"<code>generate(*args, **kwarg)</code>  <code>abstractmethod</code>","text":"<p>Load and partition the data, and then generate the necessary information about the federated task (e.g. path, partition way, ...)</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef generate(self, *args, **kwarg):\n\"\"\"Load and partition the data, and then generate the necessary\n    information about the federated task (e.g. path, partition way, ...)\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskGenerator.load_data","title":"<code>load_data(*args, **kwarg)</code>  <code>abstractmethod</code>","text":"<p>Load the original data into memory that can be partitioned</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef load_data(self, *args, **kwarg):\n\"\"\"Load the original data into memory that can be partitioned\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskGenerator.partition","title":"<code>partition(*args, **kwarg)</code>  <code>abstractmethod</code>","text":"<p>Partition the loaded data into subsets of data owned by clients and the test data owned by the server</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef partition(self, *args, **kwarg):\n\"\"\"Partition the loaded data into subsets of data owned by clients\n    and the test data owned by the server\n    \"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskPipe","title":"<code>AbstractTaskPipe</code>","text":"<p>Abstract Task Pipe</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>class AbstractTaskPipe(metaclass=ABCMeta):\nr\"\"\"\n    Abstract Task Pipe\n    \"\"\"\n    @abstractmethod\n    def save_task(self, *args, **kwargs):\n\"\"\"Save a federated task created by TaskGenerator as a static file on the disk\"\"\"\n        pass\n\n    @abstractmethod\n    def load_task(self, *args, **kwargs):\n\"\"\"Load a federated task from disk\"\"\"\n        pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskPipe.load_task","title":"<code>load_task(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Load a federated task from disk</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef load_task(self, *args, **kwargs):\n\"\"\"Load a federated task from disk\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.AbstractTaskPipe.save_task","title":"<code>save_task(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Save a federated task created by TaskGenerator as a static file on the disk</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>@abstractmethod\ndef save_task(self, *args, **kwargs):\n\"\"\"Save a federated task created by TaskGenerator as a static file on the disk\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskCalculator","title":"<code>BasicTaskCalculator</code>","text":"<p>         Bases: <code>AbstractTaskCalculator</code></p> <p>Support task-specific computation when optimizing models, such as putting data into device, computing loss, evaluating models, and creating the data loader</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>class BasicTaskCalculator(AbstractTaskCalculator):\nr\"\"\"\n    Support task-specific computation when optimizing models, such\n    as putting data into device, computing loss, evaluating models,\n    and creating the data loader\n    \"\"\"\n\n    def __init__(self, device, optimizer_name='sgd'):\nr\"\"\"\n        Args:\n            device (torch.device): device\n            optimizer_name (str): the name of the optimizer\n        \"\"\"\n        self.device = device\n        self.optimizer_name = optimizer_name\n        self.criterion = None\n        self.DataLoader = None\n        self.collect_fn = None\n\n    def to_device(self, data, *args, **kwargs):\n        return NotImplementedError\n\n    def get_dataloader(self, *args, **kwargs):\n        return NotImplementedError\n\n    def test(self, model, data, *args, **kwargs):\n        return NotImplementedError\n\n    def compute_loss(self, model, data, *args, **kwargs):\n        return NotImplementedError\n\n    def get_optimizer(self, model=None, lr=0.1, weight_decay=0, momentum=0):\nr\"\"\"\n        Create optimizer of the model parameters\n\n        Args:\n            model (torch.nn.Module): model\n            lr (float): learning rate\n            weight_decay (float): the weight_decay coefficient\n            momentum (float): the momentum coefficient\n\n        Returns:\n            the optimizer\n        \"\"\"\n        OPTIM = getattr(importlib.import_module('torch.optim'), self.optimizer_name)\n        filter_fn = filter(lambda p: p.requires_grad, model.parameters())\n        if self.optimizer_name.lower() == 'sgd':\n            return OPTIM(filter_fn, lr=lr, momentum=momentum, weight_decay=weight_decay)\n        elif self.optimizer_name.lower() in ['adam', 'rmsprop', 'adagrad']:\n            return OPTIM(filter_fn, lr=lr, weight_decay=weight_decay)\n        else:\n            raise RuntimeError(\"Invalid Optimizer.\")\n\n    def set_criterion(self, criterion:Callable)-&gt;None:\n        self.criterion = criterion\n\n    def set_collect_fn(self, collect_fn:Callable)-&gt;None:\n        self.collect_fn = collect_fn\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskCalculator.__init__","title":"<code>__init__(device, optimizer_name='sgd')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>device</p> required <code>optimizer_name</code> <code>str</code> <p>the name of the optimizer</p> <code>'sgd'</code> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def __init__(self, device, optimizer_name='sgd'):\nr\"\"\"\n    Args:\n        device (torch.device): device\n        optimizer_name (str): the name of the optimizer\n    \"\"\"\n    self.device = device\n    self.optimizer_name = optimizer_name\n    self.criterion = None\n    self.DataLoader = None\n    self.collect_fn = None\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskCalculator.get_optimizer","title":"<code>get_optimizer(model=None, lr=0.1, weight_decay=0, momentum=0)</code>","text":"<p>Create optimizer of the model parameters</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>torch.nn.Module</code> <p>model</p> <code>None</code> <code>lr</code> <code>float</code> <p>learning rate</p> <code>0.1</code> <code>weight_decay</code> <code>float</code> <p>the weight_decay coefficient</p> <code>0</code> <code>momentum</code> <code>float</code> <p>the momentum coefficient</p> <code>0</code> <p>Returns:</p> Type Description <p>the optimizer</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def get_optimizer(self, model=None, lr=0.1, weight_decay=0, momentum=0):\nr\"\"\"\n    Create optimizer of the model parameters\n\n    Args:\n        model (torch.nn.Module): model\n        lr (float): learning rate\n        weight_decay (float): the weight_decay coefficient\n        momentum (float): the momentum coefficient\n\n    Returns:\n        the optimizer\n    \"\"\"\n    OPTIM = getattr(importlib.import_module('torch.optim'), self.optimizer_name)\n    filter_fn = filter(lambda p: p.requires_grad, model.parameters())\n    if self.optimizer_name.lower() == 'sgd':\n        return OPTIM(filter_fn, lr=lr, momentum=momentum, weight_decay=weight_decay)\n    elif self.optimizer_name.lower() in ['adam', 'rmsprop', 'adagrad']:\n        return OPTIM(filter_fn, lr=lr, weight_decay=weight_decay)\n    else:\n        raise RuntimeError(\"Invalid Optimizer.\")\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskGenerator","title":"<code>BasicTaskGenerator</code>","text":"<p>         Bases: <code>AbstractTaskGenerator</code></p> <p>Load the original dataset and partition the original dataset into local_movielens_recommendation data</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>class BasicTaskGenerator(AbstractTaskGenerator):\nr\"\"\"\n        Load the original dataset and partition the\n        original dataset into local_movielens_recommendation data\n    \"\"\"\n    def __init__(self, benchmark:str, rawdata_path:str):\n\"\"\"\n        Args:\n            benchmark (str): the name of the federated task\n            rawdata_path (str): the dictionary of the original dataset\n        \"\"\"\n        # basic attribution\n        self.benchmark = benchmark\n        self.rawdata_path = rawdata_path\n        # optional attribution\n        self.partitioner = None\n        self.train_data = None\n        self.test_data = None\n        self.val_data = None\n        self.task_name = None\n        self.para = {}\n        self.additional_option = {}\n        self.train_additional_option = {}\n        self.test_additional_option = {}\n\n    def generate(self, *args, **kwarg):\n\"\"\"The whole process to generate federated task. \"\"\"\n        # load data\n        self.load_data()\n        # partition\n        self.partition()\n        # generate task name\n        self.task_name = self.get_task_name()\n        return\n\n    def load_data(self, *args, **kwargs):\n\"\"\"Download and load dataset into memory.\"\"\"\n        return\n\n    def partition(self, *args, **kwargs):\n\"\"\"Partition the data into different local_movielens_recommendation datasets\"\"\"\n        return\n\n    def register_partitioner(self, partitioner=None):\n\"\"\"Register the partitioner as self's data partitioner\"\"\"\n        self.partitioner = partitioner\n\n    def init_para(self, para_list=None):\n        pnames = list(self.para.keys())\n        if para_list is not None:\n            for i, pv in enumerate(para_list):\n                pname = pnames[i]\n                try:\n                    self.para[pname] = type(self.para[pname])(pv)\n                except:\n                    self.para[pname] = pv\n        for pname, pv in self.para.items():\n            self.__setattr__(pname, pv)\n        return\n\n    def get_task_name(self):\nr\"\"\"\n        Create the default name of the task\n        \"\"\"\n        if not hasattr(self.partitioner, 'num_parties') and hasattr(self.partitioner, 'num_clients'):\n            self.partitioner.num_parties = self.partitioner.num_clients\n        else: self.partitioner.num_parties = 'unknown'\n        return '_'.join(['B-' + self.benchmark, 'P-' + str(self.partitioner), 'N-' + str(self.partitioner.num_parties)])\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskGenerator.__init__","title":"<code>__init__(benchmark, rawdata_path)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>str</code> <p>the name of the federated task</p> required <code>rawdata_path</code> <code>str</code> <p>the dictionary of the original dataset</p> required Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def __init__(self, benchmark:str, rawdata_path:str):\n\"\"\"\n    Args:\n        benchmark (str): the name of the federated task\n        rawdata_path (str): the dictionary of the original dataset\n    \"\"\"\n    # basic attribution\n    self.benchmark = benchmark\n    self.rawdata_path = rawdata_path\n    # optional attribution\n    self.partitioner = None\n    self.train_data = None\n    self.test_data = None\n    self.val_data = None\n    self.task_name = None\n    self.para = {}\n    self.additional_option = {}\n    self.train_additional_option = {}\n    self.test_additional_option = {}\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskGenerator.generate","title":"<code>generate(*args, **kwarg)</code>","text":"<p>The whole process to generate federated task.</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def generate(self, *args, **kwarg):\n\"\"\"The whole process to generate federated task. \"\"\"\n    # load data\n    self.load_data()\n    # partition\n    self.partition()\n    # generate task name\n    self.task_name = self.get_task_name()\n    return\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskGenerator.get_task_name","title":"<code>get_task_name()</code>","text":"<p>Create the default name of the task</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def get_task_name(self):\nr\"\"\"\n    Create the default name of the task\n    \"\"\"\n    if not hasattr(self.partitioner, 'num_parties') and hasattr(self.partitioner, 'num_clients'):\n        self.partitioner.num_parties = self.partitioner.num_clients\n    else: self.partitioner.num_parties = 'unknown'\n    return '_'.join(['B-' + self.benchmark, 'P-' + str(self.partitioner), 'N-' + str(self.partitioner.num_parties)])\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskGenerator.load_data","title":"<code>load_data(*args, **kwargs)</code>","text":"<p>Download and load dataset into memory.</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def load_data(self, *args, **kwargs):\n\"\"\"Download and load dataset into memory.\"\"\"\n    return\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskGenerator.partition","title":"<code>partition(*args, **kwargs)</code>","text":"<p>Partition the data into different local_movielens_recommendation datasets</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def partition(self, *args, **kwargs):\n\"\"\"Partition the data into different local_movielens_recommendation datasets\"\"\"\n    return\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskGenerator.register_partitioner","title":"<code>register_partitioner(partitioner=None)</code>","text":"<p>Register the partitioner as self's data partitioner</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def register_partitioner(self, partitioner=None):\n\"\"\"Register the partitioner as self's data partitioner\"\"\"\n    self.partitioner = partitioner\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe","title":"<code>BasicTaskPipe</code>","text":"<p>         Bases: <code>AbstractTaskPipe</code></p> <p>Store the partition information of TaskGenerator into the disk when generating federated tasks.</p> <p>Load the original dataset and the partition information to create the federated scenario when optimizing models</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>class BasicTaskPipe(AbstractTaskPipe):\nr\"\"\"\n    Store the partition information of TaskGenerator into the disk\n    when generating federated tasks.\n\n    Load the original dataset and the partition information to\n    create the federated scenario when optimizing models\n    \"\"\"\n    TaskDataset = None\n\n    def __init__(self, task_path):\nr\"\"\"\n        Args:\n            task_path (str): the path of the federated task\n        \"\"\"\n        self.task_path = task_path\n        if os.path.exists(os.path.join(self.task_path, 'data.json')):\n            with open(os.path.join(self.task_path, 'data.json'), 'r') as inf:\n                self.feddata = json.load(inf)\n\n    def save_task(self, generator):\n\"\"\"Construct `feddata` and store it into the disk for recovering\n        the partitioned datasets again from it\"\"\"\n        raise NotImplementedError\n\n    def load_data(self, running_time_option) -&gt; dict:\n\"\"\"Load the data and process it to the format that can be distributed\n        to different objects\"\"\"\n        raise NotImplementedError\n\n    def generate_objects(self, running_time_option, algorithm, scene='horizontal') -&gt; list:\nr\"\"\"\n        Generate the virtual objects (i.e. coordinators and participants)\n        in the FL system\n\n        Args:\n            running_time_option (dict): the option (i.e. configuration)\n            algorithm (module|class): algorithm\n            scene (str): horizontal or vertical\n        \"\"\"\n        if scene=='horizontal':\n            # init clients\n            Client = algorithm.Client\n            clients = [Client(running_time_option) for _ in range(len(self.feddata['client_names']))]\n            for cid, c in enumerate(clients):\n                c.id = cid\n                c.name = self.feddata['client_names'][cid]\n            # init server\n            server = algorithm.Server(running_time_option)\n            server.name = 'server'\n            server.id = -1\n            # bind clients and server\n            server.register_clients(clients)\n            for c in clients: c.register_server(server)\n            # return objects as list\n            objects = [server]\n            objects.extend(clients)\n        elif scene=='vertical':\n            PassiveParty = algorithm.PassiveParty\n            ActiveParty = algorithm.ActiveParty\n            objects = []\n            for pid, pname in enumerate(self.feddata['party_names']):\n                is_active = self.feddata[pname]['data']['with_label']\n                obj = ActiveParty(running_time_option) if is_active else PassiveParty(running_time_option)\n                obj.id = pid\n                obj.name = pname\n                objects.append(obj)\n            for party in objects:\n                party.register_objects(objects)\n        elif scene=='hierarchical':\n            server = algorithm.Server(running_time_option)\n            server.id = -1\n            server.name = 'server'\n            edge_servers = [algorithm.EdgeServer(running_time_option) for _ in range(self.feddata['num_edge_servers'])]\n            for sid in range(len(edge_servers)):\n                edge_servers[sid].id = sid\n                edge_servers[sid].name = 'edge_server'+str(sid)\n                edge_servers[sid].clients = []\n            server.register_clients(edge_servers)\n            clients = [algorithm.Client(running_time_option) for _ in range(len(self.feddata['client_names']))]\n            edge_server_clients = [[] for _ in edge_servers]\n            for cid, c in enumerate(clients):\n                c.id = cid+len(edge_servers)\n                c.name = self.feddata['client_names'][cid]\n                edge_server_clients[self.feddata['client_group'][c.name]].append(c)\n            for edge_server, client_set in zip(edge_servers,edge_server_clients):\n                edge_server.register_clients(client_set)\n            objects = [server]\n            objects.extend(edge_servers)\n            objects.extend(clients)\n        elif scene=='decentralized':\n            # init clients\n            Client = algorithm.Client\n            clients = [Client(running_time_option) for _ in range(len(self.feddata['client_names']))]\n            for cid, c in enumerate(clients):\n                c.id = cid\n                c.name = self.feddata['client_names'][cid]\n            # init topology of clients\n            topology = self.feddata['topology']\n            for c in clients:\n                c.topology = topology\n            adjacent = self.feddata['adjacent']\n            for cid,c in enumerate(clients):\n                c.clients = [clients[k] for k,nid in enumerate(adjacent[cid]) if nid&gt;0]\n            # init protocol\n            protocol = algorithm.Protocol(running_time_option)\n            protocol.name = 'protocol'\n            # bind clients and server\n            protocol.clients = clients\n            # return objects as list\n            objects = [protocol]\n            objects.extend(clients)\n        return objects\n\n    def save_info(self, generator):\nr\"\"\"\n        Save the basic information of the generated task into the disk\n        \"\"\"\n        info = {'benchmark': '.'.join(generator.__module__.split('.')[:-1])}\n        info['scene'] = generator.scene if hasattr(generator, 'scene') else 'unknown'\n        info['num_clients'] = generator.num_clients if hasattr(generator, 'num_clients') else (generator.num_parties if hasattr(self, 'num_parties') else 'unknown')\n        with open(os.path.join(self.task_path, 'info'), 'w') as outf:\n            json.dump(info, outf)\n\n    def load_task(self, running_time_option, *args, **kwargs):\nr\"\"\"\n        Load the generated task into disk and create objects in the federated\n        scenario.\n        \"\"\"\n        task_data = self.load_data(running_time_option)\n        objects = self.generate_objects(running_time_option)\n        self.distribute(task_data, objects)\n        return objects\n\n    def distribute(self, task_data: dict, objects: list):\nr\"\"\"\n        Distribute the loaded local_movielens_recommendation datasets to different objects in\n        the federated scenario\n        \"\"\"\n        for ob in objects:\n            if ob.name in task_data.keys():\n                ob_data = task_data[ob.name]\n                for data_name, data in ob_data.items():\n                    ob.set_data(data, data_name)\n\n    def split_dataset(self, dataset, p=0.0):\nr\"\"\"\n        Split the dataset into two parts.\n\n        Args:\n            dataset (torch.utils.data.Dataset): the dataset to be splitted\n            p (float): the ratio of the splitting\n\n        Returns:\n            The two split parts\n        \"\"\"\n        if p == 0: return dataset, None\n        s1 = int(len(dataset) * p)\n        s2 = len(dataset) - s1\n        return torch.utils.data.random_split(dataset, [s2, s1])\n\n    def task_exists(self):\nr\"\"\"\n        Check whether the task already exists.\n\n        Returns:\n            True if the task already exists\n        \"\"\"\n        return os.path.exists(self.task_path)\n\n    def remove_task(self):\nr\"\"\"Remove this task\"\"\"\n        if self.task_exists():\n            shutil.rmtree(self.task_path)\n        return\n\n    def create_task_architecture(self):\n\"\"\"Create the directories of the task.\"\"\"\n        if not self.task_exists():\n            os.mkdir(self.task_path)\n            os.mkdir(os.path.join(self.task_path, 'record'))\n            os.mkdir(os.path.join(self.task_path, 'log'))\n        else:\n            raise FileExistsError(\"federated task {} already exists!\".format(self.task_path))\n\n    def gen_client_names(self, num_clients):\nr\"\"\"\n        Generate the names of clients\n\n        Returns:\n            a list of strings\n        \"\"\"\n        return [('Client{:0&gt;' + str(len(str(num_clients))) + 'd}').format(i) for i in range(num_clients)]\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.__init__","title":"<code>__init__(task_path)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>task_path</code> <code>str</code> <p>the path of the federated task</p> required Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def __init__(self, task_path):\nr\"\"\"\n    Args:\n        task_path (str): the path of the federated task\n    \"\"\"\n    self.task_path = task_path\n    if os.path.exists(os.path.join(self.task_path, 'data.json')):\n        with open(os.path.join(self.task_path, 'data.json'), 'r') as inf:\n            self.feddata = json.load(inf)\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.create_task_architecture","title":"<code>create_task_architecture()</code>","text":"<p>Create the directories of the task.</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def create_task_architecture(self):\n\"\"\"Create the directories of the task.\"\"\"\n    if not self.task_exists():\n        os.mkdir(self.task_path)\n        os.mkdir(os.path.join(self.task_path, 'record'))\n        os.mkdir(os.path.join(self.task_path, 'log'))\n    else:\n        raise FileExistsError(\"federated task {} already exists!\".format(self.task_path))\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.distribute","title":"<code>distribute(task_data, objects)</code>","text":"<p>Distribute the loaded local_movielens_recommendation datasets to different objects in the federated scenario</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def distribute(self, task_data: dict, objects: list):\nr\"\"\"\n    Distribute the loaded local_movielens_recommendation datasets to different objects in\n    the federated scenario\n    \"\"\"\n    for ob in objects:\n        if ob.name in task_data.keys():\n            ob_data = task_data[ob.name]\n            for data_name, data in ob_data.items():\n                ob.set_data(data, data_name)\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.gen_client_names","title":"<code>gen_client_names(num_clients)</code>","text":"<p>Generate the names of clients</p> <p>Returns:</p> Type Description <p>a list of strings</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def gen_client_names(self, num_clients):\nr\"\"\"\n    Generate the names of clients\n\n    Returns:\n        a list of strings\n    \"\"\"\n    return [('Client{:0&gt;' + str(len(str(num_clients))) + 'd}').format(i) for i in range(num_clients)]\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.generate_objects","title":"<code>generate_objects(running_time_option, algorithm, scene='horizontal')</code>","text":"<p>Generate the virtual objects (i.e. coordinators and participants) in the FL system</p> <p>Parameters:</p> Name Type Description Default <code>running_time_option</code> <code>dict</code> <p>the option (i.e. configuration)</p> required <code>algorithm</code> <code>module|class</code> <p>algorithm</p> required <code>scene</code> <code>str</code> <p>horizontal or vertical</p> <code>'horizontal'</code> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def generate_objects(self, running_time_option, algorithm, scene='horizontal') -&gt; list:\nr\"\"\"\n    Generate the virtual objects (i.e. coordinators and participants)\n    in the FL system\n\n    Args:\n        running_time_option (dict): the option (i.e. configuration)\n        algorithm (module|class): algorithm\n        scene (str): horizontal or vertical\n    \"\"\"\n    if scene=='horizontal':\n        # init clients\n        Client = algorithm.Client\n        clients = [Client(running_time_option) for _ in range(len(self.feddata['client_names']))]\n        for cid, c in enumerate(clients):\n            c.id = cid\n            c.name = self.feddata['client_names'][cid]\n        # init server\n        server = algorithm.Server(running_time_option)\n        server.name = 'server'\n        server.id = -1\n        # bind clients and server\n        server.register_clients(clients)\n        for c in clients: c.register_server(server)\n        # return objects as list\n        objects = [server]\n        objects.extend(clients)\n    elif scene=='vertical':\n        PassiveParty = algorithm.PassiveParty\n        ActiveParty = algorithm.ActiveParty\n        objects = []\n        for pid, pname in enumerate(self.feddata['party_names']):\n            is_active = self.feddata[pname]['data']['with_label']\n            obj = ActiveParty(running_time_option) if is_active else PassiveParty(running_time_option)\n            obj.id = pid\n            obj.name = pname\n            objects.append(obj)\n        for party in objects:\n            party.register_objects(objects)\n    elif scene=='hierarchical':\n        server = algorithm.Server(running_time_option)\n        server.id = -1\n        server.name = 'server'\n        edge_servers = [algorithm.EdgeServer(running_time_option) for _ in range(self.feddata['num_edge_servers'])]\n        for sid in range(len(edge_servers)):\n            edge_servers[sid].id = sid\n            edge_servers[sid].name = 'edge_server'+str(sid)\n            edge_servers[sid].clients = []\n        server.register_clients(edge_servers)\n        clients = [algorithm.Client(running_time_option) for _ in range(len(self.feddata['client_names']))]\n        edge_server_clients = [[] for _ in edge_servers]\n        for cid, c in enumerate(clients):\n            c.id = cid+len(edge_servers)\n            c.name = self.feddata['client_names'][cid]\n            edge_server_clients[self.feddata['client_group'][c.name]].append(c)\n        for edge_server, client_set in zip(edge_servers,edge_server_clients):\n            edge_server.register_clients(client_set)\n        objects = [server]\n        objects.extend(edge_servers)\n        objects.extend(clients)\n    elif scene=='decentralized':\n        # init clients\n        Client = algorithm.Client\n        clients = [Client(running_time_option) for _ in range(len(self.feddata['client_names']))]\n        for cid, c in enumerate(clients):\n            c.id = cid\n            c.name = self.feddata['client_names'][cid]\n        # init topology of clients\n        topology = self.feddata['topology']\n        for c in clients:\n            c.topology = topology\n        adjacent = self.feddata['adjacent']\n        for cid,c in enumerate(clients):\n            c.clients = [clients[k] for k,nid in enumerate(adjacent[cid]) if nid&gt;0]\n        # init protocol\n        protocol = algorithm.Protocol(running_time_option)\n        protocol.name = 'protocol'\n        # bind clients and server\n        protocol.clients = clients\n        # return objects as list\n        objects = [protocol]\n        objects.extend(clients)\n    return objects\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.load_data","title":"<code>load_data(running_time_option)</code>","text":"<p>Load the data and process it to the format that can be distributed to different objects</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def load_data(self, running_time_option) -&gt; dict:\n\"\"\"Load the data and process it to the format that can be distributed\n    to different objects\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.load_task","title":"<code>load_task(running_time_option, *args, **kwargs)</code>","text":"<p>Load the generated task into disk and create objects in the federated scenario.</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def load_task(self, running_time_option, *args, **kwargs):\nr\"\"\"\n    Load the generated task into disk and create objects in the federated\n    scenario.\n    \"\"\"\n    task_data = self.load_data(running_time_option)\n    objects = self.generate_objects(running_time_option)\n    self.distribute(task_data, objects)\n    return objects\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.remove_task","title":"<code>remove_task()</code>","text":"<p>Remove this task</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def remove_task(self):\nr\"\"\"Remove this task\"\"\"\n    if self.task_exists():\n        shutil.rmtree(self.task_path)\n    return\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.save_info","title":"<code>save_info(generator)</code>","text":"<p>Save the basic information of the generated task into the disk</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def save_info(self, generator):\nr\"\"\"\n    Save the basic information of the generated task into the disk\n    \"\"\"\n    info = {'benchmark': '.'.join(generator.__module__.split('.')[:-1])}\n    info['scene'] = generator.scene if hasattr(generator, 'scene') else 'unknown'\n    info['num_clients'] = generator.num_clients if hasattr(generator, 'num_clients') else (generator.num_parties if hasattr(self, 'num_parties') else 'unknown')\n    with open(os.path.join(self.task_path, 'info'), 'w') as outf:\n        json.dump(info, outf)\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.save_task","title":"<code>save_task(generator)</code>","text":"<p>Construct <code>feddata</code> and store it into the disk for recovering the partitioned datasets again from it</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def save_task(self, generator):\n\"\"\"Construct `feddata` and store it into the disk for recovering\n    the partitioned datasets again from it\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.split_dataset","title":"<code>split_dataset(dataset, p=0.0)</code>","text":"<p>Split the dataset into two parts.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>torch.utils.data.Dataset</code> <p>the dataset to be splitted</p> required <code>p</code> <code>float</code> <p>the ratio of the splitting</p> <code>0.0</code> <p>Returns:</p> Type Description <p>The two split parts</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def split_dataset(self, dataset, p=0.0):\nr\"\"\"\n    Split the dataset into two parts.\n\n    Args:\n        dataset (torch.utils.data.Dataset): the dataset to be splitted\n        p (float): the ratio of the splitting\n\n    Returns:\n        The two split parts\n    \"\"\"\n    if p == 0: return dataset, None\n    s1 = int(len(dataset) * p)\n    s2 = len(dataset) - s1\n    return torch.utils.data.random_split(dataset, [s2, s1])\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.BasicTaskPipe.task_exists","title":"<code>task_exists()</code>","text":"<p>Check whether the task already exists.</p> <p>Returns:</p> Type Description <p>True if the task already exists</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def task_exists(self):\nr\"\"\"\n    Check whether the task already exists.\n\n    Returns:\n        True if the task already exists\n    \"\"\"\n    return os.path.exists(self.task_path)\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.FromDatasetGenerator","title":"<code>FromDatasetGenerator</code>","text":"<p>         Bases: <code>BasicTaskGenerator</code></p> <p>This generator will do: 1. Directly create train_data and test_data from input; 2. Convert the train_data into the scheme that can be partitioned by Partitioner if necessary.</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>class FromDatasetGenerator(BasicTaskGenerator):\nr\"\"\"\n    This generator will do:\n    1. Directly create train_data and test_data from input;\n    2. Convert the train_data into the scheme that can be partitioned by Partitioner if necessary.\n    \"\"\"\n    def __init__(self, benchmark, train_data, val_data=None, test_data=None):\n        super(FromDatasetGenerator, self).__init__(benchmark=benchmark, rawdata_path='')\n        self.train_data = train_data\n        self.val_data = val_data\n        self.test_data = test_data\n\n    def generate(self, *args, **kwarg):\n        self.partition()\n\n    def partition(self, *args, **kwargs):\n        self.train_data = self.prepare_data_for_partition()\n        self.local_datas = self.partitioner(self.train_data)\n        self.num_clients = len(self.local_datas)\n\n    def prepare_data_for_partition(self):\n\"\"\"Transform the attribution self.train_data into the format that can be received by partitioner\"\"\"\n        return self.train_data\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.FromDatasetGenerator.prepare_data_for_partition","title":"<code>prepare_data_for_partition()</code>","text":"<p>Transform the attribution self.train_data into the format that can be received by partitioner</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>def prepare_data_for_partition(self):\n\"\"\"Transform the attribution self.train_data into the format that can be received by partitioner\"\"\"\n    return self.train_data\n</code></pre>"},{"location":"Docs/benchmark/base/#flgo.benchmark.base.XYHorizontalTaskPipe","title":"<code>XYHorizontalTaskPipe</code>","text":"<p>         Bases: <code>BasicTaskPipe</code></p> <p>This pipe is for supervised learning where each sample contains a feature \\(x_i\\) and a label \\(y_i\\)  that can be indexed by \\(i\\). To use this pipe, it's necessary to set the attribute <code>test_data</code> of the generator to be a dict like:     {'x': [...], 'y':[...]} and the attribute <code>local_datas</code> to be a list of the above dict that means the local_movielens_recommendation data owned by clients:     [{'x':[...], 'y':[...]}, ..., ]</p> Source code in <code>flgo\\benchmark\\base.py</code> <pre><code>class XYHorizontalTaskPipe(BasicTaskPipe):\n\"\"\"\n    This pipe is for supervised learning where each sample contains a feature $x_i$ and a label $y_i$\n     that can be indexed by $i$.\n    To use this pipe, it's necessary to set the attribute `test_data` of the generator to be a dict like:\n        {'x': [...], 'y':[...]}\n    and the attribute `local_datas` to be a list of the above dict that means the local_movielens_recommendation data owned by clients:\n        [{'x':[...], 'y':[...]}, ..., ]\n    \"\"\"\n    TaskDataset = torch.utils.data.TensorDataset\n\n    def save_task(self, generator):\n        client_names = self.gen_client_names(len(generator.local_datas))\n        feddata = {'client_names': client_names, 'server': {'data': generator.test_data}}\n        for cid in range(len(client_names)): feddata[client_names[cid]] = {'data': generator.local_datas[cid]}\n        with open(os.path.join(self.task_path, 'data.json'), 'w') as outf:\n            json.dump(feddata, outf)\n\n    def load_data(self, running_time_option) -&gt; dict:\n        test_data = self.feddata['server']['data']\n        test_data = self.TaskDataset(torch.tensor(test_data['x']), torch.tensor(test_data['y']))\n        local_datas = [self.TaskDataset(torch.tensor(self.feddata[cname]['data']['x']),\n                                        torch.tensor(self.feddata[cname]['data']['y'])) for cname in\n                       self.feddata['client_names']]\n        server_data_test, server_data_val = self.split_dataset(test_data, running_time_option['test_holdout'])\n        task_data = {'server': {'test': server_data_test, 'val': server_data_val}}\n        for key in self.feddata['server'].keys():\n            if key == 'data':\n                continue\n            task_data['server'][key] = self.feddata['server'][key]\n        for cid, cname in enumerate(self.feddata['client_names']):\n            cdata = local_datas[cid]\n            cdata_train, cdata_val = self.split_dataset(cdata, running_time_option['train_holdout'])\n            if running_time_option['local_test'] and cdata_val is not None:\n                cdata_val, cdata_test = self.split_dataset(cdata_val, 0.5)\n            else:\n                cdata_test = None\n            task_data[cname] = {'train': cdata_train, 'val': cdata_val, 'test': cdata_test}\n            for key in self.feddata[cname]:\n                if key == 'data':\n                    continue\n                task_data[cname][key] = self.feddata[cname][key]\n        return task_data\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/","title":"flgo.benchmark.toolkits.partition","text":"<p>This file contains preset partitioners for the benchmarks. All the Partitioner should implement the method <code>__call__(self, data)</code> where <code>data</code> is the dataset to be partitioned and the return is a list of the partitioned result.</p> <p>For example, The IIDPartitioner.call receives a indexable object (i.e. instance of torchvision.datasets.mnsit.MNSIT) and I.I.D. selects samples' indices in the original dataset as each client's local_movielens_recommendation data. The list of list of sample indices are finally returnerd (e.g. [[0,1,2,...,1008], ...,[25,23,98,...,997]]).</p> <p>To use the partitioner, you can specify Partitioner in the configuration dict for <code>flgo.gen_task</code>.  Example 1: passing the parameter of init of the Partitioner through the dict <code>para</code></p> <p>import flgo config = {'benchmark':{'name':'flgo.benchmark.mnist_classification'}, ...            'partitioner':{'name':'IIDPartitioner', 'para':{'num_clients':20, 'alpha':1.0}}} flgo.gen_task(config, './test_partition')</p>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.BasicPartitioner","title":"<code>BasicPartitioner</code>","text":"<p>         Bases: <code>AbstractPartitioner</code></p> <p>This is the basic class of data partitioner. The partitioner will be directly called by the task generator of different benchmarks. By overwriting call method, different partitioners can be realized. The input of call is usually a dataset.</p> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>class BasicPartitioner(AbstractPartitioner):\n\"\"\"This is the basic class of data partitioner. The partitioner will be directly called by the\n    task generator of different benchmarks. By overwriting __call__ method, different partitioners\n    can be realized. The input of __call__ is usually a dataset.\n    \"\"\"\n    def __call__(self, *args, **kwargs):\n        return\n\n    def register_generator(self, generator):\nr\"\"\"Register the generator as an self's attribute\"\"\"\n        self.generator = generator\n\n    def data_imbalance_generator(self, num_clients, datasize, imbalance=0):\nr\"\"\"\n        Split the data size into several parts\n\n        Args:\n            num_clients (int): the number of clients\n            datasize (int): the total data size\n            imbalance (float): the degree of data imbalance across clients\n\n        Returns:\n            a list of integer numbers that represents local_movielens_recommendation data sizes\n        \"\"\"\n        if imbalance == 0:\n            samples_per_client = [int(datasize / num_clients) for _ in range(num_clients)]\n            for _ in range(datasize % num_clients): samples_per_client[_] += 1\n        else:\n            imbalance = max(0.1, imbalance)\n            sigma = imbalance\n            mean_datasize = datasize / num_clients\n            mu = np.log(mean_datasize) - sigma ** 2 / 2.0\n            samples_per_client = np.random.lognormal(mu, sigma, (num_clients)).astype(int)\n            thresold = int(imbalance ** 1.5 * (datasize - num_clients * 10))\n            delta = int(0.1 * thresold)\n            crt_data_size = sum(samples_per_client)\n            # force current data size to match the total data size\n            while crt_data_size != datasize:\n                if crt_data_size - datasize &gt;= thresold:\n                    maxid = np.argmax(samples_per_client)\n                    maxvol = samples_per_client[maxid]\n                    new_samples = np.random.lognormal(mu, sigma, (10 * num_clients))\n                    while min(new_samples) &gt; maxvol:\n                        new_samples = np.random.lognormal(mu, sigma, (10 * num_clients))\n                    new_size_id = np.argmin(\n                        [np.abs(crt_data_size - samples_per_client[maxid] + s - datasize) for s in new_samples])\n                    samples_per_client[maxid] = new_samples[new_size_id]\n                elif crt_data_size - datasize &gt;= delta:\n                    maxid = np.argmax(samples_per_client)\n                    samples_per_client[maxid] -= delta\n                elif crt_data_size - datasize &gt; 0:\n                    maxid = np.argmax(samples_per_client)\n                    samples_per_client[maxid] -= (crt_data_size - datasize)\n                elif datasize - crt_data_size &gt;= thresold:\n                    minid = np.argmin(samples_per_client)\n                    minvol = samples_per_client[minid]\n                    new_samples = np.random.lognormal(mu, sigma, (10 * num_clients))\n                    while max(new_samples) &lt; minvol:\n                        new_samples = np.random.lognormal(mu, sigma, (10 * num_clients))\n                    new_size_id = np.argmin(\n                        [np.abs(crt_data_size - samples_per_client[minid] + s - datasize) for s in new_samples])\n                    samples_per_client[minid] = new_samples[new_size_id]\n                elif datasize - crt_data_size &gt;= delta:\n                    minid = np.argmin(samples_per_client)\n                    samples_per_client[minid] += delta\n                else:\n                    minid = np.argmin(samples_per_client)\n                    samples_per_client[minid] += (datasize - crt_data_size)\n                crt_data_size = sum(samples_per_client)\n        return samples_per_client\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.BasicPartitioner.data_imbalance_generator","title":"<code>data_imbalance_generator(num_clients, datasize, imbalance=0)</code>","text":"<p>Split the data size into several parts</p> <p>Parameters:</p> Name Type Description Default <code>num_clients</code> <code>int</code> <p>the number of clients</p> required <code>datasize</code> <code>int</code> <p>the total data size</p> required <code>imbalance</code> <code>float</code> <p>the degree of data imbalance across clients</p> <code>0</code> <p>Returns:</p> Type Description <p>a list of integer numbers that represents local_movielens_recommendation data sizes</p> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>def data_imbalance_generator(self, num_clients, datasize, imbalance=0):\nr\"\"\"\n    Split the data size into several parts\n\n    Args:\n        num_clients (int): the number of clients\n        datasize (int): the total data size\n        imbalance (float): the degree of data imbalance across clients\n\n    Returns:\n        a list of integer numbers that represents local_movielens_recommendation data sizes\n    \"\"\"\n    if imbalance == 0:\n        samples_per_client = [int(datasize / num_clients) for _ in range(num_clients)]\n        for _ in range(datasize % num_clients): samples_per_client[_] += 1\n    else:\n        imbalance = max(0.1, imbalance)\n        sigma = imbalance\n        mean_datasize = datasize / num_clients\n        mu = np.log(mean_datasize) - sigma ** 2 / 2.0\n        samples_per_client = np.random.lognormal(mu, sigma, (num_clients)).astype(int)\n        thresold = int(imbalance ** 1.5 * (datasize - num_clients * 10))\n        delta = int(0.1 * thresold)\n        crt_data_size = sum(samples_per_client)\n        # force current data size to match the total data size\n        while crt_data_size != datasize:\n            if crt_data_size - datasize &gt;= thresold:\n                maxid = np.argmax(samples_per_client)\n                maxvol = samples_per_client[maxid]\n                new_samples = np.random.lognormal(mu, sigma, (10 * num_clients))\n                while min(new_samples) &gt; maxvol:\n                    new_samples = np.random.lognormal(mu, sigma, (10 * num_clients))\n                new_size_id = np.argmin(\n                    [np.abs(crt_data_size - samples_per_client[maxid] + s - datasize) for s in new_samples])\n                samples_per_client[maxid] = new_samples[new_size_id]\n            elif crt_data_size - datasize &gt;= delta:\n                maxid = np.argmax(samples_per_client)\n                samples_per_client[maxid] -= delta\n            elif crt_data_size - datasize &gt; 0:\n                maxid = np.argmax(samples_per_client)\n                samples_per_client[maxid] -= (crt_data_size - datasize)\n            elif datasize - crt_data_size &gt;= thresold:\n                minid = np.argmin(samples_per_client)\n                minvol = samples_per_client[minid]\n                new_samples = np.random.lognormal(mu, sigma, (10 * num_clients))\n                while max(new_samples) &lt; minvol:\n                    new_samples = np.random.lognormal(mu, sigma, (10 * num_clients))\n                new_size_id = np.argmin(\n                    [np.abs(crt_data_size - samples_per_client[minid] + s - datasize) for s in new_samples])\n                samples_per_client[minid] = new_samples[new_size_id]\n            elif datasize - crt_data_size &gt;= delta:\n                minid = np.argmin(samples_per_client)\n                samples_per_client[minid] += delta\n            else:\n                minid = np.argmin(samples_per_client)\n                samples_per_client[minid] += (datasize - crt_data_size)\n            crt_data_size = sum(samples_per_client)\n    return samples_per_client\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.BasicPartitioner.register_generator","title":"<code>register_generator(generator)</code>","text":"<p>Register the generator as an self's attribute</p> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>def register_generator(self, generator):\nr\"\"\"Register the generator as an self's attribute\"\"\"\n    self.generator = generator\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.DirichletPartitioner","title":"<code>DirichletPartitioner</code>","text":"<p>         Bases: <code>BasicPartitioner</code></p> <p>`Partition the indices of samples in the original dataset according to Dirichlet distribution of the particular attribute. This way of partition is widely used by existing works in federated learning.</p> <p>Parameters:</p> Name Type Description Default <code>num_clients</code> <code>int</code> <p>the number of clients</p> <code>100</code> <code>alpha</code> <code>float</code> <p><code>alpha</code>(i.e. alpha&gt;=0) in Dir(alpha*p) where p is the global distribution. The smaller alpha is, the higher heterogeneity the data is.</p> <code>1.0</code> <code>imbalance</code> <code>float</code> <p>the degree of imbalance of the amounts of different local_movielens_recommendation data (0&lt;=imbalance&lt;=1)</p> <code>0</code> <code>error_bar</code> <code>float</code> <p>the allowed error when the generated distribution mismatches the distirbution that is actually wanted, since there may be no solution for particular imbalance and alpha.</p> <code>1e-06</code> <code>index_func</code> <code>func</code> <p>to index the distribution-dependent (i.e. label) attribute in each sample.</p> <code>lambda X: [xi[-1] for xi in X]</code> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>class DirichletPartitioner(BasicPartitioner):\n\"\"\"`Partition the indices of samples in the original dataset according to Dirichlet distribution of the\n    particular attribute. This way of partition is widely used by existing works in federated learning.\n\n    Args:\n        num_clients (int, optional): the number of clients\n        alpha (float, optional): `alpha`(i.e. alpha&gt;=0) in Dir(alpha*p) where p is the global distribution. The smaller alpha is, the higher heterogeneity the data is.\n        imbalance (float, optional): the degree of imbalance of the amounts of different local_movielens_recommendation data (0&lt;=imbalance&lt;=1)\n        error_bar (float, optional): the allowed error when the generated distribution mismatches the distirbution that is actually wanted, since there may be no solution for particular imbalance and alpha.\n        index_func (func, optional): to index the distribution-dependent (i.e. label) attribute in each sample.\n    \"\"\"\n    def __init__(self, num_clients=100, alpha=1.0, error_bar=1e-6, imbalance=0, index_func=lambda X:[xi[-1] for xi in X]):\n        self.num_clients = num_clients\n        self.alpha = alpha\n        self.imbalance = imbalance\n        self.index_func = index_func\n        self.error_bar = error_bar\n\n    def __str__(self):\n        name = \"dir{:.2f}_err{}\".format(self.alpha, self.error_bar)\n        if self.imbalance &gt; 0: name += '_imb{:.1f}'.format(self.imbalance)\n        return name\n\n    def __call__(self, data):\n        attrs = self.index_func(data)\n        num_attrs = len(set(attrs))\n        samples_per_client = self.data_imbalance_generator(self.num_clients, len(data), self.imbalance)\n        # count the label distribution\n        lb_counter = collections.Counter(attrs)\n        lb_names = list(lb_counter.keys())\n        p = np.array([1.0 * v / len(data) for v in lb_counter.values()])\n        lb_dict = {}\n        attrs = np.array(attrs)\n        for lb in lb_names:\n            lb_dict[lb] = np.where(attrs == lb)[0]\n        proportions = [np.random.dirichlet(self.alpha * p) for _ in range(self.num_clients)]\n        while np.any(np.isnan(proportions)):\n            proportions = [np.random.dirichlet(self.alpha * p) for _ in range(self.num_clients)]\n        sorted_cid_map = {k: i for k, i in zip(np.argsort(samples_per_client), [_ for _ in range(self.num_clients)])}\n        error_increase_interval = 500\n        max_error = self.error_bar\n        loop_count = 0\n        crt_id = 0\n        crt_error = 100000\n        while True:\n            if loop_count &gt;= error_increase_interval:\n                loop_count = 0\n                max_error = max_error * 10\n            # generate dirichlet distribution till ||E(proportion) - P(D)||&lt;=1e-5*self.num_classes\n            mean_prop = np.sum([pi * di for pi, di in zip(proportions, samples_per_client)], axis=0)\n            mean_prop = mean_prop / mean_prop.sum()\n            error_norm = ((mean_prop - p) ** 2).sum()\n            if crt_error - error_norm &gt;= max_error:\n                print(\"Error: {:.8f}\".format(error_norm))\n                crt_error = error_norm\n            if error_norm &lt;= max_error:\n                break\n            excid = sorted_cid_map[crt_id]\n            crt_id = (crt_id + 1) % self.num_clients\n            sup_prop = [np.random.dirichlet(self.alpha * p) for _ in range(self.num_clients)]\n            del_prop = np.sum([pi * di for pi, di in zip(proportions, samples_per_client)], axis=0)\n            del_prop -= samples_per_client[excid] * proportions[excid]\n            for i in range(error_increase_interval - loop_count):\n                alter_norms = []\n                for cid in range(self.num_clients):\n                    if np.any(np.isnan(sup_prop[cid])):\n                        continue\n                    alter_prop = del_prop + samples_per_client[excid] * sup_prop[cid]\n                    alter_prop = alter_prop / alter_prop.sum()\n                    error_alter = ((alter_prop - p) ** 2).sum()\n                    alter_norms.append(error_alter)\n                if min(alter_norms) &lt; error_norm:\n                    break\n            if len(alter_norms) &gt; 0 and min(alter_norms) &lt; error_norm:\n                alcid = np.argmin(alter_norms)\n                proportions[excid] = sup_prop[alcid]\n            loop_count += 1\n        local_datas = [[] for _ in range(self.num_clients)]\n        self.dirichlet_dist = []  # for efficiently visualizing\n        for lb in lb_names:\n            lb_idxs = lb_dict[lb]\n            lb_proportion = np.array([pi[lb_names.index(lb)] * si for pi, si in zip(proportions, samples_per_client)])\n            lb_proportion = lb_proportion / lb_proportion.sum()\n            lb_proportion = (np.cumsum(lb_proportion) * len(lb_idxs)).astype(int)[:-1]\n            lb_datas = np.split(lb_idxs, lb_proportion)\n            self.dirichlet_dist.append([len(lb_data) for lb_data in lb_datas])\n            local_datas = [local_data + lb_data.tolist() for local_data, lb_data in zip(local_datas, lb_datas)]\n        self.dirichlet_dist = np.array(self.dirichlet_dist).T\n        for i in range(self.num_clients): np.random.shuffle(local_datas[i])\n        self.local_datas = local_datas\n        return local_datas\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.DiversityPartitioner","title":"<code>DiversityPartitioner</code>","text":"<p>         Bases: <code>BasicPartitioner</code></p> <p>`Partition the indices of samples in the original dataset according to numbers of types of a particular attribute (e.g. label) . This way of partition is widely used by existing works in federated learning.</p> <p>Parameters:</p> Name Type Description Default <code>num_clients</code> <code>int</code> <p>the number of clients</p> <code>100</code> <code>diversity</code> <code>float</code> <p>the ratio of locally owned types of the attributes (i.e. the actual number=diversity * total_num_of_types)</p> <code>1.0</code> <code>imbalance</code> <code>float</code> <p>the degree of imbalance of the amounts of different local_movielens_recommendation data (0&lt;=imbalance&lt;=1)</p> required <code>index_func</code> <code>int</code> <p>the index of the distribution-dependent (i.e. label) attribute in each sample.</p> <code>lambda X: [xi[-1] for xi in X]</code> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>class DiversityPartitioner(BasicPartitioner):\n\"\"\"`Partition the indices of samples in the original dataset according to numbers of types of a particular\n    attribute (e.g. label) . This way of partition is widely used by existing works in federated learning.\n\n    Args:\n        num_clients (int, optional): the number of clients\n        diversity (float, optional): the ratio of locally owned types of the attributes (i.e. the actual number=diversity * total_num_of_types)\n        imbalance (float, optional): the degree of imbalance of the amounts of different local_movielens_recommendation data (0&lt;=imbalance&lt;=1)\n        index_func (int, optional): the index of the distribution-dependent (i.e. label) attribute in each sample.\n    \"\"\"\n    def __init__(self, num_clients=100, diversity=1.0, index_func=lambda X:[xi[-1] for xi in X]):\n        self.num_clients = num_clients\n        self.diversity = diversity\n        self.index_func = index_func\n\n    def __str__(self):\n        name = \"div{:.1f}\".format(self.diversity)\n        return name\n\n    def __call__(self, data):\n        labels = self.index_func(data)\n        num_classes = len(set(labels))\n        dpairs = [[did, lb] for did, lb in zip(list(range(len(data))), labels)]\n        num = max(int(self.diversity * num_classes), 1)\n        K = num_classes\n        local_datas = [[] for _ in range(self.num_clients)]\n        if num == K:\n            for k in range(K):\n                idx_k = [p[0] for p in dpairs if p[1] == k]\n                np.random.shuffle(idx_k)\n                split = np.array_split(idx_k, self.num_clients)\n                for cid in range(self.num_clients):\n                    local_datas[cid].extend(split[cid].tolist())\n        else:\n            times = [0 for _ in range(num_classes)]\n            contain = []\n            for i in range(self.num_clients):\n                current = []\n                j = 0\n                while (j &lt; num):\n                    mintime = np.min(times)\n                    ind = np.random.choice(np.where(times == mintime)[0])\n                    if (ind not in current):\n                        j = j + 1\n                        current.append(ind)\n                        times[ind] += 1\n                contain.append(current)\n            for k in range(K):\n                idx_k = [p[0] for p in dpairs if p[1] == k]\n                np.random.shuffle(idx_k)\n                split = np.array_split(idx_k, times[k])\n                ids = 0\n                for cid in range(self.num_clients):\n                    if k in contain[cid]:\n                        local_datas[cid].extend(split[ids].tolist())\n                        ids += 1\n        return local_datas\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.GaussianPerturbationPartitioner","title":"<code>GaussianPerturbationPartitioner</code>","text":"<p>         Bases: <code>BasicPartitioner</code></p> <p>`Partition the indices of samples I.I.D. and bind additional and static gaussian noise to each sample, which is a setting of feature skew in federated learning.</p> <p>Parameters:</p> Name Type Description Default <code>num_clients</code> <code>int</code> <p>the number of clients</p> <code>100</code> <code>imbalance</code> <code>float</code> <p>the degree of imbalance of the amounts of different local_movielens_recommendation data (0&lt;=imbalance&lt;=1)</p> <code>0.0</code> <code>sigma</code> <code>float</code> <p>the degree of feature skew</p> <code>0.1</code> <code>scale</code> <code>float</code> <p>the standard deviation of noise</p> <code>0.1</code> <code>index_func</code> <code>int</code> <p>the index of the feature to be processed for each sample.</p> <code>lambda X: [xi[0] for xi in X]</code> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>class GaussianPerturbationPartitioner(BasicPartitioner):\n\"\"\"`Partition the indices of samples I.I.D. and bind additional and static gaussian noise to each sample, which is\n    a setting of feature skew in federated learning.\n\n    Args:\n        num_clients (int, optional): the number of clients\n        imbalance (float, optional): the degree of imbalance of the amounts of different local_movielens_recommendation data (0&lt;=imbalance&lt;=1)\n        sigma (float, optional): the degree of feature skew\n        scale (float, optional): the standard deviation of noise\n        index_func (int, optional): the index of the feature to be processed for each sample.\n    \"\"\"\n    def __init__(self, num_clients=100, imbalance=0.0, sigma=0.1, scale=0.1, index_func=lambda X:[xi[0] for xi in X]):\n        self.num_clients = num_clients\n        self.imbalance = imbalance\n        self.sigma = sigma\n        self.scale = scale\n        self.index_func = index_func\n\n    def __str__(self):\n        name = \"perturb_gs{:.1f}_{:.1f}\".format(self.sigma, self.scale)\n        if self.imbalance &gt; 0: name += '_imb{:.1f}'.format(self.imbalance)\n        return name\n\n    def __call__(self, data):\n        shape = tuple(np.array(self.index_func(data)[0].shape))\n        samples_per_client = self.data_imbalance_generator(self.num_clients, len(data), self.imbalance)\n        d_idxs = np.random.permutation(len(data))\n        local_datas = np.split(d_idxs, np.cumsum(samples_per_client))[:-1]\n        local_datas = [di.tolist() for di in local_datas]\n        local_perturbation_means = [np.random.normal(0, self.sigma, shape) for _ in range(self.num_clients)]\n        local_perturbation_stds = [self.scale * np.ones(shape) for _ in range(self.num_clients)]\n        local_perturbation = []\n        for cid in range(self.num_clients):\n            c_perturbation = [np.random.normal(local_perturbation_means[cid], local_perturbation_stds[cid]).tolist() for\n                              _ in range(len(local_datas[cid]))]\n            local_perturbation.append(c_perturbation)\n        self.local_perturbation = local_perturbation\n        return local_datas\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.IDPartitioner","title":"<code>IDPartitioner</code>","text":"<p>         Bases: <code>BasicPartitioner</code></p> <p><code>Partition the indices of samples I.I.D. according to the ID of each sample, which requires the passed parameter</code>data<code>has attribution</code>id`.</p> <p>Parameters:</p> Name Type Description Default <code>num_clients</code> <code>int</code> <p>the number of clients</p> <code>-1</code> <code>priority</code> <code>str</code> <p>The value should be in set ('random', 'max', 'min'). If the number of clients is smaller than the total number of all the clients, this term will decide the selected clients according to their local_movielens_recommendation data sizes.</p> <code>'random'</code> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>class IDPartitioner(BasicPartitioner):\n\"\"\"`Partition the indices of samples I.I.D. according to the ID of each sample, which requires the passed parameter\n    `data` has attribution `id`.\n\n    Args:\n        num_clients (int, optional): the number of clients\n        priority (str, optional): The value should be in set ('random', 'max', 'min'). If the number of clients is smaller than the total number of all the clients, this term will decide the selected clients according to their local_movielens_recommendation data sizes.\n    \"\"\"\n    def __init__(self, num_clients=-1, priority='random', index_func=lambda X:X.id):\n        self.num_clients = int(num_clients)\n        self.priorty = priority\n        self.index_func = index_func\n\n    def __str__(self):\n        return 'id'\n\n    def __call__(self, data):\n        all_data = list(range(len(data)))\n        data_owners = self.index_func(data)\n        local_datas = collections.defaultdict(list)\n        for idx in range(len(all_data)):\n            local_datas[data_owners[idx]].append(idx)\n        local_datas = list(local_datas.values())\n        if self.num_clients &lt; 0:\n            self.num_clients = len(local_datas)\n        elif self.priorty == 'max':\n            local_datas = sorted(local_datas, key=lambda x: len(x), reverse=True)[:self.num_clients]\n        elif self.priorty == 'min':\n            local_datas = sorted(local_datas, key=lambda x: len(x))[:self.num_clients]\n        elif self.priorty == 'random':\n            random.shuffle(local_datas)\n            local_datas = local_datas[:self.num_clients]\n        # local_datas = sorted(local_datas, key=lambda x:data[x[0]][self.index_func] if self.index_func is not None else data.id[x[0]])\n        return local_datas\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.IIDPartitioner","title":"<code>IIDPartitioner</code>","text":"<p>         Bases: <code>BasicPartitioner</code></p> <p>`Partition the indices of samples in the original dataset indentically and independently.</p> <p>Parameters:</p> Name Type Description Default <code>num_clients</code> <code>int</code> <p>the number of clients</p> <code>100</code> <code>imbalance</code> <code>float</code> <p>the degree of imbalance of the amounts of different local_movielens_recommendation data (0&lt;=imbalance&lt;=1)</p> <code>0</code> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>class IIDPartitioner(BasicPartitioner):\n\"\"\"`Partition the indices of samples in the original dataset indentically and independently.\n\n    Args:\n        num_clients (int, optional): the number of clients\n        imbalance (float, optional): the degree of imbalance of the amounts of different local_movielens_recommendation data (0&lt;=imbalance&lt;=1)\n    \"\"\"\n    def __init__(self, num_clients=100, imbalance=0):\n        self.num_clients = num_clients\n        self.imbalance = imbalance\n\n    def __str__(self):\n        name = \"iid\"\n        if self.imbalance &gt; 0: name += '_imb{:.1f}'.format(self.imbalance)\n        return name\n\n    def __call__(self, data):\n        samples_per_client = self.data_imbalance_generator(self.num_clients, len(data), self.imbalance)\n        d_idxs = np.random.permutation(len(data))\n        local_datas = np.split(d_idxs, np.cumsum(samples_per_client))[:-1]\n        local_datas = [di.tolist() for di in local_datas]\n        return local_datas\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.NodeLouvainPartitioner","title":"<code>NodeLouvainPartitioner</code>","text":"<p>         Bases: <code>BasicPartitioner</code></p> <p>Partition a graph into several subgraph by louvain algorithms. The input of this partitioner should be of type networkx.Graph</p> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>class NodeLouvainPartitioner(BasicPartitioner):\n\"\"\"\n    Partition a graph into several subgraph by louvain algorithms. The input\n    of this partitioner should be of type networkx.Graph\n    \"\"\"\n    def __init__(self, num_clients=100):\n        self.num_clients = num_clients\n\n    def __str__(self):\n        name = \"Louvain\"\n        return name\n\n    def __call__(self, data):\nr\"\"\"\n        Partition graph data by Louvain algorithm and similar nodes (i.e. being of the same community) will be\n        allocated one client.\n        Args:\n            data (networkx.Graph):\n        Returns:\n            local_nodes (List): the local nodes id owned by each client (e.g. [[1,2], [3,4]])\n        \"\"\"\n        local_nodes = [[] for _ in range(self.num_clients)]\n        self.node_groups = community.community_louvain.best_partition(data)\n        groups = collections.defaultdict(list)\n        for ni, gi in self.node_groups.items():\n            groups[gi].append(ni)\n        groups = {k: groups[k] for k in list(range(len(groups)))}\n        # ensure the number of groups is larger than the number of clients\n        while len(groups) &lt; self.num_clients:\n            # find the group with the largest size\n            groups_lens = [groups[k] for k in range(len(groups))]\n            max_gi = np.argmax(groups_lens)\n            # set the size of the new group\n            min_glen = min(groups_lens)\n            max_glen = max(groups_lens)\n            if max_glen &lt; 2 * min_glen: min_glen = max_glen // 2\n            # split the group with the largest size into two groups\n            nodes_in_gi = groups[max_gi]\n            new_group_id = len(groups)\n            groups[new_group_id] = nodes_in_gi[:min_glen]\n            groups[max_gi] = nodes_in_gi[min_glen:]\n        # allocate different groups to clients\n        groups_lens = [len(groups[k]) for k in range(len(groups))]\n        group_ids = np.argsort(groups_lens)\n        for gi in group_ids:\n            cid = np.argmin([len(li) for li in local_nodes])\n            local_nodes[cid].extend(groups[gi])\n        return local_nodes\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.NodeLouvainPartitioner.__call__","title":"<code>__call__(data)</code>","text":"<p>Partition graph data by Louvain algorithm and similar nodes (i.e. being of the same community) will be allocated one client.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>networkx.Graph</code> required <p>Returns:</p> Name Type Description <code>local_nodes</code> <code>List</code> <p>the local nodes id owned by each client (e.g. [[1,2], [3,4]])</p> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>def __call__(self, data):\nr\"\"\"\n    Partition graph data by Louvain algorithm and similar nodes (i.e. being of the same community) will be\n    allocated one client.\n    Args:\n        data (networkx.Graph):\n    Returns:\n        local_nodes (List): the local nodes id owned by each client (e.g. [[1,2], [3,4]])\n    \"\"\"\n    local_nodes = [[] for _ in range(self.num_clients)]\n    self.node_groups = community.community_louvain.best_partition(data)\n    groups = collections.defaultdict(list)\n    for ni, gi in self.node_groups.items():\n        groups[gi].append(ni)\n    groups = {k: groups[k] for k in list(range(len(groups)))}\n    # ensure the number of groups is larger than the number of clients\n    while len(groups) &lt; self.num_clients:\n        # find the group with the largest size\n        groups_lens = [groups[k] for k in range(len(groups))]\n        max_gi = np.argmax(groups_lens)\n        # set the size of the new group\n        min_glen = min(groups_lens)\n        max_glen = max(groups_lens)\n        if max_glen &lt; 2 * min_glen: min_glen = max_glen // 2\n        # split the group with the largest size into two groups\n        nodes_in_gi = groups[max_gi]\n        new_group_id = len(groups)\n        groups[new_group_id] = nodes_in_gi[:min_glen]\n        groups[max_gi] = nodes_in_gi[min_glen:]\n    # allocate different groups to clients\n    groups_lens = [len(groups[k]) for k in range(len(groups))]\n    group_ids = np.argsort(groups_lens)\n    for gi in group_ids:\n        cid = np.argmin([len(li) for li in local_nodes])\n        local_nodes[cid].extend(groups[gi])\n    return local_nodes\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.VerticalSplittedPartitioner","title":"<code>VerticalSplittedPartitioner</code>","text":"<p>         Bases: <code>BasicPartitioner</code></p> <p>`Partition the indices and shapes of samples in the original dataset for vertical federated learning. Different to the above partitioners, the partitioner.call returns more flexible partition information instead of the indices that can be used to rebuild the partitioned data.</p> <p>Parameters:</p> Name Type Description Default <code>num_parties</code> <code>int</code> <p>the number of parties</p> <code>-1</code> <code>imbalance</code> <code>float</code> <p>the degree of imbalance of the number of features</p> <code>0</code> <code>dim</code> <code>int</code> <p>the dim of features to be partitioned</p> <code>-1</code> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>class VerticalSplittedPartitioner(BasicPartitioner):\n\"\"\"`Partition the indices and shapes of samples in the original dataset for vertical federated learning. Different\n    to the above partitioners, the partitioner.__call__ returns more flexible partition information instead of the indices that\n    can be used to rebuild the partitioned data.\n\n    Args:\n        num_parties (int, optional): the number of parties\n        imbalance (float, optional): the degree of imbalance of the number of features\n        dim (int, optional): the dim of features to be partitioned\n    \"\"\"\n    def __init__(self, num_parties=-1, imbalance=0, dim=-1):\n        self.num_parties = int(num_parties)\n        self.imbalance = imbalance\n        self.feature_pointers = []\n        self.dim = dim\n\n    def __str__(self):\n        return 'vertical_splitted_IBM{}'.format(self.imbalance)\n\n    def __call__(self, data):\n        local_datas = []\n        feature = data[0][0]\n        shape = feature.shape\n        if self.dim == -1: self.dim = int(np.argmax(shape))\n        self.num_parties = min(shape[self.dim], self.num_parties)\n        feature_sizes = self.gen_feature_size(shape[self.dim], self.num_parties, self.imbalance)\n        for pid in range(self.num_parties):\n            pdata = {'sample_idxs': list(range(len(data))), 'pt_feature': (self.dim, feature_sizes, pid),\n                     'with_label': (pid == 0)}\n            local_datas.append(pdata)\n        return local_datas\n\n    def gen_feature_size(self, total_size, num_parties, imbalance=0):\n        size_partitions = []\n        size_gen = self.integer_k_partition(total_size, num_parties)\n        while True:\n            try:\n                tmp = next(size_gen)\n                if tmp is not None:\n                    size_partitions.append(tmp)\n            except StopIteration:\n                break\n        size_partitions = sorted(size_partitions, key=lambda x: np.std(x))\n        res = size_partitions[int(imbalance * (len(size_partitions) - 1))]\n        return res\n\n    def integer_k_partition(self, n, k, l=1):\n'''n is the integer to partition, k is the length of partitions, l is the min partition element size'''\n        if k &lt; 1:\n            return None\n        if k == 1:\n            if n &gt;= l:\n                yield (n,)\n            return None\n        for i in range(l, n + 1):\n            for result in self.integer_k_partition(n - i, k - 1, i):\n                yield (i,) + result\n</code></pre>"},{"location":"Docs/benchmark/toolkits/parition/#flgo.benchmark.toolkits.partition.VerticalSplittedPartitioner.integer_k_partition","title":"<code>integer_k_partition(n, k, l=1)</code>","text":"<p>n is the integer to partition, k is the length of partitions, l is the min partition element size</p> Source code in <code>flgo\\benchmark\\toolkits\\partition.py</code> <pre><code>def integer_k_partition(self, n, k, l=1):\n'''n is the integer to partition, k is the length of partitions, l is the min partition element size'''\n    if k &lt; 1:\n        return None\n    if k == 1:\n        if n &gt;= l:\n            yield (n,)\n        return None\n    for i in range(l, n + 1):\n        for result in self.integer_k_partition(n - i, k - 1, i):\n            yield (i,) + result\n</code></pre>"},{"location":"Docs/benchmark/toolkits/visualization/","title":"flgo.benchmark.toolkits.visualization","text":""},{"location":"Docs/benchmark/toolkits/visualization/#flgo.benchmark.toolkits.visualization.community_layout","title":"<code>community_layout(g, partition)</code>","text":"<p>Compute the layout for a modular graph.</p> <p>g -- networkx.Graph or networkx.DiGraph instance     graph to plot</p> <p>partition -- dict mapping int node -&gt; int community     graph partitions</p> <p>pos -- dict mapping int node -&gt; (float x, float y)     node positions</p> Source code in <code>flgo\\benchmark\\toolkits\\visualization.py</code> <pre><code>def community_layout(g, partition):\n\"\"\"\n    Compute the layout for a modular graph.\n\n\n    Arguments:\n    ----------\n    g -- networkx.Graph or networkx.DiGraph instance\n        graph to plot\n\n    partition -- dict mapping int node -&gt; int community\n        graph partitions\n\n\n    Returns:\n    --------\n    pos -- dict mapping int node -&gt; (float x, float y)\n        node positions\n\n    \"\"\"\n\n    pos_communities = _position_communities(g, partition, scale=3.)\n\n    pos_nodes = _position_nodes(g, partition, scale=1.)\n\n    # combine positions\n    pos = dict()\n    for node in g.nodes():\n        pos[node] = pos_communities[node] + pos_nodes[node]\n\n    return pos\n</code></pre>"},{"location":"Docs/benchmark/toolkits/visualization/#flgo.benchmark.toolkits.visualization.visualize_by_class","title":"<code>visualize_by_class(generator, partitioner, task_path)</code>","text":"<p>Visualize the partitioned classification dataset and save the figure</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>flgo.benchmark.toolkits.BasicTaskGenerator</code> <p>task generator</p> required <code>partitioner</code> <code>flgo.benchmark.toolkits.partition.BasicPartitioner</code> <p>partitioner</p> required <code>task_path</code> <code>str</code> <p>the path storing the figure</p> required Source code in <code>flgo\\benchmark\\toolkits\\visualization.py</code> <pre><code>def visualize_by_class(generator, partitioner, task_path:str):\nr\"\"\"\n    Visualize the partitioned classification dataset and save the figure\n\n    Args:\n        generator (flgo.benchmark.toolkits.BasicTaskGenerator): task generator\n        partitioner (flgo.benchmark.toolkits.partition.BasicPartitioner): partitioner\n        task_path (str): the path storing the figure\n    \"\"\"\n    all_labels = [d[-1] for d in generator.train_data]\n    num_classes = len(set(all_labels))\n    ax = plt.subplots()\n    colors = [key for key in matplotlib.colors.CSS4_COLORS.keys()]\n    random.shuffle(colors)\n    client_height = 1\n    if hasattr(generator.partitioner, 'num_parties'):\n        n = generator.partitioner.num_parties\n    else:\n        n = generator.partitioner.num_clients\n    if hasattr(partitioner, 'dirichlet_dist'):\n        client_dist = generator.partitioner.dirichlet_dist.tolist()\n        data_columns = [sum(cprop) for cprop in client_dist]\n        row_map = {k: i for k, i in zip(np.argsort(data_columns), [_ for _ in range(n)])}\n        for cid, cprop in enumerate(client_dist):\n            offset = 0\n            y_bottom = row_map[cid] - client_height / 2.0\n            y_top = row_map[cid] + client_height / 2.0\n            for lbi in range(len(cprop)):\n                plt.fill_between([offset, offset + cprop[lbi]], y_bottom, y_top, facecolor=colors[lbi])\n                # plt.barh(cid, cprop[lbi], client_height, left=offset, color=)\n                offset += cprop[lbi]\n    else:\n        data_columns = [len(cidx) for cidx in generator.local_datas]\n        row_map = {k: i for k, i in zip(np.argsort(data_columns), [_ for _ in range(n)])}\n        for cid, cidxs in enumerate(generator.local_datas):\n            labels = [int(generator.train_data[did][-1]) for did in cidxs]\n            lb_counter = collections.Counter(labels)\n            offset = 0\n            y_bottom = row_map[cid] - client_height / 2.0\n            y_top = row_map[cid] + client_height / 2.0\n            for lbi in range(num_classes):\n                plt.fill_between([offset, offset + lb_counter[lbi]], y_bottom, y_top, facecolor=colors[lbi%len(colors)])\n                offset += lb_counter[lbi]\n    plt.xlim(0, max(data_columns))\n    plt.ylim(-0.5, n- 0.5)\n    plt.ylabel('Client ID')\n    plt.xlabel('Number of Samples')\n    plt.savefig(os.path.join(task_path, 'res.png'))\n    plt.show()\n</code></pre>"},{"location":"Docs/benchmark/toolkits/visualization/#flgo.benchmark.toolkits.visualization.visualize_by_community","title":"<code>visualize_by_community(generator, partitioner, task_path)</code>","text":"<p>Visualize the partitioned graph node-level dataset and save the figure</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>flgo.benchmark.toolkits.BasicTaskGenerator</code> <p>task generator</p> required <code>partitioner</code> <code>flgo.benchmark.toolkits.partition.BasicPartitioner</code> <p>partitioner</p> required <code>task_path</code> <code>str</code> <p>the path storing the figure</p> required Source code in <code>flgo\\benchmark\\toolkits\\visualization.py</code> <pre><code>def visualize_by_community(generator, partitioner, task_path:str):\nr\"\"\"\n    Visualize the partitioned graph node-level dataset and save the figure\n\n    Args:\n        generator (flgo.benchmark.toolkits.BasicTaskGenerator): task generator\n        partitioner (flgo.benchmark.toolkits.partition.BasicPartitioner): partitioner\n        task_path (str): the path storing the figure\n    \"\"\"\n    # from communities.\n    import networkx as nx\n    import community\n    community = community.community_louvain.best_partition(generator.train_data)\n    groups = collections.defaultdict(list)\n    for ni, gi in community.items():\n        groups[gi].append(ni)\n    groups = list(groups.values())\n\n    local_datas = generator.local_datas\n    client_community = {}\n    for cid, nodes in enumerate(local_datas):\n        for node in nodes: client_community[node] = cid\n    G = generator.train_data\n    total_edges = len(G.edges)\n    subgraphs = [nx.subgraph(G, li) for li in local_datas]\n    local_edges = [len(g.edges) for g in subgraphs]\n    edge_losing_rate = 1.0*(total_edges-sum(local_edges))/total_edges\n    std_edge_num = np.std(local_edges)\n    Gdegree = sum([G.degree[i] for i in G.nodes])/len(G.nodes)\n    subgraphs_degree = [sum([g.degree[i] for i in g.nodes])/len(g.nodes) for g in subgraphs]\n    std_degree = np.std(subgraphs_degree)\n    mean_degree = np.mean(subgraphs_degree)\n    title = \"num_clients:{}\\nglobal_edges:{} | edge_losing_rate:{:.4f} | std_edge_num:{:.4f}\\nglobal_degree:{:.4f} | ave_degree:{:.4f} | std_degree:{:.4f}\".format(len(local_datas), total_edges, edge_losing_rate, std_edge_num, Gdegree, mean_degree, std_degree)\n    colors = [key for key in matplotlib.colors.XKCD_COLORS.keys()]\n    pos = community_layout(G, client_community)\n    nx.draw_networkx_edges(G, pos, edgelist=list(G.edges), width=0.5, alpha=0.5)\n    local_colors = ['r', 'b', 'g']\n    for cid, cnodes in enumerate(local_datas):\n        nx.draw_networkx_nodes(G, pos, cnodes, node_size=800,alpha=0.02,\n                               node_color=local_colors[cid%len(local_colors)],\n                               node_shape='o')\n\n    for cid, cnodes in enumerate(groups):\n        nx.draw_networkx_nodes(G, pos, cnodes, node_size=20,\n                               node_color=colors[cid%len(colors)],\n                               node_shape='&gt;')\n\n    plt.title(title)\n    plt.savefig(os.path.join(task_path, 'res.png'))\n    plt.show()\n    return\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/classification/","title":"classification","text":""},{"location":"Docs/benchmark/toolkits/cv/classification/#flgo.benchmark.toolkits.cv.classification.BuiltinClassGenerator","title":"<code>BuiltinClassGenerator</code>","text":"<p>         Bases: <code>flgo.benchmark.base.BasicTaskGenerator</code></p> <p>Generator for the dataset in torchvision.datasets.</p> <p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>str</code> <p>the name of the benchmark</p> required <code>rawdata_path</code> <code>str</code> <p>the path storing the raw data</p> required <code>builtin_class</code> <code>class</code> <p>class in torchvision.datasets</p> required <code>transform</code> <code>torchvision.transforms.*</code> <p>the transform</p> <code>None</code> Source code in <code>flgo\\benchmark\\toolkits\\cv\\classification\\__init__.py</code> <pre><code>class BuiltinClassGenerator(flgo.benchmark.base.BasicTaskGenerator):\nr\"\"\"\n    Generator for the dataset in torchvision.datasets.\n\n    Args:\n        benchmark (str): the name of the benchmark\n        rawdata_path (str): the path storing the raw data\n        builtin_class (class): class in torchvision.datasets\n        transform (torchvision.transforms.*): the transform\n    \"\"\"\n    def __init__(self, benchmark, rawdata_path, builtin_class, transform=None):\n        super(BuiltinClassGenerator, self).__init__(benchmark, rawdata_path)\n        self.builtin_class = builtin_class\n        self.transform = transform\n        self.additional_option = {}\n        self.train_additional_option = {}\n        self.test_additional_option = {}\n        self.download = True\n\n    def load_data(self):\n        # load the datasets\n        train_default_init_para = {'root': self.rawdata_path, 'download':self.download, 'train':True, 'transform':self.transform}\n        test_default_init_para = {'root': self.rawdata_path, 'download':self.download, 'train':False, 'transform':self.transform}\n        train_default_init_para.update(self.additional_option)\n        train_default_init_para.update(self.train_additional_option)\n        test_default_init_para.update(self.additional_option)\n        test_default_init_para.update(self.test_additional_option)\n        if 'kwargs' not in self.builtin_class.__init__.__annotations__:\n            train_pop_key = [k for k in train_default_init_para.keys() if k not in self.builtin_class.__init__.__annotations__]\n            test_pop_key = [k for k in test_default_init_para.keys() if k not in self.builtin_class.__init__.__annotations__]\n            for k in train_pop_key: train_default_init_para.pop(k)\n            for k in test_pop_key: test_default_init_para.pop(k)\n        # init datasets\n        self.train_data = self.builtin_class(**train_default_init_para)\n        self.test_data = self.builtin_class(**test_default_init_para)\n\n    def partition(self):\n        self.local_datas = self.partitioner(self.train_data)\n        self.num_clients = len(self.local_datas)\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/classification/#flgo.benchmark.toolkits.cv.classification.BuiltinClassPipe","title":"<code>BuiltinClassPipe</code>","text":"<p>         Bases: <code>flgo.benchmark.base.BasicTaskPipe</code></p> <p>TaskPipe for the dataset in torchvision.datasets.</p> <p>Parameters:</p> Name Type Description Default <code>task_path</code> <code>str</code> <p>the path of the task</p> required <code>builtin_class</code> <code>class</code> <p>class in torchvision.datasets</p> required <code>transform</code> <code>torchvision.transforms.*</code> <p>the transform</p> <code>None</code> Source code in <code>flgo\\benchmark\\toolkits\\cv\\classification\\__init__.py</code> <pre><code>class BuiltinClassPipe(flgo.benchmark.base.BasicTaskPipe):\nr\"\"\"\n    TaskPipe for the dataset in torchvision.datasets.\n\n    Args:\n        task_path (str): the path of the task\n        builtin_class (class): class in torchvision.datasets\n        transform (torchvision.transforms.*): the transform\n    \"\"\"\n    class TaskDataset(torch.utils.data.Subset):\n        def __init__(self, dataset, indices, perturbation=None, pin_memory=False):\n            super().__init__(dataset, indices)\n            self.dataset = dataset\n            self.indices = indices\n            self.perturbation = {idx:p for idx, p in zip(indices, perturbation)} if perturbation is not None else None\n            self.pin_memory = pin_memory\n            if not self.pin_memory:\n                self.X = None\n                self.Y = None\n            else:\n                self.X = torch.stack([self.dataset[i][0] for i in self.indices])\n                self.Y = torch.LongTensor([self.dataset[i][1] for i in self.indices])\n\n        def __getitem__(self, idx):\n            if self.X is not None:\n                if self.perturbation is None:\n                    return self.X[idx], self.Y[idx]\n                else:\n                    return self.X[idx]+self.perturbation[self.indices[idx]], self.Y[idx]\n            else:\n                if self.perturbation is None:\n                    if isinstance(idx, list):\n                        return self.dataset[[self.indices[i] for i in idx]]\n                    return self.dataset[self.indices[idx]]\n                else:\n                    return self.dataset[self.indices[idx]][0] + self.perturbation[self.indices[idx]],  self.dataset[self.indices[idx]][1]\n\n    def __init__(self, task_path, buildin_class, transform=None):\n\"\"\"\n        Args:\n            task_path (str): the path of the task\n            builtin_class (class): class in torchvision.datasets\n            transform (torchvision.transforms.*): the transform\n        \"\"\"\n        super(BuiltinClassPipe, self).__init__(task_path)\n        self.builtin_class = buildin_class\n        self.transform = transform\n\n    def save_task(self, generator):\n        client_names = self.gen_client_names(len(generator.local_datas))\n        feddata = {'client_names': client_names, 'server_data': list(range(len(generator.test_data))),  'rawdata_path': generator.rawdata_path, 'additional_option': generator.additional_option, 'train_additional_option':generator.train_additional_option, 'test_additional_option':generator.test_additional_option, }\n        for cid in range(len(client_names)): feddata[client_names[cid]] = {'data': generator.local_datas[cid],}\n        if hasattr(generator.partitioner, 'local_perturbation'): feddata['local_perturbation'] = generator.partitioner.local_perturbation\n        with open(os.path.join(self.task_path, 'data.json'), 'w') as outf:\n            json.dump(feddata, outf)\n        return\n\n    def load_data(self, running_time_option) -&gt; dict:\n        # load the datasets\n        train_default_init_para = {'root': self.feddata['rawdata_path'], 'download':True, 'train':True, 'transform':self.transform}\n        test_default_init_para = {'root': self.feddata['rawdata_path'], 'download':True, 'train':False, 'transform':self.transform}\n        if 'additional_option' in self.feddata.keys():\n            train_default_init_para.update(self.feddata['additional_option'])\n            test_default_init_para.update(self.feddata['additional_option'])\n        if 'train_additional_option' in self.feddata.keys(): train_default_init_para.update(self.feddata['train_additional_option'])\n        if 'test_additional_option' in self.feddata.keys(): test_default_init_para.update(self.feddata['test_additional_option'])\n        if 'kwargs' not in self.builtin_class.__init__.__annotations__:\n            train_pop_key = [k for k in train_default_init_para.keys() if k not in self.builtin_class.__init__.__annotations__]\n            test_pop_key = [k for k in test_default_init_para.keys() if k not in self.builtin_class.__init__.__annotations__]\n            for k in train_pop_key: train_default_init_para.pop(k)\n            for k in test_pop_key: test_default_init_para.pop(k)\n        train_data = self.builtin_class(**train_default_init_para)\n        test_data = self.builtin_class(**test_default_init_para)\n        test_data = self.TaskDataset(test_data, list(range(len(test_data))), None, running_time_option['pin_memory'])\n        # rearrange data for server\n        server_data_test, server_data_val = self.split_dataset(test_data, running_time_option['test_holdout'])\n        task_data = {'server': {'test': server_data_test, 'val': server_data_val}}\n        # rearrange data for clients\n        local_perturbation = self.feddata['local_perturbation'] if 'local_perturbation' in self.feddata.keys() else [None for _ in self.feddata['client_names']]\n        for cid, cname in enumerate(self.feddata['client_names']):\n            cpert = None if  local_perturbation[cid] is None else [torch.tensor(t) for t in local_perturbation[cid]]\n            cdata = self.TaskDataset(train_data, self.feddata[cname]['data'], cpert, running_time_option['pin_memory'])\n            cdata_train, cdata_val = self.split_dataset(cdata, running_time_option['train_holdout'])\n            if running_time_option['train_holdout']&gt;0 and running_time_option['local_test']:\n                cdata_val, cdata_test = self.split_dataset(cdata_val, 0.5)\n            else:\n                cdata_test = None\n            task_data[cname] = {'train':cdata_train, 'val':cdata_val, 'test': cdata_test}\n        return task_data\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/classification/#flgo.benchmark.toolkits.cv.classification.BuiltinClassPipe.__init__","title":"<code>__init__(task_path, buildin_class, transform=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>task_path</code> <code>str</code> <p>the path of the task</p> required <code>builtin_class</code> <code>class</code> <p>class in torchvision.datasets</p> required <code>transform</code> <code>torchvision.transforms.*</code> <p>the transform</p> <code>None</code> Source code in <code>flgo\\benchmark\\toolkits\\cv\\classification\\__init__.py</code> <pre><code>def __init__(self, task_path, buildin_class, transform=None):\n\"\"\"\n    Args:\n        task_path (str): the path of the task\n        builtin_class (class): class in torchvision.datasets\n        transform (torchvision.transforms.*): the transform\n    \"\"\"\n    super(BuiltinClassPipe, self).__init__(task_path)\n    self.builtin_class = buildin_class\n    self.transform = transform\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/classification/#flgo.benchmark.toolkits.cv.classification.GeneralCalculator","title":"<code>GeneralCalculator</code>","text":"<p>         Bases: <code>flgo.benchmark.base.BasicTaskCalculator</code></p> <p>Calculator for the dataset in torchvision.datasets.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>device</p> required <code>optimizer_name</code> <code>str</code> <p>the name of the optimizer</p> <code>'sgd'</code> Source code in <code>flgo\\benchmark\\toolkits\\cv\\classification\\__init__.py</code> <pre><code>class GeneralCalculator(flgo.benchmark.base.BasicTaskCalculator):\nr\"\"\"\n    Calculator for the dataset in torchvision.datasets.\n\n    Args:\n        device (torch.device): device\n        optimizer_name (str): the name of the optimizer\n    \"\"\"\n    def __init__(self, device, optimizer_name='sgd'):\n        super(GeneralCalculator, self).__init__(device, optimizer_name)\n        self.criterion = torch.nn.CrossEntropyLoss()\n        self.DataLoader = torch.utils.data.DataLoader\n\n    def compute_loss(self, model, data):\n\"\"\"\n        Args:\n            model: the model to train\n            data: the training dataset\n        Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n        \"\"\"\n        tdata = self.to_device(data)\n        outputs = model(tdata[0])\n        loss = self.criterion(outputs, tdata[-1])\n        return {'loss': loss}\n\n    @torch.no_grad()\n    def test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n        Metric = [mean_accuracy, mean_loss]\n\n        Args:\n            model:\n            dataset:\n            batch_size:\n        Returns: [mean_accuracy, mean_loss]\n        \"\"\"\n        model.eval()\n        if batch_size==-1:batch_size=len(dataset)\n        data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n        total_loss = 0.0\n        num_correct = 0\n        for batch_id, batch_data in enumerate(data_loader):\n            batch_data = self.to_device(batch_data)\n            outputs = model(batch_data[0])\n            batch_mean_loss = self.criterion(outputs, batch_data[-1]).item()\n            y_pred = outputs.data.max(1, keepdim=True)[1]\n            correct = y_pred.eq(batch_data[-1].data.view_as(y_pred)).long().cpu().sum()\n            num_correct += correct.item()\n            total_loss += batch_mean_loss * len(batch_data[-1])\n        return {'accuracy': 1.0*num_correct/len(dataset), 'loss':total_loss/len(dataset)}\n\n    def to_device(self, data):\n        return data[0].to(self.device), data[1].to(self.device)\n\n    def get_dataloader(self, dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=False, drop_last=False):\n        if self.DataLoader == None:\n            raise NotImplementedError(\"DataLoader Not Found.\")\n        return self.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, collate_fn=self.collect_fn)\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/classification/#flgo.benchmark.toolkits.cv.classification.GeneralCalculator.compute_loss","title":"<code>compute_loss(model, data)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>model</code> <p>the model to train</p> required <code>data</code> <p>the training dataset</p> required Source code in <code>flgo\\benchmark\\toolkits\\cv\\classification\\__init__.py</code> <pre><code>def compute_loss(self, model, data):\n\"\"\"\n    Args:\n        model: the model to train\n        data: the training dataset\n    Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n    \"\"\"\n    tdata = self.to_device(data)\n    outputs = model(tdata[0])\n    loss = self.criterion(outputs, tdata[-1])\n    return {'loss': loss}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/classification/#flgo.benchmark.toolkits.cv.classification.GeneralCalculator.test","title":"<code>test(model, dataset, batch_size=64, num_workers=0, pin_memory=False)</code>","text":"<p>Metric = [mean_accuracy, mean_loss]</p> <p>Parameters:</p> Name Type Description Default <code>model</code> required <code>dataset</code> required <code>batch_size</code> <code>64</code> Source code in <code>flgo\\benchmark\\toolkits\\cv\\classification\\__init__.py</code> <pre><code>@torch.no_grad()\ndef test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n    Metric = [mean_accuracy, mean_loss]\n\n    Args:\n        model:\n        dataset:\n        batch_size:\n    Returns: [mean_accuracy, mean_loss]\n    \"\"\"\n    model.eval()\n    if batch_size==-1:batch_size=len(dataset)\n    data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n    total_loss = 0.0\n    num_correct = 0\n    for batch_id, batch_data in enumerate(data_loader):\n        batch_data = self.to_device(batch_data)\n        outputs = model(batch_data[0])\n        batch_mean_loss = self.criterion(outputs, batch_data[-1]).item()\n        y_pred = outputs.data.max(1, keepdim=True)[1]\n        correct = y_pred.eq(batch_data[-1].data.view_as(y_pred)).long().cpu().sum()\n        num_correct += correct.item()\n        total_loss += batch_mean_loss * len(batch_data[-1])\n    return {'accuracy': 1.0*num_correct/len(dataset), 'loss':total_loss/len(dataset)}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/detection/","title":"detection","text":""},{"location":"Docs/benchmark/toolkits/cv/detection/#flgo.benchmark.toolkits.cv.detection.GeneralCalculator","title":"<code>GeneralCalculator</code>","text":"<p>         Bases: <code>BasicTaskCalculator</code></p> <p>Calculator for the dataset in torchvision.datasets.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>device</p> required <code>optimizer_name</code> <code>str</code> <p>the name of the optimizer</p> <code>'sgd'</code> Source code in <code>flgo\\benchmark\\toolkits\\cv\\detection\\__init__.py</code> <pre><code>class GeneralCalculator(BasicTaskCalculator):\nr\"\"\"\n    Calculator for the dataset in torchvision.datasets.\n\n    Args:\n        device (torch.device): device\n        optimizer_name (str): the name of the optimizer\n    \"\"\"\n    def __init__(self, device, optimizer_name='sgd'):\n        super(GeneralCalculator, self).__init__(device, optimizer_name)\n        self.criterion = torch.nn.CrossEntropyLoss()\n        self.DataLoader = torch.utils.data.DataLoader\n        self.collect_fn = lambda x:tuple(zip(*x))\n\n    def compute_loss(self, model, data):\n\"\"\"\n        Args:\n            model: the model to train\n            data: the training dataset\n        Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n        \"\"\"\n        model.train()\n        tdata = self.to_device(data)\n        output = model(*tdata)\n        return {'loss':sum(list(output.values()))}\n\n    @torch.no_grad()\n    def test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n        dataloader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory, shuffle=False)\n        num_classes = dataset.num_classes\n        model.train()\n        num_samples = 0\n        losses = {}\n        for batch_data in dataloader:\n            batch_data = self.to_device(batch_data)\n            output = model(*batch_data)\n            for k in output:\n                losses[k] = losses.get(k, 0.0) + output[k].item()*len(batch_data[0])\n            losses['all_loss'] = losses.get('all_loss', 0.0) + sum([v.item() for v in output.values()])\n            num_samples += len(batch_data[0])\n        for k,v in losses.items():\n            losses[k]/=num_samples\n        # compute AP\n        predictions = []\n        targets = []\n        model.eval()\n        for images, labels in tqdm(dataloader, desc='Predicting'):\n            images = list(img.to(self.device) for img in images)\n            labels = [{k: v.numpy() for k, v in t.items()} for t in labels]\n            outputs = model(images)\n            for out in outputs:\n                for k in out.keys():\n                    out[k] = out[k].cpu().numpy()\n            predictions.extend(outputs)\n            targets.extend(labels)\n        # count TP for each class\n        dects = {i:[] for i in range(1, num_classes)}\n        gts = {i: {} for i in range(1, num_classes)}\n        for image_id, pred in enumerate(predictions):\n            for det_id in range(len(pred['boxes'])):\n                class_id = int(pred['labels'][det_id])\n                dects[class_id].append([image_id, class_id, pred['scores'][det_id], pred['boxes'][det_id]])\n        for image_id, target in enumerate(targets):\n            for gt_id in range(len(target['boxes'])):\n                class_id = int(target['labels'][gt_id])\n                gts[class_id][image_id] = gts[class_id].get(image_id, []) + [[image_id, class_id, [], target['boxes'][gt_id]]]\n        res = []\n        ious = np.arange(0.5, 1.0, 0.05)\n        tf_dicts = {class_id:{iou_th:{'tp':None, 'fp':None} for iou_th in ious} for class_id in range(1, num_classes)}\n        for class_id in range(1, num_classes):\n            c_dects = sorted(dects[class_id], key=lambda d:d[2], reverse=True)\n            c_gts = gts[class_id]\n            c_tf_dict = tf_dicts[class_id]\n            for iou_th in c_tf_dict:\n                c_tf_dict[iou_th]['tp'] = np.zeros(len(c_dects))\n                c_tf_dict[iou_th]['fp'] = np.zeros(len(c_dects))\n            # c_tp = np.zeros(len(c_dects))\n            # c_fp = np.zeros(len(c_dects))\n            c_npos = sum(list(len(v) for v in c_gts.values()))\n            for det_id in range(len(c_dects)):\n                image_id = c_dects[det_id][0]\n                gt = c_gts[image_id] if image_id in c_gts else []\n                max_iou = -0.1\n                for j in range(len(gt)):\n                    d_iou = iou(gt[j][3], c_dects[det_id][3])\n                    if d_iou&gt; max_iou:\n                        max_iou = d_iou\n                        jmax = j\n                for iou_th in ious:\n                    if max_iou&gt;iou_th:\n                        if iou_th not in c_gts[c_dects[det_id][0]][jmax][2]:\n                            c_gts[c_dects[det_id][0]][jmax][2].append(iou_th)\n                            c_tf_dict[iou_th]['tp'][det_id] = 1\n                            # c_tp[det_id] = 1\n                        else:\n                            c_tf_dict[iou_th]['fp'][det_id] = 1\n                            # c_fp[det_id] = 1\n                    else:\n                        c_tf_dict[iou_th]['fp'][det_id] = 1\n            res_ious = {}\n            for iou_th in ious:\n                c_acc_fp_i = np.cumsum(c_tf_dict[iou_th]['fp'])\n                c_acc_tp_i = np.cumsum(c_tf_dict[iou_th]['tp'])\n                c_recall_i = c_acc_tp_i/c_npos\n                c_precision_i = np.divide(c_acc_tp_i, (c_acc_tp_i + c_acc_fp_i))\n                c_ap_i, c_mpre_i, c_mrec_i, c_ii_i = average_precision(c_recall_i, c_precision_i)\n                res_ious[iou_th] = c_ap_i\n            res.append(res_ious)\n        # mAP@0.5\n        tmp = [np.array([c_res[iou_th] for c_res in res]).mean() for iou_th in ious]\n        mAP_05 = tmp[0]\n        mAP_075 = tmp[5]\n        mAP_05_095 = np.array(tmp).mean()\n        ret = {}\n        ret.update(losses)\n        ret.update({'mAP@.5':float(mAP_05), 'mAP@.75':float(mAP_075), 'mAP@.5:.95':mAP_05_095})\n        return ret\n\n    def to_device(self, data):\n        images, targets = data\n        images = list(img.to(self.device) for img in images)\n        targets = [{k: v.to(self.device) for k, v in t.items()} for t in targets]\n        return images, targets\n\n    def get_dataloader(self, dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=False, drop_last=False):\n        if self.DataLoader == None:\n            raise NotImplementedError(\"DataLoader Not Found.\")\n        return self.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, collate_fn=self.collect_fn)\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/detection/#flgo.benchmark.toolkits.cv.detection.GeneralCalculator.compute_loss","title":"<code>compute_loss(model, data)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>model</code> <p>the model to train</p> required <code>data</code> <p>the training dataset</p> required Source code in <code>flgo\\benchmark\\toolkits\\cv\\detection\\__init__.py</code> <pre><code>def compute_loss(self, model, data):\n\"\"\"\n    Args:\n        model: the model to train\n        data: the training dataset\n    Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n    \"\"\"\n    model.train()\n    tdata = self.to_device(data)\n    output = model(*tdata)\n    return {'loss':sum(list(output.values()))}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/segmentation/","title":"segmentation","text":""},{"location":"Docs/benchmark/toolkits/cv/segmentation/#flgo.benchmark.toolkits.cv.segmentation.BuiltinClassGenerator","title":"<code>BuiltinClassGenerator</code>","text":"<p>         Bases: <code>flgo.benchmark.base.BasicTaskGenerator</code></p> <p>Generator for the dataset in torchvision.datasets.</p> <p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>str</code> <p>the name of the benchmark</p> required <code>rawdata_path</code> <code>str</code> <p>the path storing the raw data</p> required <code>builtin_class</code> <code>class</code> <p>class in torchvision.datasets</p> required <code>transform</code> <code>torchvision.transforms.*</code> <p>the transform</p> required Source code in <code>flgo\\benchmark\\toolkits\\cv\\segmentation\\__init__.py</code> <pre><code>class BuiltinClassGenerator(flgo.benchmark.base.BasicTaskGenerator):\nr\"\"\"\n    Generator for the dataset in torchvision.datasets.\n\n    Args:\n        benchmark (str): the name of the benchmark\n        rawdata_path (str): the path storing the raw data\n        builtin_class (class): class in torchvision.datasets\n        transform (torchvision.transforms.*): the transform\n    \"\"\"\n    def __init__(self, benchmark, rawdata_path, builtin_class, train_transform=None, test_transform=None, num_classes=0):\n        super(BuiltinClassGenerator, self).__init__(benchmark, rawdata_path)\n        self.num_classes = num_classes\n        self.builtin_class = builtin_class\n        self.train_transform = train_transform\n        self.test_transform = test_transform\n        self.additional_option = {}\n        self.train_additional_option = {}\n        self.test_additional_option = {}\n        self.download = True\n\n    def load_data(self):\n        # load the datasets\n        train_default_init_para = {'root': self.rawdata_path, 'download':self.download, 'train':True, 'transforms':self.train_transform}\n        test_default_init_para = {'root': self.rawdata_path, 'download':self.download, 'train':False, 'transforms':self.test_transform}\n        train_default_init_para.update(self.additional_option)\n        train_default_init_para.update(self.train_additional_option)\n        test_default_init_para.update(self.additional_option)\n        test_default_init_para.update(self.test_additional_option)\n        train_pop_key = [k for k in train_default_init_para.keys() if k not in self.builtin_class.__init__.__annotations__]\n        test_pop_key = [k for k in test_default_init_para.keys() if k not in self.builtin_class.__init__.__annotations__]\n        for k in train_pop_key: train_default_init_para.pop(k)\n        for k in test_pop_key: test_default_init_para.pop(k)\n        # init datasets\n        self.train_data = self.builtin_class(**train_default_init_para)\n        self.test_data = self.builtin_class(**test_default_init_para)\n\n    def partition(self):\n        self.local_datas = self.partitioner(self.train_data)\n        self.num_clients = len(self.local_datas)\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/segmentation/#flgo.benchmark.toolkits.cv.segmentation.BuiltinClassPipe","title":"<code>BuiltinClassPipe</code>","text":"<p>         Bases: <code>flgo.benchmark.base.BasicTaskPipe</code></p> <p>TaskPipe for the dataset in torchvision.datasets.</p> <p>Parameters:</p> Name Type Description Default <code>task_path</code> <code>str</code> <p>the path of the task</p> required <code>builtin_class</code> <code>class</code> <p>class in torchvision.datasets</p> required <code>transform</code> <code>torchvision.transforms.*</code> <p>the transform</p> required Source code in <code>flgo\\benchmark\\toolkits\\cv\\segmentation\\__init__.py</code> <pre><code>class BuiltinClassPipe(flgo.benchmark.base.BasicTaskPipe):\nr\"\"\"\n    TaskPipe for the dataset in torchvision.datasets.\n\n    Args:\n        task_path (str): the path of the task\n        builtin_class (class): class in torchvision.datasets\n        transform (torchvision.transforms.*): the transform\n    \"\"\"\n    class TaskDataset(torch.utils.data.Subset):\n        def __init__(self, dataset, indices, perturbation=None, pin_memory=False):\n            super().__init__(dataset, indices)\n            self.dataset = dataset\n            self.indices = indices\n            self.perturbation = {idx: p for idx, p in zip(indices, perturbation)} if perturbation is not None else None\n            self.pin_memory = pin_memory\n            if not self.pin_memory:\n                self.X = None\n                self.Y = None\n            else:\n                self.X = [self.dataset[i][0] for i in self.indices]\n                self.Y = [self.dataset[i][1] for i in self.indices]\n\n        def __getitem__(self, idx):\n            if self.X is not None:\n                if self.perturbation is None:\n                    return self.X[idx], self.Y[idx]\n                else:\n                    return self.X[idx] + self.perturbation[self.indices[idx]], self.Y[idx]\n            else:\n                if self.perturbation is None:\n                    if isinstance(idx, list):\n                        return self.dataset[[self.indices[i] for i in idx]]\n                    return self.dataset[self.indices[idx]]\n                else:\n                    return self.dataset[self.indices[idx]][0] + self.perturbation[self.indices[idx]], \\\n                           self.dataset[self.indices[idx]][1]\n\n    def __init__(self, task_path, buildin_class, train_transform=None, test_transform=None):\n        super(BuiltinClassPipe, self).__init__(task_path)\n        self.builtin_class = buildin_class\n        self.train_transform = train_transform\n        self.test_transform = test_transform\n        self.num_classes = 0\n\n    def save_task(self, generator):\n        client_names = self.gen_client_names(len(generator.local_datas))\n        feddata = {'client_names': client_names, 'server_data': list(range(len(generator.test_data))),  'rawdata_path': generator.rawdata_path, 'additional_option': generator.additional_option, 'train_additional_option':generator.train_additional_option, 'test_additional_option':generator.test_additional_option, 'num_classes':generator.num_classes}\n        for cid in range(len(client_names)): feddata[client_names[cid]] = {'data': generator.local_datas[cid],}\n        with open(os.path.join(self.task_path, 'data.json'), 'w') as outf:\n            json.dump(feddata, outf)\n        return\n\n    def load_data(self, running_time_option) -&gt; dict:\n        # load the datasets\n        train_default_init_para = {'root': self.feddata['rawdata_path'], 'download':True, 'train':True, 'transforms':self.train_transform}\n        test_default_init_para = {'root': self.feddata['rawdata_path'], 'download':True, 'train':False, 'transforms':self.test_transform}\n        if 'additional_option' in self.feddata.keys():\n            train_default_init_para.update(self.feddata['additional_option'])\n            test_default_init_para.update(self.feddata['additional_option'])\n        if 'train_additional_option' in self.feddata.keys(): train_default_init_para.update(self.feddata['train_additional_option'])\n        if 'test_additional_option' in self.feddata.keys(): test_default_init_para.update(self.feddata['test_additional_option'])\n        train_pop_key = [k for k in train_default_init_para.keys() if k not in self.builtin_class.__init__.__annotations__]\n        test_pop_key = [k for k in test_default_init_para.keys() if k not in self.builtin_class.__init__.__annotations__]\n        for k in train_pop_key: train_default_init_para.pop(k)\n        for k in test_pop_key: test_default_init_para.pop(k)\n        train_data = self.builtin_class(**train_default_init_para)\n        test_data = self.builtin_class(**test_default_init_para)\n        test_data = self.TaskDataset(test_data, list(range(len(test_data))), None, running_time_option['pin_memory'])\n        # rearrange data for server\n        server_data_test, server_data_val = self.split_dataset(test_data, running_time_option['test_holdout'])\n        num_classes = self.feddata['num_classes']\n        if server_data_val is not None: server_data_val.num_classes = num_classes\n        if server_data_test is not None: server_data_test.num_classes = num_classes\n        task_data = {'server': {'test': server_data_test, 'val': server_data_val}}\n        # rearrange data for clients\n        local_perturbation = self.feddata['local_perturbation'] if 'local_perturbation' in self.feddata.keys() else [None for _ in self.feddata['client_names']]\n        for cid, cname in enumerate(self.feddata['client_names']):\n            cpert = None if  local_perturbation[cid] is None else [torch.tensor(t) for t in local_perturbation[cid]]\n            cdata = self.TaskDataset(train_data, self.feddata[cname]['data'], cpert, running_time_option['pin_memory'])\n            cdata_train, cdata_val = self.split_dataset(cdata, running_time_option['train_holdout'])\n            if running_time_option['train_holdout']&gt;0 and running_time_option['local_test']:\n                cdata_val, cdata_test = self.split_dataset(cdata_val, 0.5)\n            else:\n                cdata_test = None\n            if cdata_train is not None: cdata_train.num_classes = num_classes\n            if cdata_val is not None: cdata_val.num_classes = num_classes\n            if cdata_test is not None: cdata_test.num_classes = num_classes\n            task_data[cname] = {'train':cdata_train, 'val':cdata_val, 'test': cdata_test}\n        return task_data\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/segmentation/#flgo.benchmark.toolkits.cv.segmentation.GeneralCalculator","title":"<code>GeneralCalculator</code>","text":"<p>         Bases: <code>flgo.benchmark.base.BasicTaskCalculator</code></p> <p>Calculator for the dataset in torchvision.datasets.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>device</p> required <code>optimizer_name</code> <code>str</code> <p>the name of the optimizer</p> <code>'sgd'</code> Source code in <code>flgo\\benchmark\\toolkits\\cv\\segmentation\\__init__.py</code> <pre><code>class GeneralCalculator(flgo.benchmark.base.BasicTaskCalculator):\nr\"\"\"\n    Calculator for the dataset in torchvision.datasets.\n\n    Args:\n        device (torch.device): device\n        optimizer_name (str): the name of the optimizer\n    \"\"\"\n    def __init__(self, device, optimizer_name='sgd'):\n        super(GeneralCalculator, self).__init__(device, optimizer_name)\n        self.DataLoader = torch.utils.data.DataLoader\n        self.criterion = self.compute_criterion\n\n    def compute_criterion(self, inputs, target):\n        if isinstance(inputs, torch.Tensor):\n            return torch.nn.functional.cross_entropy(inputs, target, ignore_index=255)\n        losses = {}\n        for name, x in inputs.items():\n            # if len(x.shape)==len(target.shape): target = torch.squeeze(target, 1)\n            losses[name] = torch.nn.functional.cross_entropy(x, target, ignore_index=255)\n        if len(losses) == 1:\n            return losses[\"out\"]\n        return losses[\"out\"] + 0.5 * losses[\"aux\"]\n\n    def compute_loss(self, model, data):\n\"\"\"\n        Args:\n            model: the model to train\n            data (Any): the training dataset\n        Returns:\n            result (dict): dict of train-one-step's result, which should at least contains the key 'loss'\n        \"\"\"\n        tdata = self.to_device(data)\n        outputs = model(tdata[0])\n        loss = self.criterion(outputs, tdata[-1])\n        return {'loss': loss}\n\n    @torch.no_grad()\n    def test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n        Metric = [mean_accuracy, mean_loss]\n\n        Args:\n            model:\n            dataset:\n            batch_size:\n        Returns: [mean_accuracy, mean_loss]\n        \"\"\"\n        model.eval()\n        confmat = ConfusionMatrix(num_classes=dataset.num_classes)\n        if batch_size==-1:batch_size=len(dataset)\n        data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n        total_loss = 0.0\n        for batch_id, batch_data in tqdm(enumerate(data_loader), desc='Predicting...'):\n            batch_data = self.to_device(batch_data)\n            outputs = model(batch_data[0])\n            loss = self.criterion(outputs, batch_data[-1])\n            # if type(outputs) is not dict: outputs = {'out': outputs}\n            if isinstance(outputs, dict):outputs = outputs['out']\n            confmat.update(batch_data[-1].flatten(), outputs.argmax(1).flatten())\n            total_loss += loss.item()*len(batch_data[0])\n        acc_global, acc, iu = confmat.compute()\n        mAcc = acc_global.item()*100\n        classAcc = (acc*100).tolist()\n        classIoU = (iu * 100).tolist()\n        mIoU = (iu.mean()*100).item()\n        total_loss = total_loss/len(dataset)\n        return {'loss': total_loss,'mAcc':mAcc, 'classAcc':classAcc, 'mIoU':mIoU, 'classIoU':classIoU}\n\n    def to_device(self, data:tuple):\n        return data[0].to(self.device), data[1].to(self.device)\n\n    def get_dataloader(self, dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=False, drop_last=False):\n        if self.DataLoader == None:\n            raise NotImplementedError(\"DataLoader Not Found.\")\n        return self.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, collate_fn=collate_fn)\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/segmentation/#flgo.benchmark.toolkits.cv.segmentation.GeneralCalculator.compute_loss","title":"<code>compute_loss(model, data)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>model</code> <p>the model to train</p> required <code>data</code> <code>Any</code> <p>the training dataset</p> required <p>Returns:</p> Name Type Description <code>result</code> <code>dict</code> <p>dict of train-one-step's result, which should at least contains the key 'loss'</p> Source code in <code>flgo\\benchmark\\toolkits\\cv\\segmentation\\__init__.py</code> <pre><code>def compute_loss(self, model, data):\n\"\"\"\n    Args:\n        model: the model to train\n        data (Any): the training dataset\n    Returns:\n        result (dict): dict of train-one-step's result, which should at least contains the key 'loss'\n    \"\"\"\n    tdata = self.to_device(data)\n    outputs = model(tdata[0])\n    loss = self.criterion(outputs, tdata[-1])\n    return {'loss': loss}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/cv/segmentation/#flgo.benchmark.toolkits.cv.segmentation.GeneralCalculator.test","title":"<code>test(model, dataset, batch_size=64, num_workers=0, pin_memory=False)</code>","text":"<p>Metric = [mean_accuracy, mean_loss]</p> <p>Parameters:</p> Name Type Description Default <code>model</code> required <code>dataset</code> required <code>batch_size</code> <code>64</code> Source code in <code>flgo\\benchmark\\toolkits\\cv\\segmentation\\__init__.py</code> <pre><code>@torch.no_grad()\ndef test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n    Metric = [mean_accuracy, mean_loss]\n\n    Args:\n        model:\n        dataset:\n        batch_size:\n    Returns: [mean_accuracy, mean_loss]\n    \"\"\"\n    model.eval()\n    confmat = ConfusionMatrix(num_classes=dataset.num_classes)\n    if batch_size==-1:batch_size=len(dataset)\n    data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n    total_loss = 0.0\n    for batch_id, batch_data in tqdm(enumerate(data_loader), desc='Predicting...'):\n        batch_data = self.to_device(batch_data)\n        outputs = model(batch_data[0])\n        loss = self.criterion(outputs, batch_data[-1])\n        # if type(outputs) is not dict: outputs = {'out': outputs}\n        if isinstance(outputs, dict):outputs = outputs['out']\n        confmat.update(batch_data[-1].flatten(), outputs.argmax(1).flatten())\n        total_loss += loss.item()*len(batch_data[0])\n    acc_global, acc, iu = confmat.compute()\n    mAcc = acc_global.item()*100\n    classAcc = (acc*100).tolist()\n    classIoU = (iu * 100).tolist()\n    mIoU = (iu.mean()*100).item()\n    total_loss = total_loss/len(dataset)\n    return {'loss': total_loss,'mAcc':mAcc, 'classAcc':classAcc, 'mIoU':mIoU, 'classIoU':classIoU}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/graph/graph_classification/","title":"graph_classification","text":""},{"location":"Docs/benchmark/toolkits/graph/graph_classification/#flgo.benchmark.toolkits.graph.graph_classification.GeneralCalculator","title":"<code>GeneralCalculator</code>","text":"<p>         Bases: <code>BasicTaskCalculator</code></p> Source code in <code>flgo\\benchmark\\toolkits\\graph\\graph_classification\\__init__.py</code> <pre><code>class GeneralCalculator(BasicTaskCalculator):\n    def __init__(self, device, optimizer_name='sgd'):\n        super(GeneralCalculator, self).__init__(device, optimizer_name)\n        self.criterion = torch.nn.CrossEntropyLoss()\n        self.DataLoader = DataLoader\n\n    def compute_loss(self, model, data):\n\"\"\"\n        Args: model: the model to train\n                 data: the training dataset\n        Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n        \"\"\"\n        tdata = self.to_device(data)\n        outputs = model(tdata)\n        loss = self.criterion(outputs, tdata.y)\n        return {'loss': loss}\n\n    @torch.no_grad()\n    def test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n        Metric = [mean_accuracy, mean_loss]\n        Args:\n            dataset:\n                 batch_size:\n        Returns: [mean_accuracy, mean_loss]\n        \"\"\"\n        model.eval()\n        if batch_size == -1: batch_size = len(dataset)\n        data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n        total_loss = 0.0\n        num_correct = 0\n        for batch_id, batch_data in enumerate(data_loader):\n            batch_data = self.to_device(batch_data)\n            outputs = model(batch_data)\n            batch_mean_loss = self.criterion(outputs, batch_data.y).item()\n            y_pred = outputs.data.max(1, keepdim=True)[1]\n            correct = y_pred.eq(batch_data.y.data.view_as(y_pred)).long().cpu().sum()\n            num_correct += correct.item()\n            total_loss += batch_mean_loss * len(batch_data.y)\n        return {'accuracy': 1.0 * num_correct / len(dataset), 'loss': total_loss / len(dataset)}\n\n    def to_device(self, data):\n        return data.to(self.device)\n\n    def get_dataloader(self, dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=False):\n        if self.DataLoader == None:\n            raise NotImplementedError(\"DataLoader Not Found.\")\n        return self.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory)\n</code></pre>"},{"location":"Docs/benchmark/toolkits/graph/graph_classification/#flgo.benchmark.toolkits.graph.graph_classification.GeneralCalculator.compute_loss","title":"<code>compute_loss(model, data)</code>","text":"<p>model: the model to train</p> Name Type Description Default <code>data</code> <p>the training dataset</p> required Source code in <code>flgo\\benchmark\\toolkits\\graph\\graph_classification\\__init__.py</code> <pre><code>def compute_loss(self, model, data):\n\"\"\"\n    Args: model: the model to train\n             data: the training dataset\n    Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n    \"\"\"\n    tdata = self.to_device(data)\n    outputs = model(tdata)\n    loss = self.criterion(outputs, tdata.y)\n    return {'loss': loss}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/graph/graph_classification/#flgo.benchmark.toolkits.graph.graph_classification.GeneralCalculator.test","title":"<code>test(model, dataset, batch_size=64, num_workers=0, pin_memory=False)</code>","text":"<p>Metric = [mean_accuracy, mean_loss]</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <p>batch_size:</p> required Source code in <code>flgo\\benchmark\\toolkits\\graph\\graph_classification\\__init__.py</code> <pre><code>@torch.no_grad()\ndef test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n    Metric = [mean_accuracy, mean_loss]\n    Args:\n        dataset:\n             batch_size:\n    Returns: [mean_accuracy, mean_loss]\n    \"\"\"\n    model.eval()\n    if batch_size == -1: batch_size = len(dataset)\n    data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n    total_loss = 0.0\n    num_correct = 0\n    for batch_id, batch_data in enumerate(data_loader):\n        batch_data = self.to_device(batch_data)\n        outputs = model(batch_data)\n        batch_mean_loss = self.criterion(outputs, batch_data.y).item()\n        y_pred = outputs.data.max(1, keepdim=True)[1]\n        correct = y_pred.eq(batch_data.y.data.view_as(y_pred)).long().cpu().sum()\n        num_correct += correct.item()\n        total_loss += batch_mean_loss * len(batch_data.y)\n    return {'accuracy': 1.0 * num_correct / len(dataset), 'loss': total_loss / len(dataset)}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/graph/link_prediction/","title":"link_prediction","text":""},{"location":"Docs/benchmark/toolkits/graph/node_classification/","title":"node_classification","text":""},{"location":"Docs/benchmark/toolkits/nlp/classification/","title":"classification","text":""},{"location":"Docs/benchmark/toolkits/nlp/classification/#flgo.benchmark.toolkits.nlp.classification.GeneralCalculator","title":"<code>GeneralCalculator</code>","text":"<p>         Bases: <code>BasicTaskCalculator</code></p> <p>Calculator for the dataset in torchvision.datasets.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>torch.device</code> <p>device</p> required <code>optimizer_name</code> <code>str</code> <p>the name of the optimizer</p> <code>'sgd'</code> Source code in <code>flgo\\benchmark\\toolkits\\nlp\\classification\\__init__.py</code> <pre><code>class GeneralCalculator(BasicTaskCalculator):\nr\"\"\"\n    Calculator for the dataset in torchvision.datasets.\n\n    Args:\n        device (torch.device): device\n        optimizer_name (str): the name of the optimizer\n    \"\"\"\n    def __init__(self, device, optimizer_name='sgd'):\n        super(GeneralCalculator, self).__init__(device, optimizer_name)\n        self.criterion = torch.nn.CrossEntropyLoss()\n        self.DataLoader = torch.utils.data.DataLoader\n\n    def compute_loss(self, model, data):\n\"\"\"\n        Args:\n            model: the model to train\n            data: the training dataset\n        Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n        \"\"\"\n        text, label  = self.to_device(data)\n        outputs = model(text)\n        loss = self.criterion(outputs, label)\n        return {'loss': loss}\n\n    @torch.no_grad()\n    def test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n        Metric = [mean_accuracy, mean_loss]\n\n        Args:\n            model:\n            dataset:\n            batch_size:\n        Returns: [mean_accuracy, mean_loss]\n        \"\"\"\n        model.eval()\n        if batch_size==-1:batch_size=len(dataset)\n        data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n        total_loss = 0.0\n        num_correct = 0\n        for batch_id, batch_data in enumerate(data_loader):\n            batch_data = self.to_device(batch_data)\n            outputs = model(batch_data[0])\n            batch_mean_loss = self.criterion(outputs, batch_data[1]).item()\n            # y_pred = outputs.data.max(1, keepdim=True)[1]\n            # correct = y_pred.eq(batch_data[-1].data.view_as(y_pred)).long().cpu().sum()\n            num_correct += (outputs.argmax(1)==batch_data[1]).sum().item()\n            total_loss += batch_mean_loss * len(batch_data[0])\n        return {'accuracy': 1.0*num_correct/len(dataset), 'loss':total_loss/len(dataset)}\n\n    def to_device(self, data):\n        res = []\n        for i in range(len(data)):\n            if isinstance(data[i], torch.Tensor):\n                di = data[i].to(self.device)\n            elif isinstance(data[i], list):\n                di = [d.to(self.device) for d in data[i]]\n            else:\n                raise TypeError('data should be either of type list or torch.Tensor')\n            res.append(di)\n        return tuple(res)\n\n    def get_dataloader(self, dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=False, drop_last=False):\n        if self.DataLoader == None:\n            raise NotImplementedError(\"DataLoader Not Found.\")\n        return self.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, collate_fn=self.collect_fn)\n</code></pre>"},{"location":"Docs/benchmark/toolkits/nlp/classification/#flgo.benchmark.toolkits.nlp.classification.GeneralCalculator.compute_loss","title":"<code>compute_loss(model, data)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>model</code> <p>the model to train</p> required <code>data</code> <p>the training dataset</p> required Source code in <code>flgo\\benchmark\\toolkits\\nlp\\classification\\__init__.py</code> <pre><code>def compute_loss(self, model, data):\n\"\"\"\n    Args:\n        model: the model to train\n        data: the training dataset\n    Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n    \"\"\"\n    text, label  = self.to_device(data)\n    outputs = model(text)\n    loss = self.criterion(outputs, label)\n    return {'loss': loss}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/nlp/classification/#flgo.benchmark.toolkits.nlp.classification.GeneralCalculator.test","title":"<code>test(model, dataset, batch_size=64, num_workers=0, pin_memory=False)</code>","text":"<p>Metric = [mean_accuracy, mean_loss]</p> <p>Parameters:</p> Name Type Description Default <code>model</code> required <code>dataset</code> required <code>batch_size</code> <code>64</code> Source code in <code>flgo\\benchmark\\toolkits\\nlp\\classification\\__init__.py</code> <pre><code>@torch.no_grad()\ndef test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n    Metric = [mean_accuracy, mean_loss]\n\n    Args:\n        model:\n        dataset:\n        batch_size:\n    Returns: [mean_accuracy, mean_loss]\n    \"\"\"\n    model.eval()\n    if batch_size==-1:batch_size=len(dataset)\n    data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n    total_loss = 0.0\n    num_correct = 0\n    for batch_id, batch_data in enumerate(data_loader):\n        batch_data = self.to_device(batch_data)\n        outputs = model(batch_data[0])\n        batch_mean_loss = self.criterion(outputs, batch_data[1]).item()\n        # y_pred = outputs.data.max(1, keepdim=True)[1]\n        # correct = y_pred.eq(batch_data[-1].data.view_as(y_pred)).long().cpu().sum()\n        num_correct += (outputs.argmax(1)==batch_data[1]).sum().item()\n        total_loss += batch_mean_loss * len(batch_data[0])\n    return {'accuracy': 1.0*num_correct/len(dataset), 'loss':total_loss/len(dataset)}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/nlp/language_modeling/","title":"language_modeling","text":""},{"location":"Docs/benchmark/toolkits/nlp/translation/","title":"translation","text":""},{"location":"Docs/benchmark/toolkits/nlp/translation/#flgo.benchmark.toolkits.nlp.translation.GeneralCalculator","title":"<code>GeneralCalculator</code>","text":"<p>         Bases: <code>BasicTaskCalculator</code></p> Source code in <code>flgo\\benchmark\\toolkits\\nlp\\translation\\__init__.py</code> <pre><code>class GeneralCalculator(BasicTaskCalculator):\n    def __init__(self, device, optimizer_name='sgd'):\n        super(GeneralCalculator, self).__init__(device, optimizer_name)\n        self.DataLoader = torch.utils.data.DataLoader\n\n    def criterion(self, outputs, targets, ignore_index=-100):\n        loss_func = torch.nn.CrossEntropyLoss(ignore_index=ignore_index)\n        return loss_func(outputs[1:].view(-1, outputs.shape[-1]), targets[1:].view(-1))\n\n    def compute_loss(self, model, data):\n\"\"\"\n        Args:\n            model: the model to train\n            data: the training dataset\n        Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n        \"\"\"\n        sources, targets = self.to_device(data)\n        outputs = model(sources, targets)\n        loss = self.criterion(outputs, targets, model.ignore_index if hasattr(model, 'ignore_index') else -100)\n        return {'loss': loss}\n\n    @torch.no_grad()\n    def test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n        Metric = [mean_accuracy, mean_loss]\n\n        Args:\n            model:\n            dataset:\n            batch_size:\n        Returns: [mean_accuracy, mean_loss]\n        \"\"\"\n        model.eval()\n        if batch_size==-1:batch_size=len(dataset)\n        data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n        total_loss = 0.0\n        for batch_id, batch_data in enumerate(data_loader):\n            batch_data = self.to_device(batch_data)\n            outputs = model(batch_data[0], batch_data[1])\n            batch_mean_loss = self.criterion(outputs, batch_data[1], model.ignore_index if hasattr(model, 'ignore_index') else -100).item()\n            total_loss += batch_mean_loss * len(batch_data[-1])\n        return {'loss':total_loss/len(dataset)}\n\n    def to_device(self, data):\n        return data[0].to(self.device), data[1].to(self.device)\n\n    def get_dataloader(self, dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=False, drop_last=False):\n        if self.DataLoader == None:\n            raise NotImplementedError(\"DataLoader Not Found.\")\n        return self.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last, collate_fn=self.collect_fn)\n</code></pre>"},{"location":"Docs/benchmark/toolkits/nlp/translation/#flgo.benchmark.toolkits.nlp.translation.GeneralCalculator.compute_loss","title":"<code>compute_loss(model, data)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>model</code> <p>the model to train</p> required <code>data</code> <p>the training dataset</p> required Source code in <code>flgo\\benchmark\\toolkits\\nlp\\translation\\__init__.py</code> <pre><code>def compute_loss(self, model, data):\n\"\"\"\n    Args:\n        model: the model to train\n        data: the training dataset\n    Returns: dict of train-one-step's result, which should at least contains the key 'loss'\n    \"\"\"\n    sources, targets = self.to_device(data)\n    outputs = model(sources, targets)\n    loss = self.criterion(outputs, targets, model.ignore_index if hasattr(model, 'ignore_index') else -100)\n    return {'loss': loss}\n</code></pre>"},{"location":"Docs/benchmark/toolkits/nlp/translation/#flgo.benchmark.toolkits.nlp.translation.GeneralCalculator.test","title":"<code>test(model, dataset, batch_size=64, num_workers=0, pin_memory=False)</code>","text":"<p>Metric = [mean_accuracy, mean_loss]</p> <p>Parameters:</p> Name Type Description Default <code>model</code> required <code>dataset</code> required <code>batch_size</code> <code>64</code> Source code in <code>flgo\\benchmark\\toolkits\\nlp\\translation\\__init__.py</code> <pre><code>@torch.no_grad()\ndef test(self, model, dataset, batch_size=64, num_workers=0, pin_memory=False):\n\"\"\"\n    Metric = [mean_accuracy, mean_loss]\n\n    Args:\n        model:\n        dataset:\n        batch_size:\n    Returns: [mean_accuracy, mean_loss]\n    \"\"\"\n    model.eval()\n    if batch_size==-1:batch_size=len(dataset)\n    data_loader = self.get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=pin_memory)\n    total_loss = 0.0\n    for batch_id, batch_data in enumerate(data_loader):\n        batch_data = self.to_device(batch_data)\n        outputs = model(batch_data[0], batch_data[1])\n        batch_mean_loss = self.criterion(outputs, batch_data[1], model.ignore_index if hasattr(model, 'ignore_index') else -100).item()\n        total_loss += batch_mean_loss * len(batch_data[-1])\n    return {'loss':total_loss/len(dataset)}\n</code></pre>"},{"location":"Docs/experiment/","title":"Index","text":""},{"location":"Docs/experiment/#flgo.experiment","title":"<code>flgo.experiment</code>","text":"<p>This module is created for various experimental purposes</p>"},{"location":"Docs/experiment/analyzer/","title":"flgo.experiment.analyzer","text":"<p>This module is to analyze the training results saved by Logger. To use this module, a analysis plan should be designed (i.e. dict):     Selector: select the records according to the task, algorithm and options of the task     Painter: draw graphic of the selected records     Table: output some statistic of the selected records on the console</p> <p>The basic usage is to build a plan dict and pass it to flgo.experiment.analyzer</p> <p>The following three examples show how to build a customized plan:</p> How to define a Selector? <p>{'Selector': {     'task': task_path,                # all the analysis will be conducted on a single task     'header': ['fedavg'],             # only the records where the names of algorithms are in <code>header</code> will be selected      'filter': {'LR':'&lt;0.1'}          # only the records whose options satisfy the conditions in <code>filter</code> will be selected     'legend_with': ['LR', 'B', 'E']   # all the graphic will show the legends of records according to <code>legend_with</code> }, ...}</p> How to define a Painter? <p>Each <code>Painter</code> is a dict of different types of graphic (e.g. Curve, Bar and Scatter). In each types of graphic, the value is a list of figures, where each figure is defined by a dict like {'args':{...}, 'obj_option':{}, 'fig_option':{...}}</p> <pre><code>{...,\n'Painter':{\n        'Curve':[\n            {'args':{'x':'communication_round', 'y':'val_loss'}, },\n            {...}\n        ]\n    },\n...,\n}\n</code></pre> How to define a Table? <p>{..., 'Table':{         'min_value':[             {'x':'val_loss'},             ...             ]     } }</p> <p>A standard analysis plan usually consists of the above three parts, and <code>Painter</code> and <code>Table</code> are both optional</p>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer--plan-selector-painter-table","title":"plan = {'Selector':..., 'Painter':..., 'Table':...,}","text":"<p>flgo.experiment.analyzer.show(plan)</p>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Bar","title":"<code>Bar</code>","text":"<p>         Bases: <code>PaintObject</code></p> <p>Bar Object</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class Bar(PaintObject):\n\"\"\"Bar Object\"\"\"\n    def __init__(self, rec, args,  obj_option):\n        super(Bar, self).__init__(rec, args, obj_option, 'bar')\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Curve","title":"<code>Curve</code>","text":"<p>         Bases: <code>PaintObject</code></p> <p>Curve Object</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class Curve(PaintObject):\n\"\"\"Curve Object\"\"\"\n    def __init__(self, rec, args,  obj_option):\n        super(Curve, self).__init__(rec, args, obj_option, 'plot')\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.GroupCurve","title":"<code>GroupCurve</code>","text":"<p>         Bases: <code>PaintObject</code></p> <p>Group Curve Object</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class GroupCurve(PaintObject):\n\"\"\"Group Curve Object\"\"\"\n    def __init__(self, rec, args,  obj_option):\n        super(GroupCurve, self).__init__(rec, args, obj_option, '')\n\n    def draw(self, ax):\n        x = self.rec.data[self.args['x']]\n        ykey = self.args['y']\n        mean_y = self.rec.data[ykey]\n        min_y = np.min(np.array([d[ykey] for d in self.rec.datas]), axis=0)\n        max_y = np.max(np.array([d[ykey] for d in self.rec.datas]), axis=0)\n        ax.plot(x, mean_y, label=self.rec.data['label'])\n        ax.fill_between(x, max_y, min_y, alpha=0.3)\n        ax.legend()\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.PaintObject","title":"<code>PaintObject</code>","text":"<p>The basic PaintObject. Each PaintObject should inherent from this class. And the method self.draw should be overwritten if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>rec</code> <code>Record</code> <p>the record</p> required <code>args</code> <code>dict</code> <p>the painting arguments</p> required <code>obj_option</code> <code>dict</code> <p>the personal option for each object</p> required <code>draw_func</code> <code>str</code> <p>optional, the function name. All the subclass of this class won't claim this parameter.</p> required <p>Example:</p> <pre><code>    &gt;&gt;&gt; class GroupCurve(PaintObject):\n    ...     def __init__(self, rec, args,  obj_option):\n    ...         super(GroupCurve, self).__init__(rec, args, obj_option, '')\n    ...\n    ...     def draw(self, ax):\n    ...         x = self.rec.data[self.args['x']]\n    ...         ykey = self.args['y']\n    ...         mean_y = self.rec.data[ykey]\n    ...         min_y = np.min(np.array([d[ykey] for d in self.rec.datas]), axis=0)\n    ...         max_y = np.max(np.array([d[ykey] for d in self.rec.datas]), axis=0)\n    ...         ax.plot(x, mean_y, label=self.rec.data['label'])\n    ...         ax.fill_between(x, max_y, min_y, alpha=0.3)\n    ...         ax.legend()\n</code></pre> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class PaintObject:\nr\"\"\"\n    The basic PaintObject. Each PaintObject should inherent from this class.\n    And the method self.draw should be overwritten if necessary.\n\n    Args:\n        rec (Record): the record\n        args (dict): the painting arguments\n        obj_option (dict): the personal option for each object\n        draw_func (str): optional, the function name. All the subclass of this class won't claim this parameter.\n\n    Example:\n    ```python\n        &gt;&gt;&gt; class GroupCurve(PaintObject):\n        ...     def __init__(self, rec, args,  obj_option):\n        ...         super(GroupCurve, self).__init__(rec, args, obj_option, '')\n        ...\n        ...     def draw(self, ax):\n        ...         x = self.rec.data[self.args['x']]\n        ...         ykey = self.args['y']\n        ...         mean_y = self.rec.data[ykey]\n        ...         min_y = np.min(np.array([d[ykey] for d in self.rec.datas]), axis=0)\n        ...         max_y = np.max(np.array([d[ykey] for d in self.rec.datas]), axis=0)\n        ...         ax.plot(x, mean_y, label=self.rec.data['label'])\n        ...         ax.fill_between(x, max_y, min_y, alpha=0.3)\n        ...         ax.legend()\n    ```\n    \"\"\"\n    def __init__(self, rec: Record, args: dict,  obj_option: dict, draw_func: str):\n        self.rec = rec\n        self.args = args\n        self.obj_option = obj_option\n        self.draw_func = draw_func\n        self.para = (rec.data[v] for v in args.values())\n        self.with_legend = True\n\n    def draw(self, ax):\n        if 'label' in self.obj_option.keys() or 'label' not in self.rec.data.keys():\n            eval('ax.'+str(self.draw_func)+'(*self.para, **self.obj_option)')\n        else:\n            eval('ax.' + str(self.draw_func) + '(*self.para, **self.obj_option, label=self.rec.data[\"label\"])')\n        if self.with_legend: eval('ax.legend()')\n        return\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Painter","title":"<code>Painter</code>","text":"<p>Draw the information in records into figures</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list</code> <p>a list of instances of Record(...)</p> required <code>save_text</code> <code>bool</code> <p>whether to store the figures into the disk</p> required <code>path</code> <code>str</code> <p>the storing path</p> <code>'.'</code> <code>format</code> <code>str</code> <p>the storing format</p> <code>'png'</code> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class Painter:\nr\"\"\"\n    Draw the information in records into figures\n\n    Args:\n        records (list): a list of instances of Record(...)\n        save_text (bool): whether to store the figures into the disk\n        path (str): the storing path\n        format (str): the storing format\n    \"\"\"\n    def __init__(self, records: list, save_figure=False, path:str='.', format='png'):\n        self.records = records\n        self.save_figure = save_figure\n        self.path = path\n        self.format = format\n\n    def create_figure(self, object_class, fig_config):\nr\"\"\"\n        Create figure according to the PaintObject and figure configurations.\n        For each record k, a PaintObject(record, object_option) will be created\n        for later drawing. Then, a figure will be created by fig_option and all \n        the PaintObject will be put onto the figure. \n        The fig_config should be a dict like:\n            {\n                'args':{...}, # ploting arguments for each record\n                'obj_option':{...}, # assign each PaintObject with different attributes like color, label...\n                'fig_option':{...}, # the options of the figure such as title, xlabel, xlim, no_legend\n            }\n\n        Args:\n            object_class (class|str): the types of the obejct to be drawed\n            fig_config (dict): the drawing configuration\n\n        Example:\n        ```python\n            &gt;&gt;&gt; p=Painter(records)\n            &gt;&gt;&gt; p.create_figure(Curve, {'args':{'x':'communication_round', 'y':'val_loss'}})\n        ```\n        \"\"\"\n        object_class = eval(object_class) if type(object_class) is str else object_class\n        if 'split' in  fig_config.keys():\n            cols = fig_config['split']['cols'] if 'cols' in fig_config['split'] else 4\n            rows = int(math.ceil(len(self.records)/cols))\n            cols = min(len(self.records), cols)\n            if 'figsize' in fig_config['split']:\n                new_fig_size = (fig_config['split']['figsize'][0], fig_config['split']['figsize'][1])\n            else:\n                fig_size = mpl.rcParams['figure.figsize']\n                new_fig_size = (fig_size[0] * cols, fig_size[1] * rows)\n            fig, axs = plt.subplots(rows, cols, figsize=new_fig_size)\n            if type(axs) is np.ndarray:\n                axs = axs.reshape(-1)\n            else:\n                axs = [axs]\n        else:\n            fig, ax = plt.subplots()\n            axs = [ax for _ in self.records]\n        args = fig_config['args']\n        obj_options = self._generate_obj_option(fig_config['obj_option']) if 'obj_option' in fig_config.keys() else [{} for _ in self.records]\n        objects = [object_class(rec, args, obj_option) for rec, obj_option in zip(self.records, obj_options)]\n        for ob,axi in zip(objects, axs):\n            ob.draw(axi)\n        if 'fig_option' in fig_config.keys():\n            if 'no_legend' in fig_config['fig_option'].keys():\n                for obj in objects: obj.with_legend = False\n            for option_name in fig_config['fig_option']:\n                if option_name=='no_legend': continue\n                if 'split' in fig_config.keys():\n                    if type(fig_config['fig_option'][option_name]) is str:\n                        for ax in axs:\n                            eval('ax.set_'+option_name+\"('{}')\".format(fig_config['fig_option'][option_name]))\n                    else:\n                        for ax in axs:\n                            eval('ax.set_'+option_name+\"({})\".format(fig_config['fig_option'][option_name]))\n                else:\n                    if type(fig_config['fig_option'][option_name]) is str:\n                        eval('plt.'+option_name+\"('{}')\".format(fig_config['fig_option'][option_name]))\n                    else:\n                        eval('plt.' + option_name + \"({})\".format(fig_config['fig_option'][option_name]))\n        filename = None\n        if self.save_figure:\n            filename = str(uuid.uuid4())+'.'+self.format\n            plt.savefig(os.path.join(self.path, filename))\n        plt.show()\n        return filename\n\n    def _generate_obj_option(self, raw_obj_option: dict):\n        for k in raw_obj_option:\n            if type(raw_obj_option[k]) is list:\n                assert len(raw_obj_option[k]) &gt;= len(self.records)\n                raw_obj_option[k] = raw_obj_option[k][:len(self.records)]\n            else:\n                raw_obj_option[k] = [raw_obj_option[k] for _ in self.records]\n        return [{k:v[i] for k,v in raw_obj_option.items()} for i in range(len(self.records))]\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Painter.create_figure","title":"<code>create_figure(object_class, fig_config)</code>","text":"<p>Create figure according to the PaintObject and figure configurations. For each record k, a PaintObject(record, object_option) will be created for later drawing. Then, a figure will be created by fig_option and all  the PaintObject will be put onto the figure. </p> The fig_config should be a dict like <p>{     'args':{...}, # ploting arguments for each record     'obj_option':{...}, # assign each PaintObject with different attributes like color, label...     'fig_option':{...}, # the options of the figure such as title, xlabel, xlim, no_legend }</p> <p>Parameters:</p> Name Type Description Default <code>object_class</code> <code>class|str</code> <p>the types of the obejct to be drawed</p> required <code>fig_config</code> <code>dict</code> <p>the drawing configuration</p> required <p>Example:</p> <pre><code>    &gt;&gt;&gt; p=Painter(records)\n    &gt;&gt;&gt; p.create_figure(Curve, {'args':{'x':'communication_round', 'y':'val_loss'}})\n</code></pre> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def create_figure(self, object_class, fig_config):\nr\"\"\"\n    Create figure according to the PaintObject and figure configurations.\n    For each record k, a PaintObject(record, object_option) will be created\n    for later drawing. Then, a figure will be created by fig_option and all \n    the PaintObject will be put onto the figure. \n    The fig_config should be a dict like:\n        {\n            'args':{...}, # ploting arguments for each record\n            'obj_option':{...}, # assign each PaintObject with different attributes like color, label...\n            'fig_option':{...}, # the options of the figure such as title, xlabel, xlim, no_legend\n        }\n\n    Args:\n        object_class (class|str): the types of the obejct to be drawed\n        fig_config (dict): the drawing configuration\n\n    Example:\n    ```python\n        &gt;&gt;&gt; p=Painter(records)\n        &gt;&gt;&gt; p.create_figure(Curve, {'args':{'x':'communication_round', 'y':'val_loss'}})\n    ```\n    \"\"\"\n    object_class = eval(object_class) if type(object_class) is str else object_class\n    if 'split' in  fig_config.keys():\n        cols = fig_config['split']['cols'] if 'cols' in fig_config['split'] else 4\n        rows = int(math.ceil(len(self.records)/cols))\n        cols = min(len(self.records), cols)\n        if 'figsize' in fig_config['split']:\n            new_fig_size = (fig_config['split']['figsize'][0], fig_config['split']['figsize'][1])\n        else:\n            fig_size = mpl.rcParams['figure.figsize']\n            new_fig_size = (fig_size[0] * cols, fig_size[1] * rows)\n        fig, axs = plt.subplots(rows, cols, figsize=new_fig_size)\n        if type(axs) is np.ndarray:\n            axs = axs.reshape(-1)\n        else:\n            axs = [axs]\n    else:\n        fig, ax = plt.subplots()\n        axs = [ax for _ in self.records]\n    args = fig_config['args']\n    obj_options = self._generate_obj_option(fig_config['obj_option']) if 'obj_option' in fig_config.keys() else [{} for _ in self.records]\n    objects = [object_class(rec, args, obj_option) for rec, obj_option in zip(self.records, obj_options)]\n    for ob,axi in zip(objects, axs):\n        ob.draw(axi)\n    if 'fig_option' in fig_config.keys():\n        if 'no_legend' in fig_config['fig_option'].keys():\n            for obj in objects: obj.with_legend = False\n        for option_name in fig_config['fig_option']:\n            if option_name=='no_legend': continue\n            if 'split' in fig_config.keys():\n                if type(fig_config['fig_option'][option_name]) is str:\n                    for ax in axs:\n                        eval('ax.set_'+option_name+\"('{}')\".format(fig_config['fig_option'][option_name]))\n                else:\n                    for ax in axs:\n                        eval('ax.set_'+option_name+\"({})\".format(fig_config['fig_option'][option_name]))\n            else:\n                if type(fig_config['fig_option'][option_name]) is str:\n                    eval('plt.'+option_name+\"('{}')\".format(fig_config['fig_option'][option_name]))\n                else:\n                    eval('plt.' + option_name + \"({})\".format(fig_config['fig_option'][option_name]))\n    filename = None\n    if self.save_figure:\n        filename = str(uuid.uuid4())+'.'+self.format\n        plt.savefig(os.path.join(self.path, filename))\n    plt.show()\n    return filename\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Record","title":"<code>Record</code>","text":"<p>Read the record that is stored by each runner into the memory according to the task and the name.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>str</code> <p>the path of the task</p> required <code>name</code> <code>str</code> <p>the name of the saved record</p> required Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class Record:\nr\"\"\"\n    Read the record that is stored by each runner into the memory according\n    to the task and the name.\n\n    Args:\n        task (str): the path of the task\n        name (str): the name of the saved record\n    \"\"\"\n    def __init__(self, task, name):\n        self.task = task\n        self.name = name\n        self.rec_path = os.path.join(task, 'record', name)\n        with open(self.rec_path, 'r') as inf:\n            s_inf = inf.read()\n            rec = json.loads(s_inf)\n        self.data = rec\n        self.datas = [self.data]\n        self.set_communication_round()\n        self.set_client_id()\n\n    def set_communication_round(self):\n        num_rounds = self.data['option']['num_rounds']\n        eval_interval = self.data['option']['eval_interval']\n        x = [0]\n        for round in range(1, num_rounds + 1):\n            if eval_interval &gt; 0 and (round == 0 or round % eval_interval == 0):\n                x.append(round)\n            if self.data['option']['early_stop'] &gt; 0 and 'val_loss' in self.data.keys() and len(x) &gt;= len(self.data['val_loss']):\n                break\n        self.data['communication_round'] = x\n\n    def set_client_id(self):\n        with open(os.path.join(self.task, 'info')) as inf:\n            task_info = json.load(inf)\n            if 'num_clients' in task_info.keys():\n                N = int(task_info['num_clients'])\n            elif 'num_parties' in task_info.keys():\n                N = int(task_info['num_parties'])\n            else:\n                N = 0\n        self.data['client_id'] = [cid for cid in range(N)]\n\n    def set_legend(self, legend_with = []):\n        if len(legend_with)==0: self.data['label'] = []\n        self.data['label'] = [self.name[:self.name.find('_M')]]\n        for key in legend_with:\n            val = key + self.get_key_from_name(key)\n            self.data['label'].append(val)\n        self.data['label'] = ' '.join(self.data['label'])\n\n    def get_key_from_name(self, key):\n        if key == '': return ''\n        value_start = self.name.find('_' + key) + len(key) + 1\n        value_end = self.name.find('_', value_start)\n        return self.name[value_start:value_end]\n\n    @classmethod\n    def create_group(cls, rec_list: list):\nr\"\"\"\n        Organize the records in rec_list into a group-level Record,\n        where there will be a new attribute named Record.datas. And\n        the values in Record.data will be replaced by the mean values\n        of that in Record.datas\n\n        Args:\n            rec_list (list): a list of Record(...)\n\n        Returns:\n            a new group-level Record\n        \"\"\"\n        if len(rec_list) == 0: return None\n        r = copy.deepcopy(rec_list[0])\n        r.datas = [rec.data for rec in rec_list]\n        for key in r.data.keys():\n            if key == 'option': continue\n            try:\n                if type(r.data[key]) is list:\n                    ave_data = np.array([np.array(rdata[key]) for rdata in r.datas])\n                    r.data[key] = ave_data.mean(axis=0)\n            except:\n                continue\n        return r\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Record.create_group","title":"<code>create_group(rec_list)</code>  <code>classmethod</code>","text":"<p>Organize the records in rec_list into a group-level Record, where there will be a new attribute named Record.datas. And the values in Record.data will be replaced by the mean values of that in Record.datas</p> <p>Parameters:</p> Name Type Description Default <code>rec_list</code> <code>list</code> <p>a list of Record(...)</p> required <p>Returns:</p> Type Description <p>a new group-level Record</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>@classmethod\ndef create_group(cls, rec_list: list):\nr\"\"\"\n    Organize the records in rec_list into a group-level Record,\n    where there will be a new attribute named Record.datas. And\n    the values in Record.data will be replaced by the mean values\n    of that in Record.datas\n\n    Args:\n        rec_list (list): a list of Record(...)\n\n    Returns:\n        a new group-level Record\n    \"\"\"\n    if len(rec_list) == 0: return None\n    r = copy.deepcopy(rec_list[0])\n    r.datas = [rec.data for rec in rec_list]\n    for key in r.data.keys():\n        if key == 'option': continue\n        try:\n            if type(r.data[key]) is list:\n                ave_data = np.array([np.array(rdata[key]) for rdata in r.datas])\n                r.data[key] = ave_data.mean(axis=0)\n        except:\n            continue\n    return r\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Scatter","title":"<code>Scatter</code>","text":"<p>         Bases: <code>PaintObject</code></p> <p>Scatter Obejct</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class Scatter(PaintObject):\n\"\"\"Scatter Obejct\"\"\"\n    def __init__(self, rec, args,  obj_option):\n        super(Scatter, self).__init__(rec, args, obj_option, 'scatter')\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Selector","title":"<code>Selector</code>","text":"<p>Filter the records and read them into memory accoring to customized settings</p> <p>Parameters:</p> Name Type Description Default <code>selector_config</code> <code>dict</code> <p>the dictionary that is used to filter records</p> required <p>Example:</p> <pre><code>    &gt;&gt;&gt; task='./my_task'\n    &gt;&gt;&gt; selector = Selector({'task':task, 'header':['fedavg'], 'filter':{'lr':0.1}})\n    &gt;&gt;&gt; selector.records[task]\n    &gt;&gt;&gt; # selector.records is a dict where selector.records[task] is a list\n    &gt;&gt;&gt; # of the records that pass the filter\n</code></pre> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class Selector:\nr\"\"\"\n    Filter the records and read them into memory accoring to customized settings\n\n    Args:\n        selector_config (dict): the dictionary that is used to filter records\n\n    Example:\n    ```python\n        &gt;&gt;&gt; task='./my_task'\n        &gt;&gt;&gt; selector = Selector({'task':task, 'header':['fedavg'], 'filter':{'lr':0.1}})\n        &gt;&gt;&gt; selector.records[task]\n        &gt;&gt;&gt; # selector.records is a dict where selector.records[task] is a list\n        &gt;&gt;&gt; # of the records that pass the filter\n    ```\n    \"\"\"\n    def __init__(self, selector_config):\n        self.config = selector_config\n        self.tasks = [selector_config['task']] if type(selector_config['task']) is not list else selector_config['task']\n        self.headers = selector_config['header'] if type(selector_config['header']) is list else [selector_config['header']]\n        self.filter = selector_config['filter'] if 'filter' in selector_config.keys() else {}\n        self.legend_with = selector_config['legend_with'] if 'legend_with' in selector_config.keys() else []\n        self.rec_names = self.scan()\n        self.records = self.read_records(self.rec_names)\n        tmp = list(self.records.values())\n        self.all_records = []\n        for ti in tmp: self.all_records.extend(ti)\n        try:\n            self.grouped_records, self.group_names, = self.group_records()\n        except Exception() as e:\n            print(e)\n\n    def scan(self):\n        res = {}\n        for task in self.tasks:\n            path = os.path.join(task, 'record')\n            all_records = os.listdir(path)\n            tmp = []\n            # check headers\n            for header in self.headers:\n                tmp.extend([f for f in all_records if f.startswith(header) and f.endswith('.json')])\n            res[task] = self.filename_filter(tmp, self.filter)\n        return res\n\n    def filename_filter(self, fnames, filter):\n        if len(filter)==0: return fnames\n        for key in filter.keys():\n            condition = filter[key]\n            res = []\n            for f in fnames:\n                if f.find('_'+key)==-1: continue\n                fv = f[f.find('_' + key) + len(key) + 1:f.find('_', f.find('_' + key) + 1)]\n                if type(condition) is list:\n                    fv = float(fv) if ('0' &lt;= fv[0] &lt;= '9' or fv[0] == '.' or fv[0] == '-') else fv\n                    if fv in condition: res.append(f)\n                elif type(condition) is str:\n                    con = (fv+condition) if condition[0] in ['&lt;', '&gt;', '='] else (fv+'=='+condition)\n                    if eval(con): res.append(f)\n                else:\n                    if float(fv)==float(condition): res.append(f)\n            fnames = res\n        return fnames\n\n    def get_key_from_filename(self, filename, key):\n        if key == '': return ''\n        value_start = filename.find('_' + key) + len(key) + 1\n        value_end = filename.find('_', value_start)\n        return filename[value_start:value_end]\n\n    def read_records(self, rec_names):\n        res = {task: [] for task in rec_names}\n        for task in rec_names:\n            path = os.path.join(task, 'record')\n            files = os.listdir(path)\n            for record_name in rec_names[task]:\n                if record_name in files:\n                    record = Record(task, record_name)\n                    record.set_legend(self.legend_with)\n                    res[task].append(record)\n        return res\n\n    def group_records(self, key=['seed']):\n        if type(key) is not list: key=[key]\n        groups = collections.defaultdict(list)\n        for rec in self.all_records:\n            group_name = '.'.join([str(rec.data['option'][k]) for k in rec.data['option'].keys() if k not in key])\n            groups[group_name].append(rec)\n        res = []\n        for g in groups:\n            res.append(Record.create_group(groups[g]))\n        return res, list(groups.keys())\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Table","title":"<code>Table</code>","text":"<p>Organize the information in records into a table.</p> <p>Parameters:</p> Name Type Description Default <code>records</code> <code>list</code> <p>a list of instances of Record(...)</p> required <code>save_text</code> <code>bool</code> <p>whether to store the table into the disk</p> <code>False</code> <code>path</code> <code>str</code> <p>the storing path</p> <code>'.'</code> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class Table:\nr\"\"\"\n    Organize the information in records into a table.\n\n    Args:\n        records (list): a list of instances of Record(...)\n        save_text (bool): whether to store the table into the disk\n        path (str): the storing path\n    \"\"\"\n    def __init__(self, records:list, save_text:bool=False, path:str='.'):\n        self.records = records\n        self.save_text = save_text\n        self.path = path\n        self.tb = pt.PrettyTable()\n        self.tb.add_column('Task', [r.data['option']['task'] for r in self.records])\n        self.tb.add_column('Record', [r.data['label'] for r in self.records])\n        self.tb.float_format = \"3.4\"\n        self.sort_key = None\n\n    def add_column(self, func, col_option):\nr\"\"\"\n        Add a column to this table. For each record $Record_k$, its value $v_k$\n        in this column is v_k=func(Record_k, col_option), where func can be \n        arbitrarily customized.\n\n        Args:\n            func (func|str): the name of the function or the function\n            col_option (dict|str): the option of the column to index data in each record\n\n        Example:\n        ```python\n            &gt;&gt;&gt; tb = Table(records)\n            &gt;&gt;&gt; tb.add_column(min_value, col_option={'x':'val_loss'})\n            &gt;&gt;&gt; tb.print()\n        ```\n        \"\"\"\n        func = eval(func) if type(func) is str else func\n        col_option = {'x': col_option} if type(col_option) is not dict else col_option\n        column = []\n        for rec in self.records:\n            column.append(func(rec, col_option))\n        if 'name' in col_option.keys():\n            fieldname = col_option['name']\n        else:\n            fieldname = '-'.join([str(v) for k,v in col_option.items() if k!='sort'])\n            fieldname = func.__name__ + '-' + fieldname\n        self.tb.add_column(fieldname=fieldname, column=column)\n        if 'sort' in col_option.keys(): self.tb.sortby = fieldname\n\n    def set_title(self, title):\n        self.tb.title = title\n\n    def print(self):\nr\"\"\"Print and store the table\"\"\"\n        if self.save_text:\n            with open(os.path.join(self.path, str(uuid.uuid4())+'.txt'), 'w') as outf:\n                outf.write(self.tb.__repr__())\n        print(self)\n\n    def __repr__(self):\n        return self.tb.__repr__()\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Table.add_column","title":"<code>add_column(func, col_option)</code>","text":"<p>Add a column to this table. For each record \\(Record_k\\), its value \\(v_k\\) in this column is v_k=func(Record_k, col_option), where func can be  arbitrarily customized.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>func | str</code> <p>the name of the function or the function</p> required <code>col_option</code> <code>dict | str</code> <p>the option of the column to index data in each record</p> required <p>Example:</p> <pre><code>    &gt;&gt;&gt; tb = Table(records)\n    &gt;&gt;&gt; tb.add_column(min_value, col_option={'x':'val_loss'})\n    &gt;&gt;&gt; tb.print()\n</code></pre> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def add_column(self, func, col_option):\nr\"\"\"\n    Add a column to this table. For each record $Record_k$, its value $v_k$\n    in this column is v_k=func(Record_k, col_option), where func can be \n    arbitrarily customized.\n\n    Args:\n        func (func|str): the name of the function or the function\n        col_option (dict|str): the option of the column to index data in each record\n\n    Example:\n    ```python\n        &gt;&gt;&gt; tb = Table(records)\n        &gt;&gt;&gt; tb.add_column(min_value, col_option={'x':'val_loss'})\n        &gt;&gt;&gt; tb.print()\n    ```\n    \"\"\"\n    func = eval(func) if type(func) is str else func\n    col_option = {'x': col_option} if type(col_option) is not dict else col_option\n    column = []\n    for rec in self.records:\n        column.append(func(rec, col_option))\n    if 'name' in col_option.keys():\n        fieldname = col_option['name']\n    else:\n        fieldname = '-'.join([str(v) for k,v in col_option.items() if k!='sort'])\n        fieldname = func.__name__ + '-' + fieldname\n    self.tb.add_column(fieldname=fieldname, column=column)\n    if 'sort' in col_option.keys(): self.tb.sortby = fieldname\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Table.print","title":"<code>print()</code>","text":"<p>Print and store the table</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def print(self):\nr\"\"\"Print and store the table\"\"\"\n    if self.save_text:\n        with open(os.path.join(self.path, str(uuid.uuid4())+'.txt'), 'w') as outf:\n            outf.write(self.tb.__repr__())\n    print(self)\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.Trace2D","title":"<code>Trace2D</code>","text":"<p>         Bases: <code>PaintObject</code></p> <p>Trace Object</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>class Trace2D(PaintObject):\n\"\"\"Trace Object\"\"\"\n    def __init__(self, rec, args,  obj_option):\n        super(Trace2D, self).__init__(rec, args, obj_option, '')\n\n    def draw(self, ax):\n        pass\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.final_value","title":"<code>final_value(record, col_option)</code>","text":"<p>Get final value. The col_option should be like     {'x': key of record.data}</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Record</code> <p>the record</p> required <code>col_option</code> <code>dict</code> <p>column option</p> required <p>Returns:</p> Type Description <p>the column value</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def final_value(record, col_option):\nr\"\"\"\n    Get final value. The col_option should be like\n        {'x': key of record.data}\n\n    Args:\n        record (Record): the record\n        col_option (dict): column option\n\n    Returns:\n        the column value\n    \"\"\"\n    return record.data[col_option['x']][-1]\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.group_optimal_value","title":"<code>group_optimal_value(record, col_option)</code>","text":"<p>Get the grouped optimal value. The col_option should be like     {     'x': key of record.data,     'flag': 'min' or 'max'     }</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Record</code> <p>the record</p> required <code>col_option</code> <code>dict</code> <p>column option</p> required <p>Returns:</p> Type Description <p>the column value</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def group_optimal_value(record, col_option):\nr\"\"\"\n    Get the grouped optimal value. The col_option should be like\n        {\n        'x': key of record.data,\n        'flag': 'min' or 'max'\n        }\n\n    Args:\n        record (Record): the record\n        col_option (dict): column option\n\n    Returns:\n        the column value\n    \"\"\"\n    if 'flag' not in col_option.keys(): col_option['flag'] = 'min'\n    if col_option['flag']=='min': f = np.min\n    else: f=np.max\n    minvs = np.array([f(rdata[col_option['x']]) for rdata in record.datas])\n    mean_v = np.mean(minvs)\n    std_v = np.std(minvs)\n    return \"{:.4f} \u00b1 {:.4f}\".format(mean_v, std_v)\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.group_optimal_x_by_y","title":"<code>group_optimal_x_by_y(record, col_option)</code>","text":"<p>Get the grouped value of y where the grouped value of x is the optimal. The col_option should be like     {     'x': key of record.data,     'y': key of record.data,     'flag': 'min' or 'max'     }</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Record</code> <p>the record</p> required <code>col_option</code> <code>dict</code> <p>column option</p> required <p>Returns:</p> Type Description <p>the column value</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def group_optimal_x_by_y(record, col_option):\nr\"\"\"\n    Get the grouped value of y where the grouped value of x is the optimal.\n    The col_option should be like\n        {\n        'x': key of record.data,\n        'y': key of record.data,\n        'flag': 'min' or 'max'\n        }\n\n    Args:\n        record (Record): the record\n        col_option (dict): column option\n\n    Returns:\n        the column value\n    \"\"\"\n    if 'flag' not in col_option.keys(): col_option['flag'] = 'min'\n    if col_option['flag']=='min': f = np.argmin\n    else: f=np.argmax\n    vs = []\n    for rdata in record.datas:\n        tmp = f(rdata[col_option['y']])\n        vs.append(rdata[col_option['x']][tmp])\n    mean_v = np.mean(vs)\n    std_v = np.std(vs)\n    return \"{:.4f} \u00b1 {:.4f}\".format(mean_v, std_v)\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.max_value","title":"<code>max_value(record, col_option)</code>","text":"<p>Get maximal value.The col_option should be like     {'x': key of record.data}</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Record</code> <p>the record</p> required <code>col_option</code> <code>dict</code> <p>column option</p> required <p>Returns:</p> Type Description <p>the column value</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def max_value(record,  col_option):\nr\"\"\"\n    Get maximal value.The col_option should be like\n        {'x': key of record.data}\n\n    Args:\n        record (Record): the record\n        col_option (dict): column option\n\n    Returns:\n        the column value\n    \"\"\"\n    return np.max(record.data[col_option['x']])\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.mean_value","title":"<code>mean_value(record, col_option)</code>","text":"<p>Get mean value. The col_option should be like     {'x': key of record.data}</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Record</code> <p>the record</p> required <code>col_option</code> <code>dict</code> <p>column option</p> required <p>Returns:</p> Type Description <p>the column value</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def mean_value(record, col_option):\nr\"\"\"\n    Get mean value. The col_option should be like\n        {'x': key of record.data}\n\n    Args:\n        record (Record): the record\n        col_option (dict): column option\n\n    Returns:\n        the column value\n    \"\"\"\n    return np.mean(record.data[col_option['x']])\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.min_value","title":"<code>min_value(record, col_option)</code>","text":"<p>Get minimal value. The col_option should be like     {'x': key of record.data}</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Record</code> <p>the record</p> required <code>col_option</code> <code>dict</code> <p>column option</p> required <p>Returns:</p> Type Description <p>the column value</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def min_value(record,  col_option):\nr\"\"\"\n    Get minimal value. The col_option should be like\n        {'x': key of record.data}\n\n    Args:\n        record (Record): the record\n        col_option (dict): column option\n\n    Returns:\n        the column value\n    \"\"\"\n    return np.min(record.data[col_option['x']])\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.optimal_x_by_y","title":"<code>optimal_x_by_y(record, col_option)</code>","text":"<p>Get the value of y where the value of x is the optimal. The col_option should be like     {     'x': key of record.data,     'y': key of record.data,     'flag': 'min' or 'max'     }</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Record</code> <p>the record</p> required <code>col_option</code> <code>dict</code> <p>column option</p> required <p>Returns:</p> Type Description <p>the column value</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def optimal_x_by_y(record, col_option):\nr\"\"\"\n    Get the value of y where the value of x is the optimal.\n    The col_option should be like\n        {\n        'x': key of record.data,\n        'y': key of record.data,\n        'flag': 'min' or 'max'\n        }\n\n    Args:\n        record (Record): the record\n        col_option (dict): column option\n\n    Returns:\n        the column value\n    \"\"\"\n    if 'flag' not in col_option.keys(): col_option['flag'] = 'min'\n    if col_option['flag']=='min': f = np.argmin\n    else: f=np.argmax\n    tmp = f(record.data[col_option['y']])\n    return record.data[col_option['x']][tmp]\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.show","title":"<code>show(config, save_figure=False, save_text=False, path='.', seed=0)</code>","text":"<p>Show the results according to analysis configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict | str</code> <p>the analysis plan</p> required <code>save_figure</code> <code>bool</code> <p>whether to save figures</p> <code>False</code> <code>save_text</code> <code>bool</code> <p>whether to save table as .txt file</p> <code>False</code> <code>path</code> <code>str</code> <p>the path to store the results</p> <code>'.'</code> <code>seed</code> <code>int</code> <p>random seed</p> <code>0</code> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo.experiment.analyzer as al\n    &gt;&gt;&gt; # only records of fedavg running on the task 'my_task' with learning rate lr&lt;=0.01 will be selected\n    &gt;&gt;&gt; selector_config = {'task':'./my_task', 'header':['fedavg'], 'filter':['LR':'&lt;=0.1']}\n    &gt;&gt;&gt; # draw the learning curve on the validation dataset\n    &gt;&gt;&gt; painter_config = {'Curve':[{'args':{'x':'communication_round', 'y':'val_loss'}}]}\n    &gt;&gt;&gt; # show the minimal value of validation loss\n    &gt;&gt;&gt; table_config = {'min_value':[{'x':'val_loss'}]}\n    &gt;&gt;&gt; # create analysis plan\n    &gt;&gt;&gt; analysis_plan = {'Selector':selector_config, 'Painter':painter_config, 'Table':table_config}\n    &gt;&gt;&gt; # call this function\n    &gt;&gt;&gt; al.show(analysis_plan)\n</code></pre> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def show(config, save_figure=False, save_text=False, path='.', seed=0):\nr\"\"\"\n    Show the results according to analysis configuration.\n\n    Args:\n        config (dict|str): the analysis plan\n        save_figure (bool): whether to save figures\n        save_text (bool): whether to save table as .txt file\n        path (str): the path to store the results\n        seed (int): random seed\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo.experiment.analyzer as al\n        &gt;&gt;&gt; # only records of fedavg running on the task 'my_task' with learning rate lr&lt;=0.01 will be selected\n        &gt;&gt;&gt; selector_config = {'task':'./my_task', 'header':['fedavg'], 'filter':['LR':'&lt;=0.1']}\n        &gt;&gt;&gt; # draw the learning curve on the validation dataset\n        &gt;&gt;&gt; painter_config = {'Curve':[{'args':{'x':'communication_round', 'y':'val_loss'}}]}\n        &gt;&gt;&gt; # show the minimal value of validation loss\n        &gt;&gt;&gt; table_config = {'min_value':[{'x':'val_loss'}]}\n        &gt;&gt;&gt; # create analysis plan\n        &gt;&gt;&gt; analysis_plan = {'Selector':selector_config, 'Painter':painter_config, 'Table':table_config}\n        &gt;&gt;&gt; # call this function\n        &gt;&gt;&gt; al.show(analysis_plan)\n    ```\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    option = load_configuration(config)\n    record_selector = Selector(option['Selector'])\n    if 'Painter' in option.keys():\n        painter = Painter(record_selector.all_records, save_figure=save_figure, path=path)\n        group_painter = Painter(record_selector.grouped_records, save_figure=save_figure, path=path)\n        for object_class_string in option['Painter'].keys():\n            figs = option['Painter'][object_class_string] if type(option['Painter'][object_class_string]) is list else [option['Painter'][object_class_string]]\n            grouped = ('Group' in object_class_string)\n            p = group_painter if grouped else painter\n            for fig_config in figs:\n                p.create_figure(object_class_string, fig_config)\n\n    if 'Table' in option.keys():\n        tb = Table(record_selector.all_records, save_text=save_text, path=path)\n        group_tb = Table(record_selector.grouped_records, save_text=save_text, path=path)\n        for funcname in option['Table']:\n            columns = option['Table'][funcname] if type(option['Table'][funcname]) is list else [option['Table'][funcname]]\n            grouped = ('group' in funcname)\n            ctb = group_tb if grouped else tb\n            for col_option in columns:\n                ctb.add_column(funcname, col_option)\n        tb.print()\n        group_tb.print()\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.std_value","title":"<code>std_value(record, col_option)</code>","text":"<p>Get standard deviation. The col_option should be like     {'x': key of record.data}</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Record</code> <p>the record</p> required <code>col_option</code> <code>dict</code> <p>column option</p> required <p>Returns:</p> Type Description <p>the column value</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def std_value(record, col_option):\nr\"\"\"\n    Get standard deviation. The col_option should be like\n        {'x': key of record.data}\n\n    Args:\n        record (Record): the record\n        col_option (dict): column option\n\n    Returns:\n        the column value\n    \"\"\"\n    return np.std(record.data[col_option['x']])\n</code></pre>"},{"location":"Docs/experiment/analyzer/#flgo.experiment.analyzer.variance","title":"<code>variance(record, col_option)</code>","text":"<p>Get variance. The col_option should be like     {'x': key of record.data}</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>Record</code> <p>the record</p> required <code>col_option</code> <code>dict</code> <p>column option</p> required <p>Returns:</p> Type Description <p>the column value</p> Source code in <code>flgo\\experiment\\analyzer.py</code> <pre><code>def variance(record, col_option):\nr\"\"\"\n    Get variance. The col_option should be like\n        {'x': key of record.data}\n\n    Args:\n        record (Record): the record\n        col_option (dict): column option\n\n    Returns:\n        the column value\n    \"\"\"\n    return np.var(record.data[col_option['x']])\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/","title":"flgo.experiment.device_scheduler","text":"<p>This module is for scheduling GPU devices to different runners. There are three pre-defined Schedulers: BasicScheduler, AutoScheduler, and RandomScheduler.</p> <p>When the number of runners is large and GPU memory is limited, we recommend to use AutoScheduler. Otherwise, BasicScheduler and RandomScheduler are both good choices.</p>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.AbstractScheduler","title":"<code>AbstractScheduler</code>","text":"<p>Abstract Scheduler</p> Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>class AbstractScheduler(metaclass=ABCMeta):\nr\"\"\"Abstract Scheduler\"\"\"\n    @abstractmethod\n    def get_available_device(self, *args, **kwargs):\nr\"\"\"Search for a currently available device and return it\"\"\"\n        pass\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.AbstractScheduler.get_available_device","title":"<code>get_available_device(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Search for a currently available device and return it</p> Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>@abstractmethod\ndef get_available_device(self, *args, **kwargs):\nr\"\"\"Search for a currently available device and return it\"\"\"\n    pass\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.AutoScheduler","title":"<code>AutoScheduler</code>","text":"<p>         Bases: <code>BasicScheduler</code></p> <p>Automatically schedule GPUs by dynamically esimating the GPU memory occupation for all the runners and checking availability according to real-time memory information.</p> <p>Parameters:</p> Name Type Description Default <code>devices</code> <code>list</code> <p>a list of the index numbers of GPUs</p> required <code>put_interval</code> <code>int</code> <p>the minimal time interval (i.e. seconds) to allocate the same device</p> <code>5</code> <code>mean_memory_occupated</code> <code>int</code> <p>the initial mean memory occupation (i.e. MB) for all the runners</p> <code>1000</code> <code>available_interval</code> <code>int</code> <p>a gpu will be returned only if it is kept available for a period longer than this term</p> <code>5</code> <code>dynamic_memory_occupated</code> <code>bool</code> <p>whether to dynamically estimate the memory occupation</p> <code>True</code> <code>dynamic_condition</code> <code>str</code> <p>'mean' or 'max'</p> <code>'mean'</code> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo.experiment.device_scheduler\n    &gt;&gt;&gt; sc = flgo.experiment.device_scheduler.AutoScheduler([0,1])\n    &gt;&gt;&gt; import flgo\n    &gt;&gt;&gt; flgo.multi_init_and_run(runner_args, scheduler=sc)\n</code></pre> Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>class AutoScheduler(BasicScheduler):\nr\"\"\"\n    Automatically schedule GPUs by dynamically esimating the GPU memory occupation\n    for all the runners and checking availability according to real-time memory information.\n\n    Args:\n        devices (list): a list of the index numbers of GPUs\n        put_interval (int, optional): the minimal time interval (i.e. seconds) to allocate the same device\n        mean_memory_occupated (int, optional): the initial mean memory occupation (i.e. MB) for all the runners\n        available_interval (int, optional): a gpu will be returned only if it is kept available for a period longer than this term\n        dynamic_memory_occupated (bool, optional): whether to dynamically estimate the memory occupation\n        dynamic_condition (str): 'mean' or 'max'\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo.experiment.device_scheduler\n        &gt;&gt;&gt; sc = flgo.experiment.device_scheduler.AutoScheduler([0,1])\n        &gt;&gt;&gt; import flgo\n        &gt;&gt;&gt; flgo.multi_init_and_run(runner_args, scheduler=sc)\n    ```\n    \"\"\"\n    def __init__(self, devices:list, put_interval = 5, mean_memory_occupated = 1000, available_interval=5, dynamic_memory_occupated=True, dynamic_condition='mean'):\n        super(AutoScheduler, self).__init__(devices)\n        pynvml.nvmlInit()\n        crt_time = time.time()\n        self.dev_state = {\n            dev:{\n                'avl': True,\n                'time':crt_time,\n                'time_put':None,\n                'handle':pynvml.nvmlDeviceGetHandleByIndex(dev),\n                'total_memory':0,\n                'allocated_memory':0,\n                'free_memory':0,\n            }\n            for dev in self.devices\n        }\n        self.put_interval = put_interval\n        self.mean_memory_occupated = mean_memory_occupated\n        self.available_interval = available_interval\n        self.dynamic_condition = dynamic_condition\n        self.dynamic_memory_occupated = dynamic_memory_occupated\n\n    def get_available_device(self, option, *args, **kwargs):\n        for dev in self.devices:\n            self.flush(dev)\n        all_mems = []\n        for dev in self.devices:\n            dev_handle = self.dev_state[dev]['handle']\n            ps = pynvml.nvmlDeviceGetComputeRunningProcesses(dev_handle)\n            mems = [p.usedGpuMemory for p in ps if p.pid in self.process_set]\n            all_mems.extend(mems)\n        if self.dynamic_memory_occupated:\n            if len(all_mems)&gt;0:\n                mem = max(all_mems) if self.dynamic_condition=='max' else sum(all_mems)/len(all_mems)\n                self.mean_memory_occupated = self.byte2mb(mem)\n        tmp = copy.deepcopy(self.devices)\n        sorted(tmp, key=lambda x:self.dev_state[x]['free_memory'])\n        for dev in tmp:\n            if self.check_available(dev):\n                return dev\n        return None\n\n    def byte2mb(self, size):\n        return int(size/1024/1024)\n\n    def flush(self, dev):\n        if dev&gt;=0:\n            handle = self.dev_state[dev]['handle']\n            meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n            self.dev_state[dev]['total_memory'] = self.byte2mb(meminfo.total)\n            self.dev_state[dev]['allocated_memory'] = self.byte2mb(meminfo.used)\n            self.dev_state[dev]['free_memory'] = self.byte2mb(meminfo.free)\n\n    def check_available(self, dev):\n        if dev=='-1':return True\n        crt_time = time.time()\n        crt_free_memory = self.dev_state[dev]['free_memory']\n        target_memory = self.mean_memory_occupated\n        crt_avl = crt_free_memory&gt;target_memory\n        if crt_avl:\n            if self.dev_state[dev]['avl']:\n                if crt_time - self.dev_state[dev]['time']&gt;=self.available_interval:\n                    if self.dev_state[dev]['time_put'] is None or crt_time-self.dev_state[dev]['time_put']&gt;=self.put_interval:\n                        self.dev_state[dev]['time_put'] = crt_time\n                        return True\n        if crt_avl!=self.dev_state[dev]['avl']:\n            self.dev_state[dev]['avl'] = True\n            self.dev_state[dev]['time'] = crt_time\n        return False\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.BasicScheduler","title":"<code>BasicScheduler</code>","text":"<p>         Bases: <code>AbstractScheduler</code></p> <p>Basic gpu scheduler. Each device will be always considered available and will be returned in turn.</p> <p>Parameters:</p> Name Type Description Default <code>devices</code> <code>list</code> <p>a list of the index numbers of GPUs</p> required Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>class BasicScheduler(AbstractScheduler):\nr\"\"\"\n    Basic gpu scheduler. Each device will be always considered available\n    and will be returned in turn.\n\n    Args:\n        devices (list): a list of the index numbers of GPUs\n    \"\"\"\n    def __init__(self, devices:list, *args, **kwargs):\n        self.devices = devices if devices != [] else [-1]\n        self.dev_index = 0\n        self.process_set = set()\n\n    def get_available_device(self, *args, **kwargs):\n\"\"\"Return the next device\"\"\"\n        self.dev_index = (self.dev_index+1)%len(self.devices)\n        return self.devices[self.dev_index]\n\n    def set_devices(self, devices:list):\nr\"\"\"\n        Reset all the devices\n\n        Args:\n            devices (list): a list of the index numbers of GPUs\n        \"\"\"\n        self.devices=[-1] if devices==[] else devices\n        self.dev_index = self.dev_index%len(self.devices)\n\n    def add_process(self, pid=None):\nr\"\"\"\n        Record the running process that uses the gpu from the scheduler\n\n        Args:\n            pid (int): the process id\n        \"\"\"\n        if pid is not None:\n            self.process_set.add(pid)\n\n    def remove_process(self, pid=None):\nr\"\"\"\n        Remove the running process that uses the gpu from the scheduler\n\n        Args:\n            pid (int): the process id\n        \"\"\"\n        if pid is not None and pid in self.process_set:\n            self.process_set.remove(pid)\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.BasicScheduler.add_process","title":"<code>add_process(pid=None)</code>","text":"<p>Record the running process that uses the gpu from the scheduler</p> <p>Parameters:</p> Name Type Description Default <code>pid</code> <code>int</code> <p>the process id</p> <code>None</code> Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>def add_process(self, pid=None):\nr\"\"\"\n    Record the running process that uses the gpu from the scheduler\n\n    Args:\n        pid (int): the process id\n    \"\"\"\n    if pid is not None:\n        self.process_set.add(pid)\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.BasicScheduler.get_available_device","title":"<code>get_available_device(*args, **kwargs)</code>","text":"<p>Return the next device</p> Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>def get_available_device(self, *args, **kwargs):\n\"\"\"Return the next device\"\"\"\n    self.dev_index = (self.dev_index+1)%len(self.devices)\n    return self.devices[self.dev_index]\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.BasicScheduler.remove_process","title":"<code>remove_process(pid=None)</code>","text":"<p>Remove the running process that uses the gpu from the scheduler</p> <p>Parameters:</p> Name Type Description Default <code>pid</code> <code>int</code> <p>the process id</p> <code>None</code> Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>def remove_process(self, pid=None):\nr\"\"\"\n    Remove the running process that uses the gpu from the scheduler\n\n    Args:\n        pid (int): the process id\n    \"\"\"\n    if pid is not None and pid in self.process_set:\n        self.process_set.remove(pid)\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.BasicScheduler.set_devices","title":"<code>set_devices(devices)</code>","text":"<p>Reset all the devices</p> <p>Parameters:</p> Name Type Description Default <code>devices</code> <code>list</code> <p>a list of the index numbers of GPUs</p> required Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>def set_devices(self, devices:list):\nr\"\"\"\n    Reset all the devices\n\n    Args:\n        devices (list): a list of the index numbers of GPUs\n    \"\"\"\n    self.devices=[-1] if devices==[] else devices\n    self.dev_index = self.dev_index%len(self.devices)\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.RandomScheduler","title":"<code>RandomScheduler</code>","text":"<p>         Bases: <code>BasicScheduler</code></p> <p>Random GPU Scheduler</p> Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>class RandomScheduler(BasicScheduler):\n\"\"\"Random GPU Scheduler\"\"\"\n    def get_available_device(self, *args, **kwargs):\n\"\"\"Return a random device\"\"\"\n        return random.choice(self.devices)\n</code></pre>"},{"location":"Docs/experiment/device_scheduler/#flgo.experiment.device_scheduler.RandomScheduler.get_available_device","title":"<code>get_available_device(*args, **kwargs)</code>","text":"<p>Return a random device</p> Source code in <code>flgo\\experiment\\device_scheduler.py</code> <pre><code>def get_available_device(self, *args, **kwargs):\n\"\"\"Return a random device\"\"\"\n    return random.choice(self.devices)\n</code></pre>"},{"location":"Docs/experiment/logger/","title":"Index","text":"<p>         Bases: <code>Logger</code></p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>class BasicLogger(Logger):\n\n    _LEVEL = {\n        \"DEBUG\": DEBUG,\n\n        \"INFO\": INFO,\n\n        \"WARNING\": WARNING,\n\n        \"ERROR\": ERROR,\n\n        \"CRITICAL\": CRITICAL,\n    }\n\n    def __init__(self, task, option, *args, **kwargs):\n        self.task_path = task\n        self.option = option\n        super(BasicLogger, self).__init__(*args, **kwargs)\n        self.output = collections.defaultdict(list)\n        self.output['option'] = option\n        self.current_round = -1\n        self.objects = []\n        self.temp = \"{:&lt;30s}{:.4f}\"\n        self.time_costs = []\n        self.time_buf = {}\n        self.formatter = Formatter('%(asctime)s %(filename)s %(funcName)s [line:%(lineno)d] %(levelname)s %(message)s')\n        self.handler_list = []\n        self.overwrite = not self.option['no_overwrite']\n        if not self.option['no_log_console']:\n            self.streamhandler = StreamHandler()\n            self.streamhandler.setFormatter(self.formatter)\n            self.streamhandler.setLevel(self._LEVEL[self.option['log_level'].upper()])\n            self.addHandler(self.streamhandler)\n        if self.option['log_file']:\n            log_dir = self.get_log_path()\n            self.log_path = os.path.join(log_dir, self.get_time_string()+self.get_output_name('.log'))\n            if not os.path.exists(self.get_log_path()):\n                os.mkdir(log_dir)\n            self.filehandler = FileHandler(self.log_path)\n            self.filehandler.setFormatter(self.formatter)\n            self.filehandler.setLevel(self._LEVEL[self.option['log_level'].upper()])\n            self.addHandler(self.filehandler)\n        # options of early stopping\n        self._es_key = 'val_loss'\n        self._es_patience = 20\n        self._es_counter = 0\n        self._es_best_score = None\n        self._es_best_round = 0\n\n    def check_if_log(self, round, eval_interval=-1):\n\"\"\"For evaluating every 'eval_interval' rounds, check whether to log at 'round'.\"\"\"\n        self.current_round = round\n        return eval_interval &gt; 0 and (round == 0 or round % eval_interval == 0)\n\n    def time_start(self, key=''):\n\"\"\"Create a timestamp of the event 'key' starting\"\"\"\n        if key not in [k for k in self.time_buf.keys()]:\n            self.time_buf[key] = []\n        self.time_buf[key].append(time.time())\n\n    def time_end(self, key=''):\n\"\"\"Create a timestamp that ends the event 'key' and print the time interval of the event.\"\"\"\n        if key not in [k for k in self.time_buf.keys()]:\n            raise RuntimeError(\"Timer end before start.\")\n        else:\n            self.time_buf[key][-1] = time.time() - self.time_buf[key][-1]\n            self.info(\"{:&lt;30s}{:.4f}\".format(key + \":\", self.time_buf[key][-1]) + 's')\n            return self.time_buf[key][-1]\n\n    def save_output_as_json(self, filepath=None):\n\"\"\"Save the self.output as .json file\"\"\"\n        if len(self.output) == 0: return\n        self.organize_output()\n        self.output_to_jsonable_dict()\n        if filepath is None:\n            filepath = os.path.join(self.get_output_path(),self.get_output_name())\n        if not self.overwrite:\n            if os.path.exists(filepath):\n                with open(filepath, 'r') as inf:\n                    original_record = json.loads(inf.read())\n                o_keys = set(original_record.keys())\n                output_keys = set(self.output.keys())\n                new_keys = list(output_keys.difference(o_keys))\n                for k in new_keys:\n                    original_record[k] = self.output[k]\n                self.output = original_record\n        try:\n            with open(filepath, 'w') as outf:\n                json.dump(dict(self.output), outf)\n        except:\n            self.error('Failed to save flw.logger.output as results')\n\n    def check_is_jsonable(self, x):\n        try:\n            json.dumps(x)\n            return True\n        except:\n            return False\n\n    def output_to_jsonable_dict(self):\n        for key, value in self.output.items():\n            if not self.check_is_jsonable(value):\n                try:\n                    self.output[key] = str(self.output[key])\n                    self.warning(\"flw.logger.output['{}'] is not jsonable, and is automatically converted to string.\".format(key))\n                except:\n                    del self.output[key]\n                    self.warning(\"Automatically remove flw.logger.output['{}'] from logger, because it is not jsonable and is failed to convert into string. \".format(key))\n        return\n\n    def write_var_into_output(self, var_name=None, var_value=None):\n\"\"\"Add variable 'var_name' and its value var_value to logger\"\"\"\n        if var_name == None: raise RuntimeError(\"Missing the name of the variable to be logged.\")\n        self.output[var_name].append(var_value)\n        return\n\n    def register_variable(self, **kwargs):\n\"\"\"Initialze the logger in utils.fflow.initialize()\"\"\"\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n        return\n\n    def show_current_output(self, yes_key=['train', 'test', 'val'], no_key=['dist']):\n        for key, val in self.output.items():\n            a = [(yk in key) for yk in yes_key]\n            nf = [(nk not in key) for nk in no_key]\n            if np.all(nf) and np.any(a):\n                try:\n                    content = self.temp.format(key, val[-1])\n                except:\n                    content = \"{}:\".format(key)+str(val[-1])\n                self.info(content)\n\n    def get_output_name(self, suffix='.json'):\n        if not hasattr(self, 'option'): raise NotImplementedError('logger has no attr named \"option\"')\n        header = \"{}_\".format(self.option[\"algorithm\"])\n        if hasattr(self, 'coordinator'):\n            for para, pv in self.coordinator.algo_para.items():\n                header = header + para + \"{}_\".format(pv)\n        else:\n            if self.option['algo_para'] is not None:\n                header = header + 'algopara_'+'|'.join([str(p) for p in self.option['algo_para']])\n\n        output_name = header + \"M{}_R{}_B{}_\".format(self.option['model'], self.option['num_rounds'], self.option['batch_size'])\n        if self.option['num_steps']&lt;0:\n            output_name = output_name + (\"E{}_\".format(self.option['num_epochs']))\n        else:\n            output_name = output_name + (\"K{}_\".format(self.option['num_steps']))\n\n        output_name = output_name + \"LR{:.4f}_P{:.2f}_S{}_LD{:.3f}_WD{:.3f}\".format(\n                        self.option['learning_rate'],\n                        self.option['proportion'],\n                        self.option['seed'],\n                        self.option['lr_scheduler'] + self.option['learning_rate_decay'],\n                        self.option['weight_decay'],\n        )\n        output_name = output_name + '_SIM{}_AVL{}_CN{}_CP{}_RS{}_LG{}'.format(\n                        self.simulator if hasattr(self, 'simulator') else 'None',\n                        self.option['availability'],\n                        self.option['connectivity'],\n                        self.option['completeness'],\n                        self.option['responsiveness'],\n                        self.__class__.__name__,\n        )\n        output_name = output_name + suffix\n        return output_name\n\n    def get_output_path(self):\n        if not hasattr(self, 'option'): raise NotImplementedError('logger has no attr named \"option\"')\n        return os.path.join(self.task_path, 'record')\n\n    def get_log_path(self):\n        return os.path.join(self.task_path, 'log')\n\n    def get_time_string(self):\n        return time.strftime('%Y-%m-%d-%H-%M-%S')\n\n    def early_stop(self):\n        # Early stopping when there is no improvement on the validation loss for more than self.option['early_stop'] rounds\n        if self.option['early_stop']&lt;0 or (self._es_key not in self.output): return False\n        score = -self.output[self._es_key][-1]\n        if np.isnan(score): return True\n        if self._es_best_score is None:\n            self._es_best_score = score\n            self._es_best_round = self.coordinator.current_round-1\n            self._es_patience = self.option['early_stop']\n        elif score&lt;self._es_best_score:\n            self._es_counter += 1\n            if self._es_counter &gt;= self._es_patience:\n                self.info('Early stopping after training for {} rounds.'.format(self.coordinator.current_round-1))\n                return True\n        else:\n            self._es_best_score = score\n            self._es_best_round = self.coordinator.current_round-1\n            self._es_counter = 0\n        return False\n\n    def initialize(self, *args, **kwargs):\n        return\n\n    def log_once(self, *args, **kwargs):\n\"\"\"This method is called at the beginning of each communication round of Server.\n        The round-wise operations of recording should be complemented here.\"\"\"\n        # calculate the testing metrics on testing dataset owned by coordinator\n        test_metric = self.coordinator.test()\n        for met_name, met_val in test_metric.items():\n            self.output['test_' + met_name].append(met_val)\n        val_metric = self.coordinator.test(flag='val')\n        for met_name, met_val in val_metric.items():\n            self.output['val_' + met_name].append(met_val)\n        # calculate weighted averaging of metrics on training datasets across participants\n        local_data_vols = [c.datavol for c in self.participants]\n        total_data_vol = sum(local_data_vols)\n        train_metrics = self.coordinator.global_test(flag='train')\n        for met_name, met_val in train_metrics.items():\n            self.output['train_' + met_name + '_dist'].append(met_val)\n            self.output['train_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n        # calculate weighted averaging and other statistics of metrics on validation datasets across clients\n        local_val_metrics = self.coordinator.global_test(flag='val')\n        for met_name, met_val in local_val_metrics.items():\n            self.output['local_val_'+met_name+'_dist'].append(met_val)\n            self.output['local_val_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n            self.output['mean_local_val_' + met_name].append(np.mean(met_val))\n            self.output['std_local_val_' + met_name].append(np.std(met_val))\n        local_test_metrics = self.coordinator.global_test(flag='test')\n        for met_name, met_val in local_test_metrics.items():\n            self.output['local_test_'+met_name+'_dist'].append(met_val)\n            self.output['local_test_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n            self.output['mean_local_test_' + met_name].append(np.mean(met_val))\n            self.output['std_local_test_' + met_name].append(np.std(met_val))\n        # output to stdout\n        self.show_current_output()\n\n    def organize_output(self, *args, **kwargs):\n\"\"\"This method will be called before saving self.output\"\"\"\n        for key in self.output.keys():\n            if '_dist' in key:\n                self.output[key] = self.output[key][-1]\n        return\n</code></pre>"},{"location":"Docs/experiment/logger/#flgo.experiment.logger.BasicLogger.check_if_log","title":"<code>check_if_log(round, eval_interval=-1)</code>","text":"<p>For evaluating every 'eval_interval' rounds, check whether to log at 'round'.</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def check_if_log(self, round, eval_interval=-1):\n\"\"\"For evaluating every 'eval_interval' rounds, check whether to log at 'round'.\"\"\"\n    self.current_round = round\n    return eval_interval &gt; 0 and (round == 0 or round % eval_interval == 0)\n</code></pre>"},{"location":"Docs/experiment/logger/#flgo.experiment.logger.BasicLogger.log_once","title":"<code>log_once(*args, **kwargs)</code>","text":"<p>This method is called at the beginning of each communication round of Server. The round-wise operations of recording should be complemented here.</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def log_once(self, *args, **kwargs):\n\"\"\"This method is called at the beginning of each communication round of Server.\n    The round-wise operations of recording should be complemented here.\"\"\"\n    # calculate the testing metrics on testing dataset owned by coordinator\n    test_metric = self.coordinator.test()\n    for met_name, met_val in test_metric.items():\n        self.output['test_' + met_name].append(met_val)\n    val_metric = self.coordinator.test(flag='val')\n    for met_name, met_val in val_metric.items():\n        self.output['val_' + met_name].append(met_val)\n    # calculate weighted averaging of metrics on training datasets across participants\n    local_data_vols = [c.datavol for c in self.participants]\n    total_data_vol = sum(local_data_vols)\n    train_metrics = self.coordinator.global_test(flag='train')\n    for met_name, met_val in train_metrics.items():\n        self.output['train_' + met_name + '_dist'].append(met_val)\n        self.output['train_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n    # calculate weighted averaging and other statistics of metrics on validation datasets across clients\n    local_val_metrics = self.coordinator.global_test(flag='val')\n    for met_name, met_val in local_val_metrics.items():\n        self.output['local_val_'+met_name+'_dist'].append(met_val)\n        self.output['local_val_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n        self.output['mean_local_val_' + met_name].append(np.mean(met_val))\n        self.output['std_local_val_' + met_name].append(np.std(met_val))\n    local_test_metrics = self.coordinator.global_test(flag='test')\n    for met_name, met_val in local_test_metrics.items():\n        self.output['local_test_'+met_name+'_dist'].append(met_val)\n        self.output['local_test_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n        self.output['mean_local_test_' + met_name].append(np.mean(met_val))\n        self.output['std_local_test_' + met_name].append(np.std(met_val))\n    # output to stdout\n    self.show_current_output()\n</code></pre>"},{"location":"Docs/experiment/logger/#flgo.experiment.logger.BasicLogger.organize_output","title":"<code>organize_output(*args, **kwargs)</code>","text":"<p>This method will be called before saving self.output</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def organize_output(self, *args, **kwargs):\n\"\"\"This method will be called before saving self.output\"\"\"\n    for key in self.output.keys():\n        if '_dist' in key:\n            self.output[key] = self.output[key][-1]\n    return\n</code></pre>"},{"location":"Docs/experiment/logger/#flgo.experiment.logger.BasicLogger.register_variable","title":"<code>register_variable(**kwargs)</code>","text":"<p>Initialze the logger in utils.fflow.initialize()</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def register_variable(self, **kwargs):\n\"\"\"Initialze the logger in utils.fflow.initialize()\"\"\"\n    for k, v in kwargs.items():\n        setattr(self, k, v)\n    return\n</code></pre>"},{"location":"Docs/experiment/logger/#flgo.experiment.logger.BasicLogger.save_output_as_json","title":"<code>save_output_as_json(filepath=None)</code>","text":"<p>Save the self.output as .json file</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def save_output_as_json(self, filepath=None):\n\"\"\"Save the self.output as .json file\"\"\"\n    if len(self.output) == 0: return\n    self.organize_output()\n    self.output_to_jsonable_dict()\n    if filepath is None:\n        filepath = os.path.join(self.get_output_path(),self.get_output_name())\n    if not self.overwrite:\n        if os.path.exists(filepath):\n            with open(filepath, 'r') as inf:\n                original_record = json.loads(inf.read())\n            o_keys = set(original_record.keys())\n            output_keys = set(self.output.keys())\n            new_keys = list(output_keys.difference(o_keys))\n            for k in new_keys:\n                original_record[k] = self.output[k]\n            self.output = original_record\n    try:\n        with open(filepath, 'w') as outf:\n            json.dump(dict(self.output), outf)\n    except:\n        self.error('Failed to save flw.logger.output as results')\n</code></pre>"},{"location":"Docs/experiment/logger/#flgo.experiment.logger.BasicLogger.time_end","title":"<code>time_end(key='')</code>","text":"<p>Create a timestamp that ends the event 'key' and print the time interval of the event.</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def time_end(self, key=''):\n\"\"\"Create a timestamp that ends the event 'key' and print the time interval of the event.\"\"\"\n    if key not in [k for k in self.time_buf.keys()]:\n        raise RuntimeError(\"Timer end before start.\")\n    else:\n        self.time_buf[key][-1] = time.time() - self.time_buf[key][-1]\n        self.info(\"{:&lt;30s}{:.4f}\".format(key + \":\", self.time_buf[key][-1]) + 's')\n        return self.time_buf[key][-1]\n</code></pre>"},{"location":"Docs/experiment/logger/#flgo.experiment.logger.BasicLogger.time_start","title":"<code>time_start(key='')</code>","text":"<p>Create a timestamp of the event 'key' starting</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def time_start(self, key=''):\n\"\"\"Create a timestamp of the event 'key' starting\"\"\"\n    if key not in [k for k in self.time_buf.keys()]:\n        self.time_buf[key] = []\n    self.time_buf[key].append(time.time())\n</code></pre>"},{"location":"Docs/experiment/logger/#flgo.experiment.logger.BasicLogger.write_var_into_output","title":"<code>write_var_into_output(var_name=None, var_value=None)</code>","text":"<p>Add variable 'var_name' and its value var_value to logger</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def write_var_into_output(self, var_name=None, var_value=None):\n\"\"\"Add variable 'var_name' and its value var_value to logger\"\"\"\n    if var_name == None: raise RuntimeError(\"Missing the name of the variable to be logged.\")\n    self.output[var_name].append(var_value)\n    return\n</code></pre>"},{"location":"Docs/experiment/logger/BasicLogger/","title":"BasicLogger","text":"<p>         Bases: <code>Logger</code></p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>class BasicLogger(Logger):\n\n    _LEVEL = {\n        \"DEBUG\": DEBUG,\n\n        \"INFO\": INFO,\n\n        \"WARNING\": WARNING,\n\n        \"ERROR\": ERROR,\n\n        \"CRITICAL\": CRITICAL,\n    }\n\n    def __init__(self, task, option, *args, **kwargs):\n        self.task_path = task\n        self.option = option\n        super(BasicLogger, self).__init__(*args, **kwargs)\n        self.output = collections.defaultdict(list)\n        self.output['option'] = option\n        self.current_round = -1\n        self.objects = []\n        self.temp = \"{:&lt;30s}{:.4f}\"\n        self.time_costs = []\n        self.time_buf = {}\n        self.formatter = Formatter('%(asctime)s %(filename)s %(funcName)s [line:%(lineno)d] %(levelname)s %(message)s')\n        self.handler_list = []\n        self.overwrite = not self.option['no_overwrite']\n        if not self.option['no_log_console']:\n            self.streamhandler = StreamHandler()\n            self.streamhandler.setFormatter(self.formatter)\n            self.streamhandler.setLevel(self._LEVEL[self.option['log_level'].upper()])\n            self.addHandler(self.streamhandler)\n        if self.option['log_file']:\n            log_dir = self.get_log_path()\n            self.log_path = os.path.join(log_dir, self.get_time_string()+self.get_output_name('.log'))\n            if not os.path.exists(self.get_log_path()):\n                os.mkdir(log_dir)\n            self.filehandler = FileHandler(self.log_path)\n            self.filehandler.setFormatter(self.formatter)\n            self.filehandler.setLevel(self._LEVEL[self.option['log_level'].upper()])\n            self.addHandler(self.filehandler)\n        # options of early stopping\n        self._es_key = 'val_loss'\n        self._es_patience = 20\n        self._es_counter = 0\n        self._es_best_score = None\n        self._es_best_round = 0\n\n    def check_if_log(self, round, eval_interval=-1):\n\"\"\"For evaluating every 'eval_interval' rounds, check whether to log at 'round'.\"\"\"\n        self.current_round = round\n        return eval_interval &gt; 0 and (round == 0 or round % eval_interval == 0)\n\n    def time_start(self, key=''):\n\"\"\"Create a timestamp of the event 'key' starting\"\"\"\n        if key not in [k for k in self.time_buf.keys()]:\n            self.time_buf[key] = []\n        self.time_buf[key].append(time.time())\n\n    def time_end(self, key=''):\n\"\"\"Create a timestamp that ends the event 'key' and print the time interval of the event.\"\"\"\n        if key not in [k for k in self.time_buf.keys()]:\n            raise RuntimeError(\"Timer end before start.\")\n        else:\n            self.time_buf[key][-1] = time.time() - self.time_buf[key][-1]\n            self.info(\"{:&lt;30s}{:.4f}\".format(key + \":\", self.time_buf[key][-1]) + 's')\n            return self.time_buf[key][-1]\n\n    def save_output_as_json(self, filepath=None):\n\"\"\"Save the self.output as .json file\"\"\"\n        if len(self.output) == 0: return\n        self.organize_output()\n        self.output_to_jsonable_dict()\n        if filepath is None:\n            filepath = os.path.join(self.get_output_path(),self.get_output_name())\n        if not self.overwrite:\n            if os.path.exists(filepath):\n                with open(filepath, 'r') as inf:\n                    original_record = json.loads(inf.read())\n                o_keys = set(original_record.keys())\n                output_keys = set(self.output.keys())\n                new_keys = list(output_keys.difference(o_keys))\n                for k in new_keys:\n                    original_record[k] = self.output[k]\n                self.output = original_record\n        try:\n            with open(filepath, 'w') as outf:\n                json.dump(dict(self.output), outf)\n        except:\n            self.error('Failed to save flw.logger.output as results')\n\n    def check_is_jsonable(self, x):\n        try:\n            json.dumps(x)\n            return True\n        except:\n            return False\n\n    def output_to_jsonable_dict(self):\n        for key, value in self.output.items():\n            if not self.check_is_jsonable(value):\n                try:\n                    self.output[key] = str(self.output[key])\n                    self.warning(\"flw.logger.output['{}'] is not jsonable, and is automatically converted to string.\".format(key))\n                except:\n                    del self.output[key]\n                    self.warning(\"Automatically remove flw.logger.output['{}'] from logger, because it is not jsonable and is failed to convert into string. \".format(key))\n        return\n\n    def write_var_into_output(self, var_name=None, var_value=None):\n\"\"\"Add variable 'var_name' and its value var_value to logger\"\"\"\n        if var_name == None: raise RuntimeError(\"Missing the name of the variable to be logged.\")\n        self.output[var_name].append(var_value)\n        return\n\n    def register_variable(self, **kwargs):\n\"\"\"Initialze the logger in utils.fflow.initialize()\"\"\"\n        for k, v in kwargs.items():\n            setattr(self, k, v)\n        return\n\n    def show_current_output(self, yes_key=['train', 'test', 'val'], no_key=['dist']):\n        for key, val in self.output.items():\n            a = [(yk in key) for yk in yes_key]\n            nf = [(nk not in key) for nk in no_key]\n            if np.all(nf) and np.any(a):\n                try:\n                    content = self.temp.format(key, val[-1])\n                except:\n                    content = \"{}:\".format(key)+str(val[-1])\n                self.info(content)\n\n    def get_output_name(self, suffix='.json'):\n        if not hasattr(self, 'option'): raise NotImplementedError('logger has no attr named \"option\"')\n        header = \"{}_\".format(self.option[\"algorithm\"])\n        if hasattr(self, 'coordinator'):\n            for para, pv in self.coordinator.algo_para.items():\n                header = header + para + \"{}_\".format(pv)\n        else:\n            if self.option['algo_para'] is not None:\n                header = header + 'algopara_'+'|'.join([str(p) for p in self.option['algo_para']])\n\n        output_name = header + \"M{}_R{}_B{}_\".format(self.option['model'], self.option['num_rounds'], self.option['batch_size'])\n        if self.option['num_steps']&lt;0:\n            output_name = output_name + (\"E{}_\".format(self.option['num_epochs']))\n        else:\n            output_name = output_name + (\"K{}_\".format(self.option['num_steps']))\n\n        output_name = output_name + \"LR{:.4f}_P{:.2f}_S{}_LD{:.3f}_WD{:.3f}\".format(\n                        self.option['learning_rate'],\n                        self.option['proportion'],\n                        self.option['seed'],\n                        self.option['lr_scheduler'] + self.option['learning_rate_decay'],\n                        self.option['weight_decay'],\n        )\n        output_name = output_name + '_SIM{}_AVL{}_CN{}_CP{}_RS{}_LG{}'.format(\n                        self.simulator if hasattr(self, 'simulator') else 'None',\n                        self.option['availability'],\n                        self.option['connectivity'],\n                        self.option['completeness'],\n                        self.option['responsiveness'],\n                        self.__class__.__name__,\n        )\n        output_name = output_name + suffix\n        return output_name\n\n    def get_output_path(self):\n        if not hasattr(self, 'option'): raise NotImplementedError('logger has no attr named \"option\"')\n        return os.path.join(self.task_path, 'record')\n\n    def get_log_path(self):\n        return os.path.join(self.task_path, 'log')\n\n    def get_time_string(self):\n        return time.strftime('%Y-%m-%d-%H-%M-%S')\n\n    def early_stop(self):\n        # Early stopping when there is no improvement on the validation loss for more than self.option['early_stop'] rounds\n        if self.option['early_stop']&lt;0 or (self._es_key not in self.output): return False\n        score = -self.output[self._es_key][-1]\n        if np.isnan(score): return True\n        if self._es_best_score is None:\n            self._es_best_score = score\n            self._es_best_round = self.coordinator.current_round-1\n            self._es_patience = self.option['early_stop']\n        elif score&lt;self._es_best_score:\n            self._es_counter += 1\n            if self._es_counter &gt;= self._es_patience:\n                self.info('Early stopping after training for {} rounds.'.format(self.coordinator.current_round-1))\n                return True\n        else:\n            self._es_best_score = score\n            self._es_best_round = self.coordinator.current_round-1\n            self._es_counter = 0\n        return False\n\n    def initialize(self, *args, **kwargs):\n        return\n\n    def log_once(self, *args, **kwargs):\n\"\"\"This method is called at the beginning of each communication round of Server.\n        The round-wise operations of recording should be complemented here.\"\"\"\n        # calculate the testing metrics on testing dataset owned by coordinator\n        test_metric = self.coordinator.test()\n        for met_name, met_val in test_metric.items():\n            self.output['test_' + met_name].append(met_val)\n        val_metric = self.coordinator.test(flag='val')\n        for met_name, met_val in val_metric.items():\n            self.output['val_' + met_name].append(met_val)\n        # calculate weighted averaging of metrics on training datasets across participants\n        local_data_vols = [c.datavol for c in self.participants]\n        total_data_vol = sum(local_data_vols)\n        train_metrics = self.coordinator.global_test(flag='train')\n        for met_name, met_val in train_metrics.items():\n            self.output['train_' + met_name + '_dist'].append(met_val)\n            self.output['train_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n        # calculate weighted averaging and other statistics of metrics on validation datasets across clients\n        local_val_metrics = self.coordinator.global_test(flag='val')\n        for met_name, met_val in local_val_metrics.items():\n            self.output['local_val_'+met_name+'_dist'].append(met_val)\n            self.output['local_val_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n            self.output['mean_local_val_' + met_name].append(np.mean(met_val))\n            self.output['std_local_val_' + met_name].append(np.std(met_val))\n        local_test_metrics = self.coordinator.global_test(flag='test')\n        for met_name, met_val in local_test_metrics.items():\n            self.output['local_test_'+met_name+'_dist'].append(met_val)\n            self.output['local_test_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n            self.output['mean_local_test_' + met_name].append(np.mean(met_val))\n            self.output['std_local_test_' + met_name].append(np.std(met_val))\n        # output to stdout\n        self.show_current_output()\n\n    def organize_output(self, *args, **kwargs):\n\"\"\"This method will be called before saving self.output\"\"\"\n        for key in self.output.keys():\n            if '_dist' in key:\n                self.output[key] = self.output[key][-1]\n        return\n</code></pre>"},{"location":"Docs/experiment/logger/BasicLogger/#flgo.experiment.logger.BasicLogger.check_if_log","title":"<code>check_if_log(round, eval_interval=-1)</code>","text":"<p>For evaluating every 'eval_interval' rounds, check whether to log at 'round'.</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def check_if_log(self, round, eval_interval=-1):\n\"\"\"For evaluating every 'eval_interval' rounds, check whether to log at 'round'.\"\"\"\n    self.current_round = round\n    return eval_interval &gt; 0 and (round == 0 or round % eval_interval == 0)\n</code></pre>"},{"location":"Docs/experiment/logger/BasicLogger/#flgo.experiment.logger.BasicLogger.log_once","title":"<code>log_once(*args, **kwargs)</code>","text":"<p>This method is called at the beginning of each communication round of Server. The round-wise operations of recording should be complemented here.</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def log_once(self, *args, **kwargs):\n\"\"\"This method is called at the beginning of each communication round of Server.\n    The round-wise operations of recording should be complemented here.\"\"\"\n    # calculate the testing metrics on testing dataset owned by coordinator\n    test_metric = self.coordinator.test()\n    for met_name, met_val in test_metric.items():\n        self.output['test_' + met_name].append(met_val)\n    val_metric = self.coordinator.test(flag='val')\n    for met_name, met_val in val_metric.items():\n        self.output['val_' + met_name].append(met_val)\n    # calculate weighted averaging of metrics on training datasets across participants\n    local_data_vols = [c.datavol for c in self.participants]\n    total_data_vol = sum(local_data_vols)\n    train_metrics = self.coordinator.global_test(flag='train')\n    for met_name, met_val in train_metrics.items():\n        self.output['train_' + met_name + '_dist'].append(met_val)\n        self.output['train_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n    # calculate weighted averaging and other statistics of metrics on validation datasets across clients\n    local_val_metrics = self.coordinator.global_test(flag='val')\n    for met_name, met_val in local_val_metrics.items():\n        self.output['local_val_'+met_name+'_dist'].append(met_val)\n        self.output['local_val_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n        self.output['mean_local_val_' + met_name].append(np.mean(met_val))\n        self.output['std_local_val_' + met_name].append(np.std(met_val))\n    local_test_metrics = self.coordinator.global_test(flag='test')\n    for met_name, met_val in local_test_metrics.items():\n        self.output['local_test_'+met_name+'_dist'].append(met_val)\n        self.output['local_test_' + met_name].append(1.0 * sum([client_vol * client_met for client_vol, client_met in zip(local_data_vols, met_val)]) / total_data_vol)\n        self.output['mean_local_test_' + met_name].append(np.mean(met_val))\n        self.output['std_local_test_' + met_name].append(np.std(met_val))\n    # output to stdout\n    self.show_current_output()\n</code></pre>"},{"location":"Docs/experiment/logger/BasicLogger/#flgo.experiment.logger.BasicLogger.organize_output","title":"<code>organize_output(*args, **kwargs)</code>","text":"<p>This method will be called before saving self.output</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def organize_output(self, *args, **kwargs):\n\"\"\"This method will be called before saving self.output\"\"\"\n    for key in self.output.keys():\n        if '_dist' in key:\n            self.output[key] = self.output[key][-1]\n    return\n</code></pre>"},{"location":"Docs/experiment/logger/BasicLogger/#flgo.experiment.logger.BasicLogger.register_variable","title":"<code>register_variable(**kwargs)</code>","text":"<p>Initialze the logger in utils.fflow.initialize()</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def register_variable(self, **kwargs):\n\"\"\"Initialze the logger in utils.fflow.initialize()\"\"\"\n    for k, v in kwargs.items():\n        setattr(self, k, v)\n    return\n</code></pre>"},{"location":"Docs/experiment/logger/BasicLogger/#flgo.experiment.logger.BasicLogger.save_output_as_json","title":"<code>save_output_as_json(filepath=None)</code>","text":"<p>Save the self.output as .json file</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def save_output_as_json(self, filepath=None):\n\"\"\"Save the self.output as .json file\"\"\"\n    if len(self.output) == 0: return\n    self.organize_output()\n    self.output_to_jsonable_dict()\n    if filepath is None:\n        filepath = os.path.join(self.get_output_path(),self.get_output_name())\n    if not self.overwrite:\n        if os.path.exists(filepath):\n            with open(filepath, 'r') as inf:\n                original_record = json.loads(inf.read())\n            o_keys = set(original_record.keys())\n            output_keys = set(self.output.keys())\n            new_keys = list(output_keys.difference(o_keys))\n            for k in new_keys:\n                original_record[k] = self.output[k]\n            self.output = original_record\n    try:\n        with open(filepath, 'w') as outf:\n            json.dump(dict(self.output), outf)\n    except:\n        self.error('Failed to save flw.logger.output as results')\n</code></pre>"},{"location":"Docs/experiment/logger/BasicLogger/#flgo.experiment.logger.BasicLogger.time_end","title":"<code>time_end(key='')</code>","text":"<p>Create a timestamp that ends the event 'key' and print the time interval of the event.</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def time_end(self, key=''):\n\"\"\"Create a timestamp that ends the event 'key' and print the time interval of the event.\"\"\"\n    if key not in [k for k in self.time_buf.keys()]:\n        raise RuntimeError(\"Timer end before start.\")\n    else:\n        self.time_buf[key][-1] = time.time() - self.time_buf[key][-1]\n        self.info(\"{:&lt;30s}{:.4f}\".format(key + \":\", self.time_buf[key][-1]) + 's')\n        return self.time_buf[key][-1]\n</code></pre>"},{"location":"Docs/experiment/logger/BasicLogger/#flgo.experiment.logger.BasicLogger.time_start","title":"<code>time_start(key='')</code>","text":"<p>Create a timestamp of the event 'key' starting</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def time_start(self, key=''):\n\"\"\"Create a timestamp of the event 'key' starting\"\"\"\n    if key not in [k for k in self.time_buf.keys()]:\n        self.time_buf[key] = []\n    self.time_buf[key].append(time.time())\n</code></pre>"},{"location":"Docs/experiment/logger/BasicLogger/#flgo.experiment.logger.BasicLogger.write_var_into_output","title":"<code>write_var_into_output(var_name=None, var_value=None)</code>","text":"<p>Add variable 'var_name' and its value var_value to logger</p> Source code in <code>flgo\\experiment\\logger\\__init__.py</code> <pre><code>def write_var_into_output(self, var_name=None, var_value=None):\n\"\"\"Add variable 'var_name' and its value var_value to logger\"\"\"\n    if var_name == None: raise RuntimeError(\"Missing the name of the variable to be logged.\")\n    self.output[var_name].append(var_value)\n    return\n</code></pre>"},{"location":"Docs/simulator/","title":"Index","text":""},{"location":"Docs/simulator/#flgo.simulator","title":"<code>flgo.simulator</code>","text":"<p>This module is to simulate arbitrary system heterogeneity that may occur in practice. We conclude four types of system heterogeneity from existing works.</p> System Heterogeneity Description <ol> <li> <p>Availability: the devices will be either available or unavailable at each moment, where only the                 available devices can be selected to participate in training.</p> </li> <li> <p>Responsiveness: the responsiveness describes the length of the period from the server broadcasting the                 gloabl model to the server receiving the locally trained model from a particular client.</p> </li> <li> <p>Completeness: since the server cannot fully control the behavior of devices,it's possible for devices to                 upload imcomplete model updates (i.e. only training for a few steps).</p> </li> <li> <p>Connectivity: the clients who promise to complete training may suffer accidients so that the server may lose                 connections with these client who will never return the currently trained local_movielens_recommendation model.</p> </li> </ol> <p>We build up a client state machine to simulate the four types of system heterogeneity, and provide high-level APIs to allow customized system heterogeneity simulation.</p> <p>Example: How to customize the system heterogeneity:</p> <pre><code>&gt;&gt;&gt; class MySimulator(flgo.simulator.base.BasicSimulator):\n...     def update_client_availability(self):\n...         # update the variable 'prob_available' and 'prob_unavailable' for all the clients\n...         self.set_variable(self.all_clients, 'prob_available', [0.9 for _ in self.all_clients])\n...         self.set_variable(self.all_clients, 'prob_unavailable', [0.1 for _ in self.all_clients])\n...\n...     def update_client_connectivity(self, client_ids):\n...         # update the variable 'prob_drop' for clients in client_ids\n...         self.set_variable(client_ids, 'prob_drop', [0.1 for _ in client_ids])\n...\n...     def update_client_responsiveness(self, client_ids, *args, **kwargs):\n...         # update the variable 'latency' for clients in client_ids\n...         self.set_variable(client_ids, 'latency', [np.random.randint(5,100) for _ in client_ids])\n...\n...     def update_client_completeness(self, client_ids, *args, **kwargs):\n...         # update the variable 'working_amount' for clients in client_ids\n...         self.set_variable(client_ids, 'working_amount',  [max(int(self.clients[cid].num_steps*np.random.rand()), 1) for cid in client_ids])\n&gt;&gt;&gt; r = flgo.init(task, algorithm=fedavg, Simulator=MySimulator)\n&gt;&gt;&gt; # The runner r will be runned under the customized system heterogeneity, where the clients' states will be flushed by\n&gt;&gt;&gt; # MySimulator.update_client_xxx at each moment of the virtual clock or particular events happen (i.e. a client was selected)\n</code></pre> <p>We also provide some preset Simulator like flgo.simulator.DefaultSimulator and flgo.simulator.</p>"},{"location":"Docs/simulator/base/","title":"flgo.simulator.base","text":""},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator","title":"<code>BasicSimulator</code>","text":"<p>         Bases: <code>AbstractSimulator</code></p> <p>Simulate the system heterogeneity with the client state machine.</p> <p>Parameters:</p> Name Type Description Default <code>object</code> <code>list</code> <p>a list of objects in the federated scenario</p> required Source code in <code>flgo\\simulator\\base.py</code> <pre><code>class BasicSimulator(AbstractSimulator):\nr\"\"\"\n    Simulate the system heterogeneity with the client state machine.\n\n    Args:\n        object (list): a list of objects in the federated scenario\n    \"\"\"\n    _STATE = ['offline', 'idle', 'selected', 'working', 'dropped']\n    _VAR_NAMES = ['prob_available', 'prob_unavailable', 'prob_drop', 'working_amount', 'latency']\n    def __init__(self, objects, *args, **kwargs):\n        if len(objects)&gt;0:\n            self.server = objects[0]\n            self.clients = {c.id:c for c in objects[1:]}\n        else:\n            self.server = None\n            self.clients = {}\n        self.all_clients = list(self.clients.keys())\n        self.random_module = np.random.RandomState(0)\n        # client states and the variables\n        self.client_states = {cid:'idle' for cid in self.clients}\n        self.roundwise_fixed_availability = False\n        self.availability_latest_round = -1\n        self.variables = {c.id:{\n            'prob_available': 1.,\n            'prob_unavailable': 0.,\n            'prob_drop': 0.,\n            'working_amount': c.num_steps,\n            'latency': 0,\n        } for c in self.clients.values()}\n        for var in self._VAR_NAMES:\n            self.set_variable(self.all_clients, var, [self.variables[cid][var] for cid in self.all_clients])\n        self.state_counter = {c:{'dropped_counter': 0, 'latency_counter': 0, } for c in self.clients}\n\n    def initialize(self, *args, **kwargs):\n        return\n\n    def get_client_with_state(self, state='idle'):\nr\"\"\"\n        Get clients according to their states.\n\n        Args:\n            state (str): the state in ['offline', 'idle', 'selected', 'working', 'dropped']\n\n        Returns:\n            a list of clients whose states are state\n        \"\"\"\n        return [cid for cid, cstate in self.client_states.items() if cstate == state]\n\n    def set_client_state(self, client_ids, state):\nr\"\"\"\n        Set the states of clients in client_ids to the state\n\n        Args:\n            client_ids (list): a list of clients' ids\n            state (str): the state in ['offline', 'idle', 'selected', 'working', 'dropped']\n\n        Returns:\n            a list of clients whose states are state\n        \"\"\"\n        if state not in self._STATE: raise RuntimeError('{} not in the default state'.format(state))\n        if type(client_ids) is not list: client_ids = [client_ids]\n        for cid in client_ids: self.client_states[cid] = state\n        if state == 'dropped':\n            self.set_client_dropped_counter(client_ids)\n        if state == 'working':\n            self.set_client_latency_counter(client_ids)\n        if state == 'idle':\n            self.reset_client_counter(client_ids)\n\n    def set_client_latency_counter(self, client_ids = []):\nr\"\"\"Set the latency_counter\"\"\"\n        if type(client_ids) is not list: client_ids = [client_ids]\n        for cid in client_ids:\n            self.state_counter[cid]['dropped_counter'] = 0\n            self.state_counter[cid]['latency_counter'] = self.variables[cid]['latency']\n\n    def set_client_dropped_counter(self, client_ids = []):\nr\"\"\"Set the dropped_counter\"\"\"\n        if type(client_ids) is not list: client_ids = [client_ids]\n        for cid in client_ids:\n            self.state_counter[cid]['latency_counter'] = 0\n            self.state_counter[cid]['dropped_counter'] = self.server.get_tolerance_for_latency()\n\n    def reset_client_counter(self, client_ids = []):\nr\"\"\"Reset the clients' counter\"\"\"\n        if type(client_ids) is not list: client_ids = [client_ids]\n        for cid in client_ids:\n            self.state_counter[cid]['dropped_counter'] = self.state_counter[cid]['latency_counter'] = 0\n        return\n\n    def get_clients(self, client_ids:list=None):\n\"\"\"\n        Args:\n            client_ids (list): a list of client ids\n        Returns:\n            res (list): a list of client object\n        \"\"\"\n        if client_ids is None: return [self.clients[cid] for cid in self.all_clients]\n        return [self.clients[cid] for cid in client_ids]\n\n    @property\n    def idle_clients(self):\n\"\"\"Return ideal clients\"\"\"\n        return self.get_client_with_state('idle')\n\n    @property\n    def working_clients(self):\n\"\"\"Return working clients\"\"\"\n        return self.get_client_with_state('working')\n\n    @property\n    def offline_clients(self):\n\"\"\"Return offline clients\"\"\"\n        return self.get_client_with_state('offline')\n\n    @property\n    def selected_clients(self):\n\"\"\"Return the selected clients\"\"\"\n        return self.get_client_with_state('selected')\n\n    @property\n    def dropped_clients(self):\n\"\"\"Return the dropped clients\"\"\"\n        return self.get_client_with_state('dropped')\n\n    def get_variable(self, client_ids, varname):\nr\"\"\"\n        Get the simulator-private variables of the clients in client_ids according to varname\n\n        Args:\n            client_ids (list): a list of clients' ids\n            varname (str): the name of the simulator-private variable\n\n        Returns:\n            the simulator-private variables of the clients in client_ids\n        \"\"\"\n        if len(self.variables) ==0: return None\n        if type(client_ids) is not list: client_ids = [client_ids]\n        return [self.variables[cid][varname] if varname in self.variables[cid].keys() else None for cid in client_ids]\n\n    def set_variable(self, client_ids, varname, values):\nr\"\"\"\n        Set the simulator-private variables of the clients in client_ids to values\n\n        Args:\n            client_ids (list): a list of clients' ids\n            varname (str): the name of the simulator-private variable\n            values (list): a list of things\n        \"\"\"\n        if type(client_ids) is not list: client_ids = [client_ids]\n        if not isinstance(values, Iterable): values = [values]\n        assert len(client_ids) == len(values)\n        for cid, v in zip(client_ids, values):\n            self.variables[cid][varname] = v\n            setattr(self.clients[cid], '_'+varname, v)\n\n    def update_client_availability(self, *args, **kwargs):\n\"\"\"API to update client availability every time unit\"\"\"\n        return\n\n    def update_client_connectivity(self, client_ids, *args, **kwargs):\n\"\"\"API to update client connectivity every time unit\"\"\"\n        return\n\n    def update_client_completeness(self, client_ids, *args, **kwargs):\n\"\"\"API to update client completeness every time unit\"\"\"\n        return\n\n    def update_client_responsiveness(self, client_ids, *args, **kwargs):\n\"\"\"API to update client responsiveness every time unit\"\"\"\n        return\n\n    def flush(self):\n\"\"\"Flush the client state machine as time goes by\"\"\"\n        # +++++++++++++++++++ availability +++++++++++++++++++++\n        # change self.variables[cid]['prob_available'] and self.variables[cid]['prob_unavailable'] for each client `cid`\n        self.update_client_availability()\n        # update states for offline &amp; idle clients\n        if len(self.idle_clients)==0 or not self.roundwise_fixed_availability or self.server.current_round &gt; self.availability_latest_round:\n            self.availability_latest_round = self.server.current_round\n            offline_clients = {cid: 'offline' for cid in self.offline_clients}\n            idle_clients = {cid:'idle' for cid in self.idle_clients}\n            for cid in offline_clients:\n                if (self.random_module.rand() &lt;= self.variables[cid]['prob_available']): offline_clients[cid] = 'idle'\n            for cid in self.idle_clients:\n                if  (self.random_module.rand() &lt;= self.variables[cid]['prob_unavailable']): idle_clients[cid] = 'offline'\n            new_idle_clients = [cid for cid in offline_clients if offline_clients[cid] == 'idle']\n            new_offline_clients = [cid for cid in idle_clients if idle_clients[cid] == 'offline']\n            self.set_client_state(new_idle_clients, 'idle')\n            self.set_client_state(new_offline_clients, 'offline')\n        # update states for dropped clients\n        for cid in self.dropped_clients:\n            self.state_counter[cid]['dropped_counter'] -= 1\n            if self.state_counter[cid]['dropped_counter'] &lt; 0:\n                self.state_counter[cid]['dropped_counter'] = 0\n                self.client_states[cid] = 'offline'\n                if (self.random_module.rand() &lt; self.variables[cid]['prob_unavailable']):\n                    self.set_client_state([cid], 'offline')\n                else:\n                    self.set_client_state([cid], 'idle')\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.dropped_clients","title":"<code>dropped_clients</code>  <code>property</code>","text":"<p>Return the dropped clients</p>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.idle_clients","title":"<code>idle_clients</code>  <code>property</code>","text":"<p>Return ideal clients</p>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.offline_clients","title":"<code>offline_clients</code>  <code>property</code>","text":"<p>Return offline clients</p>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.selected_clients","title":"<code>selected_clients</code>  <code>property</code>","text":"<p>Return the selected clients</p>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.working_clients","title":"<code>working_clients</code>  <code>property</code>","text":"<p>Return working clients</p>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.flush","title":"<code>flush()</code>","text":"<p>Flush the client state machine as time goes by</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def flush(self):\n\"\"\"Flush the client state machine as time goes by\"\"\"\n    # +++++++++++++++++++ availability +++++++++++++++++++++\n    # change self.variables[cid]['prob_available'] and self.variables[cid]['prob_unavailable'] for each client `cid`\n    self.update_client_availability()\n    # update states for offline &amp; idle clients\n    if len(self.idle_clients)==0 or not self.roundwise_fixed_availability or self.server.current_round &gt; self.availability_latest_round:\n        self.availability_latest_round = self.server.current_round\n        offline_clients = {cid: 'offline' for cid in self.offline_clients}\n        idle_clients = {cid:'idle' for cid in self.idle_clients}\n        for cid in offline_clients:\n            if (self.random_module.rand() &lt;= self.variables[cid]['prob_available']): offline_clients[cid] = 'idle'\n        for cid in self.idle_clients:\n            if  (self.random_module.rand() &lt;= self.variables[cid]['prob_unavailable']): idle_clients[cid] = 'offline'\n        new_idle_clients = [cid for cid in offline_clients if offline_clients[cid] == 'idle']\n        new_offline_clients = [cid for cid in idle_clients if idle_clients[cid] == 'offline']\n        self.set_client_state(new_idle_clients, 'idle')\n        self.set_client_state(new_offline_clients, 'offline')\n    # update states for dropped clients\n    for cid in self.dropped_clients:\n        self.state_counter[cid]['dropped_counter'] -= 1\n        if self.state_counter[cid]['dropped_counter'] &lt; 0:\n            self.state_counter[cid]['dropped_counter'] = 0\n            self.client_states[cid] = 'offline'\n            if (self.random_module.rand() &lt; self.variables[cid]['prob_unavailable']):\n                self.set_client_state([cid], 'offline')\n            else:\n                self.set_client_state([cid], 'idle')\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.get_client_with_state","title":"<code>get_client_with_state(state='idle')</code>","text":"<p>Get clients according to their states.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>str</code> <p>the state in ['offline', 'idle', 'selected', 'working', 'dropped']</p> <code>'idle'</code> <p>Returns:</p> Type Description <p>a list of clients whose states are state</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def get_client_with_state(self, state='idle'):\nr\"\"\"\n    Get clients according to their states.\n\n    Args:\n        state (str): the state in ['offline', 'idle', 'selected', 'working', 'dropped']\n\n    Returns:\n        a list of clients whose states are state\n    \"\"\"\n    return [cid for cid, cstate in self.client_states.items() if cstate == state]\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.get_clients","title":"<code>get_clients(client_ids=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>client_ids</code> <code>list</code> <p>a list of client ids</p> <code>None</code> <p>Returns:</p> Name Type Description <code>res</code> <code>list</code> <p>a list of client object</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def get_clients(self, client_ids:list=None):\n\"\"\"\n    Args:\n        client_ids (list): a list of client ids\n    Returns:\n        res (list): a list of client object\n    \"\"\"\n    if client_ids is None: return [self.clients[cid] for cid in self.all_clients]\n    return [self.clients[cid] for cid in client_ids]\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.get_variable","title":"<code>get_variable(client_ids, varname)</code>","text":"<p>Get the simulator-private variables of the clients in client_ids according to varname</p> <p>Parameters:</p> Name Type Description Default <code>client_ids</code> <code>list</code> <p>a list of clients' ids</p> required <code>varname</code> <code>str</code> <p>the name of the simulator-private variable</p> required <p>Returns:</p> Type Description <p>the simulator-private variables of the clients in client_ids</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def get_variable(self, client_ids, varname):\nr\"\"\"\n    Get the simulator-private variables of the clients in client_ids according to varname\n\n    Args:\n        client_ids (list): a list of clients' ids\n        varname (str): the name of the simulator-private variable\n\n    Returns:\n        the simulator-private variables of the clients in client_ids\n    \"\"\"\n    if len(self.variables) ==0: return None\n    if type(client_ids) is not list: client_ids = [client_ids]\n    return [self.variables[cid][varname] if varname in self.variables[cid].keys() else None for cid in client_ids]\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.reset_client_counter","title":"<code>reset_client_counter(client_ids=[])</code>","text":"<p>Reset the clients' counter</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def reset_client_counter(self, client_ids = []):\nr\"\"\"Reset the clients' counter\"\"\"\n    if type(client_ids) is not list: client_ids = [client_ids]\n    for cid in client_ids:\n        self.state_counter[cid]['dropped_counter'] = self.state_counter[cid]['latency_counter'] = 0\n    return\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.set_client_dropped_counter","title":"<code>set_client_dropped_counter(client_ids=[])</code>","text":"<p>Set the dropped_counter</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def set_client_dropped_counter(self, client_ids = []):\nr\"\"\"Set the dropped_counter\"\"\"\n    if type(client_ids) is not list: client_ids = [client_ids]\n    for cid in client_ids:\n        self.state_counter[cid]['latency_counter'] = 0\n        self.state_counter[cid]['dropped_counter'] = self.server.get_tolerance_for_latency()\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.set_client_latency_counter","title":"<code>set_client_latency_counter(client_ids=[])</code>","text":"<p>Set the latency_counter</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def set_client_latency_counter(self, client_ids = []):\nr\"\"\"Set the latency_counter\"\"\"\n    if type(client_ids) is not list: client_ids = [client_ids]\n    for cid in client_ids:\n        self.state_counter[cid]['dropped_counter'] = 0\n        self.state_counter[cid]['latency_counter'] = self.variables[cid]['latency']\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.set_client_state","title":"<code>set_client_state(client_ids, state)</code>","text":"<p>Set the states of clients in client_ids to the state</p> <p>Parameters:</p> Name Type Description Default <code>client_ids</code> <code>list</code> <p>a list of clients' ids</p> required <code>state</code> <code>str</code> <p>the state in ['offline', 'idle', 'selected', 'working', 'dropped']</p> required <p>Returns:</p> Type Description <p>a list of clients whose states are state</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def set_client_state(self, client_ids, state):\nr\"\"\"\n    Set the states of clients in client_ids to the state\n\n    Args:\n        client_ids (list): a list of clients' ids\n        state (str): the state in ['offline', 'idle', 'selected', 'working', 'dropped']\n\n    Returns:\n        a list of clients whose states are state\n    \"\"\"\n    if state not in self._STATE: raise RuntimeError('{} not in the default state'.format(state))\n    if type(client_ids) is not list: client_ids = [client_ids]\n    for cid in client_ids: self.client_states[cid] = state\n    if state == 'dropped':\n        self.set_client_dropped_counter(client_ids)\n    if state == 'working':\n        self.set_client_latency_counter(client_ids)\n    if state == 'idle':\n        self.reset_client_counter(client_ids)\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.set_variable","title":"<code>set_variable(client_ids, varname, values)</code>","text":"<p>Set the simulator-private variables of the clients in client_ids to values</p> <p>Parameters:</p> Name Type Description Default <code>client_ids</code> <code>list</code> <p>a list of clients' ids</p> required <code>varname</code> <code>str</code> <p>the name of the simulator-private variable</p> required <code>values</code> <code>list</code> <p>a list of things</p> required Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def set_variable(self, client_ids, varname, values):\nr\"\"\"\n    Set the simulator-private variables of the clients in client_ids to values\n\n    Args:\n        client_ids (list): a list of clients' ids\n        varname (str): the name of the simulator-private variable\n        values (list): a list of things\n    \"\"\"\n    if type(client_ids) is not list: client_ids = [client_ids]\n    if not isinstance(values, Iterable): values = [values]\n    assert len(client_ids) == len(values)\n    for cid, v in zip(client_ids, values):\n        self.variables[cid][varname] = v\n        setattr(self.clients[cid], '_'+varname, v)\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.update_client_availability","title":"<code>update_client_availability(*args, **kwargs)</code>","text":"<p>API to update client availability every time unit</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def update_client_availability(self, *args, **kwargs):\n\"\"\"API to update client availability every time unit\"\"\"\n    return\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.update_client_completeness","title":"<code>update_client_completeness(client_ids, *args, **kwargs)</code>","text":"<p>API to update client completeness every time unit</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def update_client_completeness(self, client_ids, *args, **kwargs):\n\"\"\"API to update client completeness every time unit\"\"\"\n    return\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.update_client_connectivity","title":"<code>update_client_connectivity(client_ids, *args, **kwargs)</code>","text":"<p>API to update client connectivity every time unit</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def update_client_connectivity(self, client_ids, *args, **kwargs):\n\"\"\"API to update client connectivity every time unit\"\"\"\n    return\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.BasicSimulator.update_client_responsiveness","title":"<code>update_client_responsiveness(client_ids, *args, **kwargs)</code>","text":"<p>API to update client responsiveness every time unit</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def update_client_responsiveness(self, client_ids, *args, **kwargs):\n\"\"\"API to update client responsiveness every time unit\"\"\"\n    return\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock","title":"<code>ElemClock</code>","text":"<p>Simulate the clock by the timestamp of each Element</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>class ElemClock:\nr\"\"\"Simulate the clock by the timestamp of each Element\"\"\"\n    class Elem:\nr\"\"\"\n        Element with a timestamp\n\n        Args:\n            x: element\n            time (int): the timestamp\n        \"\"\"\n        def __init__(self, x, time):\n            self.x = x\n            self.time = time\n\n        def __str__(self):\n            return '{} at Time {}'.format(self.x, self.time)\n\n        def __lt__(self, other):\n            return self.time &lt; other.time\n\n    def __init__(self):\n        self.q = PriorityQueue()\n        self.time = 0\n        self.simulator = None\n\n    def step(self, delta_t=1):\nr\"\"\"\n        Step delta_t units of the virtual time\n\n        Args:\n            delta_t (int): the delta of time\n        \"\"\"\n        if delta_t &lt; 0: raise RuntimeError(\"Cannot inverse time of simulator.base.clock.\")\n        if self.simulator is not None:\n            for t in range(delta_t):\n                self.simulator.flush()\n        self.time += delta_t\n\n    def set_time(self, t):\nr\"\"\"\n        Set time\n\n        Args:\n            t (int): time\n        \"\"\"\n        if t &lt; self.time: raise RuntimeError(\"Cannot inverse time of simulator.base.clock.\")\n        self.time = t\n\n    def put(self, x, time):\nr\"\"\"\n        Put an element into the time queue with timestamp\n\n        Args:\n            x: element\n            time (int): the timestamp\n        \"\"\"\n        self.q.put(self.Elem(x, time))\n\n    def get(self):\nr\"\"\"\n        Get an element from the queue\n\n        Returns:\n            the element in the nearest coming time\n        \"\"\"\n        if self.q.empty(): return None\n        return self.q.get().x\n\n    def get_until(self, t):\nr\"\"\"\n        Get elements from the queue until time t\n\n        Args:\n            t (int): time\n\n        Returns:\n            a list of elements whose timestamps is no larger than t\n        \"\"\"\n        res = []\n        while not self.empty():\n            elem = self.q.get()\n            if elem.time &gt; t:\n                self.put(elem.x, elem.time)\n                break\n            pkg = elem.x\n            res.append(pkg)\n        return res\n\n    def get_sofar(self):\nr\"\"\"\n        Get elements from the queue until now\n\n        Returns:\n            a list of elements whose timestamps is no larger than the current time\n        \"\"\"\n        return self.get_until(self.current_time)\n\n    def gets(self):\nr\"\"\"\n        Get all the elements in the queue\n\n        Returns:\n            a list of elements in the queue\n        \"\"\"\n        if self.empty(): return []\n        res = []\n        while not self.empty(): res.append(self.q.get())\n        res = [rx.x for rx in res]\n        return res\n\n    def clear(self):\nr\"\"\"\n        Clear the queue\n        \"\"\"\n        while not self.empty():\n            self.get()\n\n    def conditionally_clear(self, f):\nr\"\"\"\n        Clear elements if f(element) is False\n\n        Args:\n            f (function): a function that receives element and returns bool variable\n        \"\"\"\n        buf = []\n        while not self.empty(): buf.append(self.q.get())\n        for elem in buf:\n            if not f(elem.x): self.q.put(elem)\n        return\n\n    def empty(self):\nr\"\"\"Return whether the queue is empty\"\"\"\n        return self.q.empty()\n\n    @ property\n    def current_time(self):\nr\"\"\"Return the current time\"\"\"\n        return self.time\n\n    def register_simulator(self, simulator):\nr\"\"\"Set self.simulator=simulator\"\"\"\n        self.simulator = simulator\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.current_time","title":"<code>current_time</code>  <code>property</code>","text":"<p>Return the current time</p>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.Elem","title":"<code>Elem</code>","text":"<p>Element with a timestamp</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>element</p> required <code>time</code> <code>int</code> <p>the timestamp</p> required Source code in <code>flgo\\simulator\\base.py</code> <pre><code>class Elem:\nr\"\"\"\n    Element with a timestamp\n\n    Args:\n        x: element\n        time (int): the timestamp\n    \"\"\"\n    def __init__(self, x, time):\n        self.x = x\n        self.time = time\n\n    def __str__(self):\n        return '{} at Time {}'.format(self.x, self.time)\n\n    def __lt__(self, other):\n        return self.time &lt; other.time\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.clear","title":"<code>clear()</code>","text":"<p>Clear the queue</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def clear(self):\nr\"\"\"\n    Clear the queue\n    \"\"\"\n    while not self.empty():\n        self.get()\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.conditionally_clear","title":"<code>conditionally_clear(f)</code>","text":"<p>Clear elements if f(element) is False</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>function</code> <p>a function that receives element and returns bool variable</p> required Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def conditionally_clear(self, f):\nr\"\"\"\n    Clear elements if f(element) is False\n\n    Args:\n        f (function): a function that receives element and returns bool variable\n    \"\"\"\n    buf = []\n    while not self.empty(): buf.append(self.q.get())\n    for elem in buf:\n        if not f(elem.x): self.q.put(elem)\n    return\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.empty","title":"<code>empty()</code>","text":"<p>Return whether the queue is empty</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def empty(self):\nr\"\"\"Return whether the queue is empty\"\"\"\n    return self.q.empty()\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.get","title":"<code>get()</code>","text":"<p>Get an element from the queue</p> <p>Returns:</p> Type Description <p>the element in the nearest coming time</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def get(self):\nr\"\"\"\n    Get an element from the queue\n\n    Returns:\n        the element in the nearest coming time\n    \"\"\"\n    if self.q.empty(): return None\n    return self.q.get().x\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.get_sofar","title":"<code>get_sofar()</code>","text":"<p>Get elements from the queue until now</p> <p>Returns:</p> Type Description <p>a list of elements whose timestamps is no larger than the current time</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def get_sofar(self):\nr\"\"\"\n    Get elements from the queue until now\n\n    Returns:\n        a list of elements whose timestamps is no larger than the current time\n    \"\"\"\n    return self.get_until(self.current_time)\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.get_until","title":"<code>get_until(t)</code>","text":"<p>Get elements from the queue until time t</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>int</code> <p>time</p> required <p>Returns:</p> Type Description <p>a list of elements whose timestamps is no larger than t</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def get_until(self, t):\nr\"\"\"\n    Get elements from the queue until time t\n\n    Args:\n        t (int): time\n\n    Returns:\n        a list of elements whose timestamps is no larger than t\n    \"\"\"\n    res = []\n    while not self.empty():\n        elem = self.q.get()\n        if elem.time &gt; t:\n            self.put(elem.x, elem.time)\n            break\n        pkg = elem.x\n        res.append(pkg)\n    return res\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.gets","title":"<code>gets()</code>","text":"<p>Get all the elements in the queue</p> <p>Returns:</p> Type Description <p>a list of elements in the queue</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def gets(self):\nr\"\"\"\n    Get all the elements in the queue\n\n    Returns:\n        a list of elements in the queue\n    \"\"\"\n    if self.empty(): return []\n    res = []\n    while not self.empty(): res.append(self.q.get())\n    res = [rx.x for rx in res]\n    return res\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.put","title":"<code>put(x, time)</code>","text":"<p>Put an element into the time queue with timestamp</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>element</p> required <code>time</code> <code>int</code> <p>the timestamp</p> required Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def put(self, x, time):\nr\"\"\"\n    Put an element into the time queue with timestamp\n\n    Args:\n        x: element\n        time (int): the timestamp\n    \"\"\"\n    self.q.put(self.Elem(x, time))\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.register_simulator","title":"<code>register_simulator(simulator)</code>","text":"<p>Set self.simulator=simulator</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def register_simulator(self, simulator):\nr\"\"\"Set self.simulator=simulator\"\"\"\n    self.simulator = simulator\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.set_time","title":"<code>set_time(t)</code>","text":"<p>Set time</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>int</code> <p>time</p> required Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def set_time(self, t):\nr\"\"\"\n    Set time\n\n    Args:\n        t (int): time\n    \"\"\"\n    if t &lt; self.time: raise RuntimeError(\"Cannot inverse time of simulator.base.clock.\")\n    self.time = t\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.ElemClock.step","title":"<code>step(delta_t=1)</code>","text":"<p>Step delta_t units of the virtual time</p> <p>Parameters:</p> Name Type Description Default <code>delta_t</code> <code>int</code> <p>the delta of time</p> <code>1</code> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def step(self, delta_t=1):\nr\"\"\"\n    Step delta_t units of the virtual time\n\n    Args:\n        delta_t (int): the delta of time\n    \"\"\"\n    if delta_t &lt; 0: raise RuntimeError(\"Cannot inverse time of simulator.base.clock.\")\n    if self.simulator is not None:\n        for t in range(delta_t):\n            self.simulator.flush()\n    self.time += delta_t\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.PriorityQueue","title":"<code>PriorityQueue</code>","text":"<p>Priority Queue</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>class PriorityQueue:\nr\"\"\"Priority Queue\"\"\"\n    def __init__(self):\n        self.queue = []\n\n    def size(self):\nr\"\"\"The size of the queue\"\"\"\n        return len(self.queue)\n\n    def empty(self):\nr\"\"\"Return whether the queue is empty\"\"\"\n        return len(self.queue)==0\n\n    def put(self, item):\nr\"\"\"Put item into the queue\"\"\"\n        heapq.heappush(self.queue, item)\n\n    def get(self):\nr\"\"\"Get item from the queue\"\"\"\n        return heapq.heappop(self.queue)\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.PriorityQueue.empty","title":"<code>empty()</code>","text":"<p>Return whether the queue is empty</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def empty(self):\nr\"\"\"Return whether the queue is empty\"\"\"\n    return len(self.queue)==0\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.PriorityQueue.get","title":"<code>get()</code>","text":"<p>Get item from the queue</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def get(self):\nr\"\"\"Get item from the queue\"\"\"\n    return heapq.heappop(self.queue)\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.PriorityQueue.put","title":"<code>put(item)</code>","text":"<p>Put item into the queue</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def put(self, item):\nr\"\"\"Put item into the queue\"\"\"\n    heapq.heappush(self.queue, item)\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.PriorityQueue.size","title":"<code>size()</code>","text":"<p>The size of the queue</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def size(self):\nr\"\"\"The size of the queue\"\"\"\n    return len(self.queue)\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.seed_generator","title":"<code>seed_generator(seed=0)</code>","text":"<p>Return an integer as the seed</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def seed_generator(seed=0):\n\"\"\"Return an integer as the seed\"\"\"\n    while True:\n        yield seed+1\n        seed+=1\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.size_of_package","title":"<code>size_of_package(package)</code>","text":"<p>Compute the size of the package</p> <p>Parameters:</p> Name Type Description Default <code>package</code> <code>dict</code> <p>the pacakge</p> required <p>Returns:</p> Name Type Description <code>size</code> <code>int</code> <p>the size of the package</p> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def size_of_package(package):\nr\"\"\"\n    Compute the size of the package\n\n    Args:\n        package (dict): the pacakge\n\n    Returns:\n        size (int): the size of the package\n    \"\"\"\n    size = 0\n    for v in package.values():\n        if type(v) is torch.Tensor:\n            size += sys.getsizeof(v.storage())\n        else:\n            size += v.__sizeof__()\n    return size\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.with_availability","title":"<code>with_availability(sample)</code>","text":"<p>The decorator for sampling with client availability</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo.algorithm.fedbase\n    &gt;&gt;&gt; import flgo.simulator.base as ss\n    &gt;&gt;&gt; class Server(flgo.algorithm.fedbase.BasicServer):\n    ...     @ss.with_availability\n    ...     def sample(self):\n    ...         ...\n</code></pre> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def with_availability(sample):\nr\"\"\"\n    The decorator for sampling with client availability\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo.algorithm.fedbase\n        &gt;&gt;&gt; import flgo.simulator.base as ss\n        &gt;&gt;&gt; class Server(flgo.algorithm.fedbase.BasicServer):\n        ...     @ss.with_availability\n        ...     def sample(self):\n        ...         ...\n    ```\n    \"\"\"\n    def sample_with_availability(self):\n        available_clients = self.gv.simulator.idle_clients\n        # ensure that there is at least one client to be available at the current moment\n        # while len(available_clients) == 0:\n        #     self.gv.clock.step()\n        #     available_clients = self.gv.simulator.idle_clients\n        # call the original sampling function\n        selected_clients = sample(self)\n        # filter the selected but unavailable clients\n        effective_clients = set(selected_clients).intersection(set(available_clients))\n        # return the selected and available clients (e.g. sampling with replacement should be considered here)\n        self._unavailable_selected_clients = [cid for cid in selected_clients if cid not in effective_clients]\n        if len(self._unavailable_selected_clients)&gt;0:\n            self.gv.logger.info('The selected clients {} are not currently available.'.format(self._unavailable_selected_clients))\n        selected_clients = [cid for cid in selected_clients if cid in effective_clients]\n        self.gv.simulator.set_client_state(selected_clients, 'selected')\n        return selected_clients\n    return sample_with_availability\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.with_clock","title":"<code>with_clock(communicate)</code>","text":"<p>The decorator to simulate the scene where there is a virtual global clock</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo.algorithm.fedbase\n    &gt;&gt;&gt; import flgo.simulator.base as ss\n    &gt;&gt;&gt; class Server(flgo.algorithm.fedbase.BasicServer):\n    ...     @ss.with_clock\n    ...     def communicate(self,...):\n    ...         ...\n</code></pre> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def with_clock(communicate):\nr\"\"\"\n    The decorator to simulate the scene where there is a virtual global clock\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo.algorithm.fedbase\n        &gt;&gt;&gt; import flgo.simulator.base as ss\n        &gt;&gt;&gt; class Server(flgo.algorithm.fedbase.BasicServer):\n        ...     @ss.with_clock\n        ...     def communicate(self,...):\n        ...         ...\n    ```\n    \"\"\"\n    def communicate_with_clock(self, selected_clients, mtype=0, asynchronous=False):\n        self.gv.simulator.update_client_completeness(selected_clients)\n        res = communicate(self, selected_clients, mtype, asynchronous)\n        # If all the selected clients are unavailable, directly return the result without waiting.\n        # Else if all the available clients have dropped out and not using asynchronous communication,  waiting for `tolerance_for_latency` time units.\n        tolerance_for_latency = self.get_tolerance_for_latency()\n        if not asynchronous and len(selected_clients)==0:\n            if hasattr(self, '_dropped_selected_clients') and len(self._dropped_selected_clients)&gt;0:\n                self.gv.clock.step(tolerance_for_latency)\n            return res\n        # Convert the unpacked packages to a list of packages of each client.\n        pkgs = [{key: vi[id] for key, vi in res.items()} for id in range(len(list(res.values())[0]))] if len(selected_clients)&gt;0 else []\n        if len(pkgs)&gt;0 and pkgs[0].get('__cid', None) is None:\n            for cid, pkg in zip(selected_clients, pkgs):\n                pkg['__cid'] = cid\n        # Put the packages from selected clients into clock only if when there are effective selected clients\n        if len(selected_clients)&gt;0:\n            # Set selected clients' states as `working`\n            self.gv.simulator.set_client_state(selected_clients, 'working')\n            for pi in pkgs:\n                self.gv.clock.put(pi, pi.get('__t', 0))\n        # Receiving packages in asynchronous\\synchronous way\n        # Wait for client packages. If communicating in asynchronous way, the waiting time is 0.\n        if asynchronous:\n            # Return the currently received packages to the server\n            eff_pkgs = self.gv.clock.get_until(self.gv.clock.current_time)\n            eff_cids = [pkg_i['__cid'] for pkg_i in eff_pkgs]\n        else:\n            # Wait all the selected clients for no more than `tolerance_for_latency` time units.\n            # Check if anyone had dropped out or will be overdue\n            max_latency = max(self.gv.simulator.get_variable(selected_clients, 'latency'))\n            any_drop, any_overdue = (hasattr(self, '_dropped_selected_clients') and len(self._dropped_selected_clients) &gt; 0), (max_latency &gt;  tolerance_for_latency)\n            # Compute delta of time for the communication.\n            delta_t = tolerance_for_latency if any_drop or any_overdue else max_latency\n            # Receive packages within due\n            eff_pkgs = self.gv.clock.get_until(self.gv.clock.current_time + delta_t)\n            self.gv.clock.step(int(delta_t))\n            # Drop the packages of overdue clients and reset their states to `idle`\n            eff_cids = [pkg_i['__cid'] for pkg_i in eff_pkgs]\n            self._overdue_clients = list(set([cid for cid in selected_clients if cid not in eff_cids]))\n            # no additional wait for the synchronous selected clients and preserve the later packages from asynchronous clients\n            if len(self._overdue_clients) &gt; 0:\n                self.gv.clock.conditionally_clear(lambda x: x['__cid'] in self._overdue_clients)\n                self.gv.simulator.set_client_state(self._overdue_clients, 'idle')\n            # Resort effective packages\n            pkg_map = {pkg_i['__cid']: pkg_i for pkg_i in eff_pkgs}\n            eff_pkgs = [pkg_map[cid] for cid in selected_clients if cid in eff_cids]\n        self.gv.simulator.set_client_state(eff_cids, 'offline')\n        self.received_clients = [pkg_i['__cid'] for pkg_i in eff_pkgs]\n        return self.unpack(eff_pkgs)\n    return communicate_with_clock\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.with_completeness","title":"<code>with_completeness(train)</code>","text":"<p>The decorator to simulate the scene where the clients may upload incomplete model updates</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo.algorithm.fedbase\n    &gt;&gt;&gt; import flgo.simulator.base as ss\n    &gt;&gt;&gt; class Client(flgo.algorithm.fedbase.BasicClient):\n    ...     @ss.with_completeness\n    ...     def train(self,...):\n    ...         ...\n</code></pre> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def with_completeness(train):\nr\"\"\"\n    The decorator to simulate the scene where the clients may upload incomplete model updates\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo.algorithm.fedbase\n        &gt;&gt;&gt; import flgo.simulator.base as ss\n        &gt;&gt;&gt; class Client(flgo.algorithm.fedbase.BasicClient):\n        ...     @ss.with_completeness\n        ...     def train(self,...):\n        ...         ...\n    ```\n    \"\"\"\n    @functools.wraps(train)\n    def train_with_incomplete_update(self, model, *args, **kwargs):\n        old_num_steps = self.num_steps\n        self.num_steps = self._working_amount\n        res = train(self, model, *args, **kwargs)\n        self.num_steps = old_num_steps\n        return res\n    return train_with_incomplete_update\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.with_dropout","title":"<code>with_dropout(communicate)</code>","text":"<p>The decorator for communicating to simulate the scene where clients may drop out</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo.algorithm.fedbase\n    &gt;&gt;&gt; import flgo.simulator.base as ss\n    &gt;&gt;&gt; class Server(flgo.algorithm.fedbase.BasicServer):\n    ...     @ss.with_dropout\n    ...     def communicate(self,...):\n    ...         ...\n</code></pre> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def with_dropout(communicate):\nr\"\"\"\n    The decorator for communicating to simulate the scene where clients may drop out\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo.algorithm.fedbase\n        &gt;&gt;&gt; import flgo.simulator.base as ss\n        &gt;&gt;&gt; class Server(flgo.algorithm.fedbase.BasicServer):\n        ...     @ss.with_dropout\n        ...     def communicate(self,...):\n        ...         ...\n    ```\n    \"\"\"\n    @functools.wraps(communicate)\n    def communicate_with_dropout(self, selected_clients, mtype=0, asynchronous=False):\n        if len(selected_clients) &gt; 0:\n            self.gv.simulator.update_client_connectivity(selected_clients)\n            probs_drop = self.gv.simulator.get_variable(selected_clients, 'prob_drop')\n            self._dropped_selected_clients = [cid for cid,prob in zip(selected_clients, probs_drop) if self.gv.simulator.random_module.rand() &lt;= prob]\n            self.gv.simulator.set_client_state(self._dropped_selected_clients, 'dropped')\n            return communicate(self, [cid for cid in selected_clients if cid not in self._dropped_selected_clients], mtype, asynchronous)\n        else:\n            return communicate(self, selected_clients, mtype, asynchronous)\n    return communicate_with_dropout\n</code></pre>"},{"location":"Docs/simulator/base/#flgo.simulator.base.with_latency","title":"<code>with_latency(communicate_with)</code>","text":"<p>The decorator to simulate the scene where there are network latencies during communication</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo.algorithm.fedbase\n    &gt;&gt;&gt; import flgo.simulator.base as ss\n    &gt;&gt;&gt; class Server(flgo.algorithm.fedbase.BasicServer):\n    ...     @ss.with_latency\n    ...     def communicate_with(self,...):\n    ...         ...\n</code></pre> Source code in <code>flgo\\simulator\\base.py</code> <pre><code>def with_latency(communicate_with):\nr\"\"\"\n    The decorator to simulate the scene where there are network latencies during communication\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo.algorithm.fedbase\n        &gt;&gt;&gt; import flgo.simulator.base as ss\n        &gt;&gt;&gt; class Server(flgo.algorithm.fedbase.BasicServer):\n        ...     @ss.with_latency\n        ...     def communicate_with(self,...):\n        ...         ...\n    ```\n    \"\"\"\n    @functools.wraps(communicate_with)\n    def delayed_communicate_with(self, target_id, package):\n        # Calculate latency for the target client\n        # Set local_movielens_recommendation model size of clients for computation cost estimation\n        model_size = package['model'].count_parameters(output=False) if 'model' in package.keys() else 0\n        self.gv.simulator.set_variable(target_id, '__model_size', model_size)\n        # Set downloading package sizes for clients for downloading cost estimation\n        self.gv.simulator.set_variable(target_id, '__download_package_size',size_of_package(package))\n        res = communicate_with(self, target_id, package)\n        # Set uploading package sizes for clients for uploading cost estimation\n        self.gv.simulator.set_variable(target_id, '__upload_package_size', size_of_package(res))\n        # update latency of the target client according to the communication cost and computation cost\n        self.gv.simulator.update_client_responsiveness([target_id])\n        # Record the size of the package that may influence the value of the latency\n        # Update the real-time latency of the client response\n        # Get the updated latency\n        latency = self.gv.simulator.get_variable(target_id, 'latency')[0]\n        self.clients[target_id]._latency = latency\n        res['__cid'] = target_id\n        # Compute the arrival time\n        res['__t'] = self.gv.clock.current_time + latency\n        return res\n    return delayed_communicate_with\n</code></pre>"},{"location":"Docs/simulator/default_simulator/","title":"flgo.simulator.default_simulator","text":"<p>This simulator supports for the following system heterogeneity:</p> <p>availability_modes = {     'IDL': ideal_client_availability,     'YMF': y_max_first_client_availability,     'MDF': more_data_first_client_availability,     'LDF': less_data_first_client_availability,     'YFF': y_fewer_first_client_availability,     'HOMO': homogeneous_client_availability,     'LN': lognormal_client_availability,     'SLN': sin_lognormal_client_availability,     'YC': y_cycle_client_availability, }</p> <p>connectivity_modes = {     'IDL': ideal_client_connectivity,     'HOMO': homogeneous_client_connectivity, }</p> <p>completeness_modes = {     'IDL': ideal_client_completeness,     'PDU': part_dynamic_uniform_client_completeness,     'FSU': full_static_unifrom_client_completeness,     'ADU': arbitrary_dynamic_unifrom_client_completeness,     'ASU': arbitrary_static_unifrom_client_completeness, }</p> <p>responsiveness_modes = {     'IDL': ideal_client_responsiveness,     'LN': lognormal_client_responsiveness,     'UNI': uniform_client_responsiveness, }</p>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.arbitrary_dynamic_unifrom_client_completeness","title":"<code>arbitrary_dynamic_unifrom_client_completeness(simulator, a=1, b=1)</code>","text":"<p>This setting follows the setting in the paper 'Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization' (http://arxiv.org/abs/2007.07481). The string <code>mode</code> should be like 'FEDNOVA-Uniform(a,b)' where <code>a</code> is the minimal value of the number of local_movielens_recommendation epochs and <code>b</code> is the maximal value. If this mode is active, the <code>num_epochs</code> and <code>num_steps</code> of clients will be disable.</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def arbitrary_dynamic_unifrom_client_completeness(simulator, a=1, b=1):\n\"\"\"\n    This setting follows the setting in the paper 'Tackling the Objective Inconsistency Problem in\n    Heterogeneous Federated Optimization' (http://arxiv.org/abs/2007.07481). The string `mode` should be like\n    'FEDNOVA-Uniform(a,b)' where `a` is the minimal value of the number of local_movielens_recommendation epochs and `b` is the maximal\n    value. If this mode is active, the `num_epochs` and `num_steps` of clients will be disable.\n    \"\"\"\n    simulator._incomplete_a = min(a, 1)\n    simulator._incomplete_b = max(b, simulator._incomplete_a)\n    def f(self, client_ids = []):\n        for cid in client_ids:\n            self.clients[cid].set_local_epochs(self.random_module.randint(low=self._incomplete_a, high=self._incomplete_b))\n        working_amounts = [self.clients[cid].num_steps for cid in self.all_clients]\n        self.set_variable(self.all_clients, 'working_amount', working_amounts)\n        return\n    return f\n</code></pre>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.arbitrary_static_unifrom_client_completeness","title":"<code>arbitrary_static_unifrom_client_completeness(simulator, a=1, b=1)</code>","text":"<p>This setting follows the setting in the paper 'Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization' (http://arxiv.org/abs/2007.07481). The string <code>mode</code> should be like 'FEDNOVA-Uniform(a,b)' where <code>a</code> is the minimal value of the number of local_movielens_recommendation epochs and <code>b</code> is the maximal value. If this mode is active, the <code>num_epochs</code> and <code>num_steps</code> of clients will be disable.</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def arbitrary_static_unifrom_client_completeness(simulator, a=1, b=1):\n\"\"\"\n    This setting follows the setting in the paper 'Tackling the Objective Inconsistency Problem in\n    Heterogeneous Federated Optimization' (http://arxiv.org/abs/2007.07481). The string `mode` should be like\n    'FEDNOVA-Uniform(a,b)' where `a` is the minimal value of the number of local_movielens_recommendation epochs and `b` is the maximal\n    value. If this mode is active, the `num_epochs` and `num_steps` of clients will be disable.\n    \"\"\"\n    a = min(a, 1)\n    b = max(b, a)\n    for cid in simulator.clients:\n        simulator.clients[cid].set_local_epochs(np.random.randint(low=a, high=b))\n    working_amounts = [simulator.clients[cid].num_steps for cid in simulator.all_clients]\n    simulator.set_variable(simulator.all_clients, 'working_amount', working_amounts)\n    return\n</code></pre>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.homogeneous_client_availability","title":"<code>homogeneous_client_availability(simulator, beta=0.2)</code>","text":"<p>All the clients share a homogeneous active rate <code>1-beta</code> where beta \u2208 [0,1)</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def homogeneous_client_availability(simulator, beta=0.2):\n\"\"\"\n    All the clients share a homogeneous active rate `1-beta` where beta \u2208 [0,1)\n    \"\"\"\n    # alpha = float(mode[mode.find('-') + 1:]) if mode.find('-') != -1 else 0.8\n    probs = [1.-beta for _ in simulator.clients]\n    simulator.set_variable(simulator.all_clients, 'prob_available', probs)\n    simulator.set_variable(simulator.all_clients, 'prob_unavailable', [1 - p for p in probs])\n    simulator.roundwise_fixed_availability = True\n</code></pre>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.less_data_first_client_availability","title":"<code>less_data_first_client_availability(simulator, beta=0.5)</code>","text":"<p>Clients with less data will have a larger active rate at each round.         ci=(1-beta)^(-|Di|), pi=ci/cmax, beta \u2208 [0,1)</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def less_data_first_client_availability(simulator, beta=0.5):\n\"\"\"\n    Clients with less data will have a larger active rate at each round.\n            ci=(1-beta)^(-|Di|), pi=ci/cmax, beta \u2208 [0,1)\n    \"\"\"\n    # alpha = float(mode[mode.find('-') + 1:]) if mode.find('-') != -1 else 0.1\n    prop = np.array([len(c.train_data) for c in simulator.server.clients])\n    prop = prop ** (-beta)\n    maxp = np.max(prop)\n    probs = prop/maxp\n    simulator.set_variable(simulator.all_clients, 'prob_available', probs)\n    simulator.set_variable(simulator.all_clients, 'prob_unavailable', [1 - p for p in probs])\n    simulator.roundwise_fixed_availability = True\n</code></pre>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.lognormal_client_availability","title":"<code>lognormal_client_availability(simulator, beta=0.1)</code>","text":"<p>The following two settings are from 'Federated Learning Under Intermittent Client Availability and Time-Varying Communication Constraints' (http://arxiv.org/abs/2205.06730).     ci ~ logmal(0, lognormal(0, -ln(1-beta)), pi=ci/cmax</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def lognormal_client_availability(simulator, beta=0.1):\n\"\"\"The following two settings are from 'Federated Learning Under Intermittent\n    Client Availability and Time-Varying Communication Constraints' (http://arxiv.org/abs/2205.06730).\n        ci ~ logmal(0, lognormal(0, -ln(1-beta)), pi=ci/cmax\n    \"\"\"\n    epsilon = 0.000001\n    Tks = [np.random.lognormal(0, -np.log(1 - beta - epsilon)) for _ in simulator.clients]\n    max_Tk = max(Tks)\n    probs = np.array(Tks)/max_Tk\n    simulator.set_variable(simulator.all_clients, 'prob_available', probs)\n    simulator.set_variable(simulator.all_clients, 'prob_unavailable', [1 - p for p in probs])\n    simulator.roundwise_fixed_availability = True\n</code></pre>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.more_data_first_client_availability","title":"<code>more_data_first_client_availability(simulator, beta=0.0001)</code>","text":"<p>Clients with more data will have a larger active rate at each round. e.g. ci=tanh(-|Di| ln(beta+epsilon)), pi=ci/cmax, beta \u2208 [0,1)</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def more_data_first_client_availability(simulator, beta=0.0001):\n\"\"\"\n    Clients with more data will have a larger active rate at each round.\n    e.g. ci=tanh(-|Di| ln(beta+epsilon)), pi=ci/cmax, beta \u2208 [0,1)\n    \"\"\"\n    p = np.array([len(c.train_data) for c in simulator.server.clients])\n    p = p ** beta\n    maxp = np.max(p)\n    probs = p/maxp\n    simulator.set_variable(simulator.all_clients, 'prob_available', probs)\n    simulator.set_variable(simulator.all_clients, 'prob_unavailable', [1 - p for p in probs])\n    simulator.roundwise_fixed_availability = True\n</code></pre>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.part_dynamic_uniform_client_completeness","title":"<code>part_dynamic_uniform_client_completeness(simulator, p=0.5)</code>","text":"<p>This setting follows the setting in the paper 'Federated Optimization in Heterogeneous Networks' (http://arxiv.org/abs/1812.06127). The <code>p</code> specifies the number of selected clients with incomplete updates.</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def part_dynamic_uniform_client_completeness(simulator, p=0.5):\n\"\"\"\n    This setting follows the setting in the paper 'Federated Optimization in Heterogeneous Networks'\n    (http://arxiv.org/abs/1812.06127). The `p` specifies the number of selected clients with\n    incomplete updates.\n    \"\"\"\n    simulator.prob_incomplete = p\n    def f(self, client_ids = []):\n        was = []\n        for cid in client_ids:\n            wa = self.random_module.randint(low=0, high=self.clients[cid].num_steps) if self.random_module.rand() &lt; self.prob_incomplete else self.clients[cid].num_steps\n            wa = max(1, wa)\n            was.append(wa)\n            self.clients[cid].num_steps = wa\n        self.set_variable(client_ids, 'working_amount', was)\n        return\n    return f\n</code></pre>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.sin_lognormal_client_availability","title":"<code>sin_lognormal_client_availability(simulator, beta=0.1)</code>","text":"<p>This setting shares the same active rate distribution with LogNormal, however, the active rates are also influenced by the time (i.e. communication round). The active rates obey a sin wave according to the time with period T.     ci ~ logmal(0, lognormal(0, -ln(1-beta)), pi=ci/cmax, p(i,t)=(0.4sin((1+R%T)/T*2pi)+0.5) * pi</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def sin_lognormal_client_availability(simulator, beta=0.1):\n\"\"\"This setting shares the same active rate distribution with LogNormal, however, the active rates are\n    also influenced by the time (i.e. communication round). The active rates obey a sin wave according to the\n    time with period T.\n        ci ~ logmal(0, lognormal(0, -ln(1-beta)), pi=ci/cmax, p(i,t)=(0.4sin((1+R%T)/T*2pi)+0.5) * pi\n    \"\"\"\n    # beta = float(mode[mode.find('-') + 1:]) if mode.find('-') != -1 else 0.1\n    epsilon = 0.000001\n    Tks = [np.random.lognormal(0, -np.log(1 - beta - epsilon)) for _ in simulator.clients]\n    max_Tk = max(Tks)\n    q = np.array(Tks)/max_Tk\n    simulator.set_variable(simulator.all_clients, 'q', q)\n    simulator.set_variable(simulator.all_clients, 'prob_available', q)\n    def f(self):\n        T = 24\n        times = np.linspace(start=0, stop=2 * np.pi, num=T)\n        fts = 0.4 * np.sin(times) + 0.5\n        t = self.server.current_round % T\n        q = self.get_variable(self.all_clients, 'q')\n        probs = [fts[t]*qi for qi in q]\n        self.set_variable(self.all_clients, 'prob_available', probs)\n        self.set_variable(self.all_clients, 'prob_unavailable', [1 - p for p in probs])\n    simulator.roundwise_fixed_availability = True\n    return f\n</code></pre>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.y_fewer_first_client_availability","title":"<code>y_fewer_first_client_availability(simulator, beta=0.2)</code>","text":"<p>Clients with fewer kinds of labels will owe a larger active rate.     ci = |set(Yi)|/|set(Y)|, pi = beta*ci + (1-beta)</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def y_fewer_first_client_availability(simulator, beta=0.2):\n\"\"\"\n    Clients with fewer kinds of labels will owe a larger active rate.\n        ci = |set(Yi)|/|set(Y)|, pi = beta*ci + (1-beta)\n    \"\"\"\n    label_num = len(set([int(simulator.server.test_data[di][-1]) for di in range(len(simulator.server.test_data))]))\n    probs = []\n    for c in simulator.server.clients:\n        train_set = set([int(c.train_data[di][-1]) for di in range(len(c.train_data))])\n        val_set = set([int(c.val_data[di][-1]) for di in range(len(c.val_data))])\n        label_set = train_set.union(val_set)\n        probs.append(beta * len(label_set) / label_num + (1 - beta))\n    simulator.set_variable(simulator.all_clients, 'prob_available', probs)\n    simulator.set_variable(simulator.all_clients, 'prob_unavailable', [1 - p for p in probs])\n    simulator.roundwise_fixed_availability = True\n</code></pre>"},{"location":"Docs/simulator/default_simulator/#flgo.simulator.default_simulator.y_max_first_client_availability","title":"<code>y_max_first_client_availability(simulator, beta=0.1)</code>","text":"<p>This setting follows the activity mode in 'Fast Federated Learning in the Presence of Arbitrary Device Unavailability' , where each client ci will be ready</p> for joining in a round with a static probability <p>pi = beta * min({label kept by ci}) / max({all labels}) + ( 1 - beta )</p> <p>and the participation of client is independent across rounds. The string mode should be like 'YMaxFirst-x' where x should be replaced by a float number.</p> Source code in <code>flgo\\simulator\\default_simulator.py</code> <pre><code>def y_max_first_client_availability(simulator, beta=0.1):\n\"\"\"\n    This setting follows the activity mode in 'Fast Federated Learning in the\n    Presence of Arbitrary Device Unavailability' , where each client ci will be ready\n    for joining in a round with a static probability:\n        pi = beta * min({label kept by ci}) / max({all labels}) + ( 1 - beta )\n    and the participation of client is independent across rounds. The string mode\n    should be like 'YMaxFirst-x' where x should be replaced by a float number.\n    \"\"\"\n    # alpha = float(mode[mode.find('-') + 1:]) if mode.find('-') != -1 else 0.1\n    def label_counter(dataset):\n        return collections.Counter([int(dataset[di][-1]) for di in range(len(dataset))])\n    label_num = len(label_counter(simulator.server.test_data))\n    probs = []\n    for c in simulator.get_clients():\n        c_counter = label_counter((c.train_data + c.val_data) if c.val_data is not None else c.train_data)\n        c_label = [lb for lb in c_counter.keys()]\n        probs.append((beta * min(c_label) / max(1, label_num - 1)) + (1 - beta))\n    simulator.set_variable(simulator.all_clients, 'prob_available', probs)\n    simulator.set_variable(simulator.all_clients, 'prob_unavailable', [1 - p for p in probs])\n    simulator.roundwise_fixed_availability = True\n    return\n</code></pre>"},{"location":"Docs/utils/fflow/","title":"flgo.utils.fflow","text":""},{"location":"Docs/utils/fflow/#flgo.utils.fflow.GlobalVariable","title":"<code>GlobalVariable</code>","text":"<p>This class is to create a shared space for sharing variables across different parties for each runner</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>class GlobalVariable:\n\"\"\"This class is to create a shared space for sharing variables across\n    different parties for each runner\"\"\"\n\n    def __init__(self):\n        self.logger = None\n        self.simulator = None\n        self.clock = None\n        self.dev_list = None\n        self.TaskCalculator = None\n        self.TaskPipe = None\n        self.crt_dev = 0\n\n    def apply_for_device(self):\nr\"\"\"\n        Apply for a new device from currently available ones (i.e. devices in self.dev_list)\n\n        Returns:\n            GPU device (i.e. torch.device)\n        \"\"\"\n        if self.dev_list is None: return None\n        dev = self.dev_list[self.crt_dev]\n        self.crt_dev = (self.crt_dev + 1) % len(self.dev_list)\n        return dev\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.GlobalVariable.apply_for_device","title":"<code>apply_for_device()</code>","text":"<p>Apply for a new device from currently available ones (i.e. devices in self.dev_list)</p> <p>Returns:</p> Type Description <p>GPU device (i.e. torch.device)</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def apply_for_device(self):\nr\"\"\"\n    Apply for a new device from currently available ones (i.e. devices in self.dev_list)\n\n    Returns:\n        GPU device (i.e. torch.device)\n    \"\"\"\n    if self.dev_list is None: return None\n    dev = self.dev_list[self.crt_dev]\n    self.crt_dev = (self.crt_dev + 1) % len(self.dev_list)\n    return dev\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.convert_model","title":"<code>convert_model(get_model, model_name='anonymous', scene='horizontal')</code>","text":"<p>Convert an existing model into a model that can be loaded in flgo.</p> <p>Parameters:</p> Name Type Description Default <code>get_model</code> <code>Callable</code> <p>this function will return a model of type torch.nn.Module when it is called</p> required <code>model_name</code> <code>str</code> <p>the name of the model</p> <code>'anonymous'</code> <code>scene</code> <code>str</code> <p>the FL scene</p> <code>'horizontal'</code> <p>Returns:</p> Name Type Description <code>res_model</code> <p>the model can be used in flgo.init(..., model=res_model, ...)</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def convert_model(get_model:Callable, model_name='anonymous', scene:str='horizontal'):\nr\"\"\"\n    Convert an existing model into a model that can be loaded in flgo.\n    Args:\n        get_model (Callable): this function will return a model of type torch.nn.Module when it is called\n        model_name (str): the name of the model\n        scene (str): the FL scene\n\n    Returns:\n        res_model: the model can be used in flgo.init(..., model=res_model, ...)\n    \"\"\"\n    class DecoratedModel(flgo.utils.fmodule.FModule):\n        def __init__(self):\n            super().__init__()\n            self.model = get_model()\n\n        def forward(self, *args, **kwargs):\n            return self.model(*args, **kwargs)\n\n    if scene=='horizontal':\n        class AnonymousModel:\n            __name__ = model_name\n\n            @classmethod\n            def init_global_module(self, object):\n                if 'Server' in object.__class__.__name__:\n                    object.model = DecoratedModel().to(object.device)\n\n            @classmethod\n            def init_local_module(self, object):\n                pass\n\n    elif scene=='decentralized':\n        class AnonymousModel:\n            __name__ = model_name\n\n            @classmethod\n            def init_local_module(self, object):\n                if 'Client' in object.__class__.__name__:\n                    object.model = DecoratedModel().to(object.device)\n\n            @classmethod\n            def init_global_module(self, object):\n                pass\n    else:\n        raise NotImplementedError('The current version only support converting model for horizontalFL and DecentralizedFL.')\n    return AnonymousModel()\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.gen_benchmark","title":"<code>gen_benchmark(benchmark, config_file, target_path='.', data_type='cv', task_type='classification')</code>","text":"<pre><code>Create customized benchmarks from configurations. The configuration is a .py file that describes the datasets and the model,\nwhere there must exist a function named `get_model` and a variable `train_data`. `val_data` and test_data are two optional\nvariables in the configuration.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>str</code> <p>the name of the benchmark</p> required <code>config_file</code> <code>str</code> <p>the path of the configuration file</p> required <code>target_path</code> <p>(str): the path to store the benchmark</p> <code>'.'</code> <code>data_type</code> <code>str</code> <p>the type of dataset that should be in the list ['cv', 'nlp', 'graph', 'rec', 'series', 'tabular']</p> <code>'cv'</code> <code>task_type</code> <code>str</code> <p>the type of the task (e.g. classification, regression...)</p> <code>'classification'</code> <p>Returns:</p> Name Type Description <code>bmk_module</code> <code>str</code> <p>the module name of the generated benchmark</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def gen_benchmark(benchmark:str, config_file:str, target_path='.',data_type:str='cv', task_type:str='classification'):\nr\"\"\"\n        Create customized benchmarks from configurations. The configuration is a .py file that describes the datasets and the model,\n        where there must exist a function named `get_model` and a variable `train_data`. `val_data` and test_data are two optional\n        variables in the configuration.\n    Args:\n        benchmark (str): the name of the benchmark\n        config_file (str): the path of the configuration file\n        target_path: (str): the path to store the benchmark\n        data_type (str): the type of dataset that should be in the list ['cv', 'nlp', 'graph', 'rec', 'series', 'tabular']\n        task_type (str): the type of the task (e.g. classification, regression...)\n    Returns:\n        bmk_module (str): the module name of the generated benchmark\n    \"\"\"\n    if not os.path.exists(config_file): raise FileNotFoundError('File {} not found.'.format(config_file))\n    target_path = os.path.abspath(target_path)\n    bmk_path = os.path.join(target_path, benchmark)\n    if os.path.exists(bmk_path): raise FileExistsError('Benchmark {} already exists'.format(bmk_path))\n    temp_path = os.path.join(flgo.benchmark.path, 'toolkits', data_type, task_type, 'temp')\n    if not os.path.exists(temp_path):\n        raise NotImplementedError('There is no support to automatically generation of {}.{}. More other types are comming soon...'.format(data_type, task_type))\n    else:\n        shutil.copytree(temp_path, bmk_path)\n    shutil.copyfile(config_file, os.path.join(bmk_path, 'config.py'))\n    bmk_module = '.'.join(os.path.relpath(bmk_path, os.getcwd()).split(os.path.sep))\n    return bmk_module\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.gen_benchmark_from_file","title":"<code>gen_benchmark_from_file(benchmark, config_file, target_path='.', data_type='cv', task_type='classification')</code>","text":"<pre><code>Create customized benchmarks from configurations. The configuration is a .py file that describes the datasets and the model,\nwhere there must exist a function named `get_model` and a variable `train_data`. `val_data` and test_data are two optional\nvariables in the configuration.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>str</code> <p>the name of the benchmark</p> required <code>config_file</code> <code>str</code> <p>the path of the configuration file</p> required <code>target_path</code> <p>(str): the path to store the benchmark</p> <code>'.'</code> <code>data_type</code> <code>str</code> <p>the type of dataset that should be in the list ['cv', 'nlp', 'graph', 'rec', 'series', 'tabular']</p> <code>'cv'</code> <code>task_type</code> <code>str</code> <p>the type of the task (e.g. classification, regression...)</p> <code>'classification'</code> <p>Returns:</p> Name Type Description <code>bmk_module</code> <code>str</code> <p>the module name of the generated benchmark</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def gen_benchmark_from_file(benchmark:str, config_file:str, target_path='.',data_type:str='cv', task_type:str='classification'):\nr\"\"\"\n        Create customized benchmarks from configurations. The configuration is a .py file that describes the datasets and the model,\n        where there must exist a function named `get_model` and a variable `train_data`. `val_data` and test_data are two optional\n        variables in the configuration.\n    Args:\n        benchmark (str): the name of the benchmark\n        config_file (str): the path of the configuration file\n        target_path: (str): the path to store the benchmark\n        data_type (str): the type of dataset that should be in the list ['cv', 'nlp', 'graph', 'rec', 'series', 'tabular']\n        task_type (str): the type of the task (e.g. classification, regression...)\n    Returns:\n        bmk_module (str): the module name of the generated benchmark\n    \"\"\"\n    if not os.path.exists(config_file): raise FileNotFoundError('File {} not found.'.format(config_file))\n    target_path = os.path.abspath(target_path)\n    bmk_path = os.path.join(target_path, benchmark)\n    if os.path.exists(bmk_path): raise FileExistsError('Benchmark {} already exists'.format(bmk_path))\n    temp_path = os.path.join(flgo.benchmark.path, 'toolkits', data_type, task_type, 'temp')\n    if not os.path.exists(temp_path):\n        raise NotImplementedError('There is no support to automatically generation of {}.{}. More other types are comming soon...'.format(data_type, task_type))\n    else:\n        shutil.copytree(temp_path, bmk_path)\n    shutil.copyfile(config_file, os.path.join(bmk_path, 'config.py'))\n    bmk_module = '.'.join(os.path.relpath(bmk_path, os.getcwd()).split(os.path.sep))\n    return bmk_module\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.gen_decentralized_benchmark","title":"<code>gen_decentralized_benchmark(benchmark, config_file, target_path='.', data_type='cv', task_type='classification')</code>","text":"<pre><code>Create customized benchmarks from configurations. The configuration is a .py file that describes the datasets and the model,\nwhere there must exist a function named `get_model` and a variable `train_data`. `val_data` and test_data are two optional\nvariables in the configuration.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>str</code> <p>the name of the benchmark</p> required <code>config_file</code> <code>str</code> <p>the path of the configuration file</p> required <code>target_path</code> <p>(str): the path to store the benchmark</p> <code>'.'</code> <code>data_type</code> <code>str</code> <p>the type of dataset that should be in the list ['cv', 'nlp', 'graph', 'rec', 'series', 'tabular']</p> <code>'cv'</code> <code>task_type</code> <code>str</code> <p>the type of the task (e.g. classification, regression...)</p> <code>'classification'</code> <p>Returns:</p> Name Type Description <code>bmk_module</code> <code>str</code> <p>the module name of the generated benchmark</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def gen_decentralized_benchmark(benchmark:str, config_file:str, target_path = '.', data_type:str='cv', task_type:str='classification'):\nr\"\"\"\n        Create customized benchmarks from configurations. The configuration is a .py file that describes the datasets and the model,\n        where there must exist a function named `get_model` and a variable `train_data`. `val_data` and test_data are two optional\n        variables in the configuration.\n    Args:\n        benchmark (str): the name of the benchmark\n        config_file (str): the path of the configuration file\n        target_path: (str): the path to store the benchmark\n        data_type (str): the type of dataset that should be in the list ['cv', 'nlp', 'graph', 'rec', 'series', 'tabular']\n        task_type (str): the type of the task (e.g. classification, regression...)\n    Returns:\n        bmk_module (str): the module name of the generated benchmark\n    \"\"\"\n    if not os.path.exists(config_file): raise FileNotFoundError('File {} not found.'.format(config_file))\n    target_path = os.path.abspath(target_path)\n    bmk_path = os.path.join(target_path, benchmark)\n    if os.path.exists(bmk_path): raise FileExistsError('Benchmark {} already exists'.format(bmk_path))\n    temp_path = os.path.join(flgo.benchmark.path, 'toolkits', data_type, task_type, 'dec_temp')\n    if not os.path.exists(temp_path):\n        raise NotImplementedError('There is no support to automatically generation of {}.{}. More other types are comming soon...'.format(data_type, task_type))\n    else:\n        shutil.copytree(temp_path, bmk_path)\n    shutil.copyfile(config_file, os.path.join(bmk_path, 'config.py'))\n    bmk_module = '.'.join(os.path.relpath(bmk_path, os.getcwd()).split(os.path.sep))\n    return bmk_module\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.gen_hierarchical_benchmark","title":"<code>gen_hierarchical_benchmark(benchmark, config_file, target_path='.', data_type='cv', task_type='classification')</code>","text":"<pre><code>Create customized benchmarks from configurations. The configuration is a .py file that describes the datasets and the model,\nwhere there must exist a function named `get_model` and a variable `train_data`. `val_data` and test_data are two optional\nvariables in the configuration.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>str</code> <p>the name of the benchmark</p> required <code>config_file</code> <code>str</code> <p>the path of the configuration file</p> required <code>target_path</code> <p>(str): the path to store the benchmark</p> <code>'.'</code> <code>data_type</code> <code>str</code> <p>the type of dataset that should be in the list ['cv', 'nlp', 'graph', 'rec', 'series', 'tabular']</p> <code>'cv'</code> <code>task_type</code> <code>str</code> <p>the type of the task (e.g. classification, regression...)</p> <code>'classification'</code> <p>Returns:</p> Name Type Description <code>bmk_module</code> <code>str</code> <p>the module name of the generated benchmark</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def gen_hierarchical_benchmark(benchmark:str, config_file:str, target_path = '.', data_type:str='cv', task_type:str='classification'):\nr\"\"\"\n        Create customized benchmarks from configurations. The configuration is a .py file that describes the datasets and the model,\n        where there must exist a function named `get_model` and a variable `train_data`. `val_data` and test_data are two optional\n        variables in the configuration.\n    Args:\n        benchmark (str): the name of the benchmark\n        config_file (str): the path of the configuration file\n        target_path: (str): the path to store the benchmark\n        data_type (str): the type of dataset that should be in the list ['cv', 'nlp', 'graph', 'rec', 'series', 'tabular']\n        task_type (str): the type of the task (e.g. classification, regression...)\n    Returns:\n        bmk_module (str): the module name of the generated benchmark\n    \"\"\"\n    if not os.path.exists(config_file): raise FileNotFoundError('File {} not found.'.format(config_file))\n    target_path = os.path.abspath(target_path)\n    bmk_path = os.path.join(target_path, benchmark)\n    if os.path.exists(bmk_path): raise FileExistsError('Benchmark {} already exists'.format(bmk_path))\n    temp_path = os.path.join(flgo.benchmark.path, 'toolkits', data_type, task_type, 'hier_temp')\n    if not os.path.exists(temp_path):\n        raise NotImplementedError('There is no support to automatically generation of {}.{}. More other types are comming soon...'.format(data_type, task_type))\n    else:\n        shutil.copytree(temp_path, bmk_path)\n    shutil.copyfile(config_file, os.path.join(bmk_path, 'config.py'))\n    bmk_module = '.'.join(os.path.relpath(bmk_path, os.getcwd()).split(os.path.sep))\n    return bmk_module\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.gen_task","title":"<code>gen_task(config={}, task_path='', rawdata_path='', seed=0)</code>","text":"<p>Generate a federated task that is specified by the benchmark information and the partition information, where the generated task will be stored in the task_path and the raw data will be downloaded into the rawdata_path.</p> <pre><code>config (dict || str): configuration is either a dict contains parameters or a filename of a .yml file\ntask_path (str): where the generated task will be stored\nrawdata_path (str): where the raw data will be downloaded\\stored\nseed (int): the random seed used to generate the task\n</code></pre> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo\n    &gt;&gt;&gt; config = {'benchmark':{'name':'flgo.benchmark.mnist_classification'}, 'partitioner':{'name':'IIDParitioner', 'para':{'num_clients':100}}}\n    &gt;&gt;&gt; flgo.gen_task(config, './my_mnist_iid')\n    &gt;&gt;&gt; # The task will be stored as `my_mnist_iid` in the current working dictionary\n</code></pre> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def gen_task(config={}, task_path:str= '', rawdata_path:str= '', seed:int=0):\nr\"\"\"\n    Generate a federated task that is specified by the benchmark information and the partition information, where the generated task will be stored in the task_path and the raw data will be downloaded into the rawdata_path.\n\n        config (dict || str): configuration is either a dict contains parameters or a filename of a .yml file\n        task_path (str): where the generated task will be stored\n        rawdata_path (str): where the raw data will be downloaded\\stored\n        seed (int): the random seed used to generate the task\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo\n        &gt;&gt;&gt; config = {'benchmark':{'name':'flgo.benchmark.mnist_classification'}, 'partitioner':{'name':'IIDParitioner', 'para':{'num_clients':100}}}\n        &gt;&gt;&gt; flgo.gen_task(config, './my_mnist_iid')\n        &gt;&gt;&gt; # The task will be stored as `my_mnist_iid` in the current working dictionary\n    ```\n    \"\"\"\n    # setup random seed\n    random.seed(3 + seed)\n    np.random.seed(97 + seed)\n    torch.manual_seed(12+seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    # load configuration\n    gen_option = load_configuration(config)\n    if type(gen_option['benchmark']) is not dict: gen_option['benchmark']={'name':gen_option['benchmark']}\n    if 'para' not in gen_option['benchmark'].keys(): gen_option['benchmark']['para'] = {}\n    if 'partitioner' in gen_option.keys():\n        if not isinstance(gen_option['partitioner'], dict):\n            gen_option['partitioner'] = {'name': gen_option['partitioner'], 'para':{}}\n        # update parameters of partitioner\n        if 'para' not in gen_option['partitioner'].keys():\n            gen_option['partitioner']['para'] = {}\n        else:\n            if 'name' not in gen_option['partitioner'].keys():\n                gen_option['benchmark']['para'].update(gen_option['partitioner']['para'])\n    # init generator\n    if rawdata_path!='': gen_option['benchmark']['para']['rawdata_path']=rawdata_path\n    if type(gen_option['benchmark']['name']) is str:\n        bmk_core = importlib.import_module('.'.join([gen_option['benchmark']['name'], 'core']))\n    elif hasattr(gen_option['benchmark']['name'], '__path__'):\n        bmk_core = importlib.import_module('.core', gen_option['benchmark']['name'].__name__)\n    else:\n        raise RuntimeError(\"The value of parameter config['benchmark']['name'] should be either a string or a python package.\")\n    task_generator = getattr(bmk_core, 'TaskGenerator')(**gen_option['benchmark']['para'])\n    bmk_module = importlib.import_module(gen_option['benchmark']['name']) if type(\n        gen_option['benchmark']['name']) is str else gen_option['benchmark']['name']\n    # create partitioner for generator if specified\n    if 'partitioner' in gen_option.keys() and 'name' in gen_option['partitioner'].keys():\n        Partitioner = gen_option['partitioner']['name']\n        if type(Partitioner) is str:\n            if Partitioner in globals().keys(): Partitioner = eval(Partitioner)\n            else: Partitioner = getattr(flgo.benchmark.partition, Partitioner)\n        partitioner = Partitioner(**gen_option['partitioner']['para'])\n        task_generator.register_partitioner(partitioner)\n        partitioner.register_generator(task_generator)\n    else:\n        try:\n            if hasattr(bmk_module, 'default_partitioner'):\n                Partitioner = getattr(bmk_module, 'default_partitioner')\n                default_partition_para = getattr(bmk_module, 'default_partition_para') if hasattr(bmk_module, 'default_partition_para') else {}\n                partitioner = Partitioner(**default_partition_para)\n                task_generator.register_partitioner(partitioner)\n                partitioner.register_generator(task_generator)\n            else:\n                partitioner = None\n        except:\n            partitioner = None\n    # generate federated task\n    task_generator.generate()\n    # save the generated federated benchmark\n    # initialize task pipe\n    if task_path=='': task_path = os.path.join('.', task_generator.task_name)\n    task_pipe = getattr(bmk_core, 'TaskPipe')(task_path)\n    # check if task already exists\n    if task_pipe.task_exists():\n        raise FileExistsError('Task {} already exists.'.format(task_path))\n    try:\n        # create task architecture\n        task_pipe.create_task_architecture()\n        # save meta infomation\n        task_pipe.save_info(task_generator)\n        # save task\n        task_pipe.save_task(task_generator)\n        print('Task {} has been successfully generated.'.format(task_pipe.task_path))\n    except Exception as e:\n        print(e)\n        task_pipe.remove_task()\n        print(\"Failed to saving splited dataset.\")\n    # save visualization\n    if hasattr(bmk_module, 'visualize'):\n        try:\n            visualize_func = getattr(bmk_module,'visualize')\n            visualize_func(task_generator, partitioner, task_path)\n        except Exception as e:\n            print('Warning: Failed to visualize the partitioned result where there exists error {}'.format(e))\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.gen_task_from_para","title":"<code>gen_task_from_para(benchmark, bmk_para={}, Partitioner=None, par_para={}, task_path='', rawdata_path='', seed=0)</code>","text":"<p>Generate a federated task according to the parameters of this function. The formats and meanings of the inputs are listed as below:</p> <p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>package | str</code> <p>the benchmark package or the module path of it</p> required <code>bmk_para</code> <code>dict</code> <p>the customized parameter dict of the method TaskGenerator.init() of the benchmark</p> <code>{}</code> <code>Partitioner</code> <code>flgo.benchmark.toolkits.partition.BasicPartitioner | str</code> <p>the class of the Partitioner or the name of the Partitioner that was realized in flgo.benchmark.toolkits.partition</p> <code>None</code> <code>par_para</code> <code>dict</code> <p>the customized parameter dict of the method Partitioner.init()</p> <code>{}</code> <code>task_path</code> <code>str</code> <p>the path to store the generated task</p> <code>''</code> <code>rawdata_path</code> <code>str</code> <p>where the raw data will be downloaded\\stored</p> <code>''</code> <code>seed</code> <code>int</code> <p>the random seed used to generate the task</p> <code>0</code> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo\n    &gt;&gt;&gt; import flgo.benchmark.mnist_classification as mnist\n    &gt;&gt;&gt; from flgo.benchmark.toolkits.partition import IIDPartitioner\n    &gt;&gt;&gt; # GENERATE TASK BY PASSING THE MODULE OF BENCHMARK AND THE CLASS OF THE PARTITIOENR\n    &gt;&gt;&gt; flgo.gen_task_from_para(benchmark=mnist, Partitioner = IIDPartitioner, par_para={'num_clients':100}, task_path='./mnist_gen_by_para1')\n    &gt;&gt;&gt; # GENERATE THE SAME TASK BY PASSING THE STRING\n    &gt;&gt;&gt; flgo.gen_task_from_para(benchmark='flgo.benchmark.mnist_classification', Partitioner='IIDPartitioner', par_para={'num_clients':100}, task_path='./mnist_gen_by_para2')\n</code></pre> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def gen_task_from_para(benchmark, bmk_para:dict={}, Partitioner=None, par_para:dict={}, task_path: str= '', rawdata_path:str= '', seed:int=0):\nr\"\"\"\n    Generate a federated task according to the parameters of this function. The formats and meanings of the inputs are listed as below:\n\n    Args:\n        benchmark (package|str): the benchmark package or the module path of it\n        bmk_para (dict): the customized parameter dict of the method TaskGenerator.__init__() of the benchmark\n        Partitioner (flgo.benchmark.toolkits.partition.BasicPartitioner|str): the class of the Partitioner or the name of the Partitioner that was realized in flgo.benchmark.toolkits.partition\n        par_para (dict): the customized parameter dict of the method Partitioner.__init__()\n        task_path (str): the path to store the generated task\n        rawdata_path (str): where the raw data will be downloaded\\stored\n        seed (int): the random seed used to generate the task\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo\n        &gt;&gt;&gt; import flgo.benchmark.mnist_classification as mnist\n        &gt;&gt;&gt; from flgo.benchmark.toolkits.partition import IIDPartitioner\n        &gt;&gt;&gt; # GENERATE TASK BY PASSING THE MODULE OF BENCHMARK AND THE CLASS OF THE PARTITIOENR\n        &gt;&gt;&gt; flgo.gen_task_from_para(benchmark=mnist, Partitioner = IIDPartitioner, par_para={'num_clients':100}, task_path='./mnist_gen_by_para1')\n        &gt;&gt;&gt; # GENERATE THE SAME TASK BY PASSING THE STRING\n        &gt;&gt;&gt; flgo.gen_task_from_para(benchmark='flgo.benchmark.mnist_classification', Partitioner='IIDPartitioner', par_para={'num_clients':100}, task_path='./mnist_gen_by_para2')\n    ```\n    \"\"\"\n    random.seed(3 + seed)\n    np.random.seed(97 + seed)\n    torch.manual_seed(12+seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    if type(benchmark) is str: benchmark = importlib.import_module(benchmark)\n    if not hasattr(benchmark, '__path__'): raise RuntimeError(\"benchmark should be a package or the path of a package\")\n    if Partitioner is not None:\n        if type(Partitioner) is str:\n            if Partitioner in globals().keys(): Partitioner = eval(Partitioner)\n            else: Partitioner = getattr(flgo.benchmark.toolkits.partition, Partitioner)\n        partitioner = Partitioner(**par_para)\n    else:\n        try:\n            if hasattr(benchmark, 'default_partitioner'):\n                Partitioner = getattr(benchmark, 'default_partitioner')\n                default_partition_para = getattr(benchmark, 'default_partition_para') if hasattr(benchmark, 'default_partition_para') else {}\n                partitioner = Partitioner(**default_partition_para)\n            else:\n                partitioner = None\n        except:\n            partitioner = None\n    if rawdata_path!='': bmk_para['rawdata_path']=rawdata_path\n    bmk_core = benchmark.core\n    task_generator = getattr(bmk_core, 'TaskGenerator')(**bmk_para)\n    if partitioner is not None:\n        task_generator.register_partitioner(partitioner)\n        partitioner.register_generator(task_generator)\n    task_generator.generate()\n    # save the generated federated benchmark\n    # initialize task pipe\n    if task_path=='': task_path = os.path.join('.', task_generator.task_name)\n    task_pipe = getattr(bmk_core, 'TaskPipe')(task_path)\n    # check if task already exists\n    if task_pipe.task_exists():\n        raise FileExistsError('Task {} already exists.'.format(task_path))\n    try:\n        # create task architecture\n        task_pipe.create_task_architecture()\n        # save meta infomation\n        task_pipe.save_info(task_generator)\n        # save task\n        task_pipe.save_task(task_generator)\n        print('Task {} has been successfully generated.'.format(task_pipe.task_path))\n    except Exception as e:\n        print(e)\n        task_pipe.remove_task()\n        print(\"Failed to saving splited dataset.\")\n    # save visualization\n    try:\n        visualize_func = getattr(benchmark,'visualize')\n        visualize_func(task_generator, partitioner, task_path)\n    except:\n        pass\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.init","title":"<code>init(task, algorithm, option={}, model=None, Logger=None, Simulator=flgo.simulator.DefaultSimulator, scene='horizontal')</code>","text":"<p>Initialize a runner in FLGo, which is to optimize a model on a specific task (i.e. IID-mnist-of-100-clients) by the selected federated algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>str</code> <p>the dictionary of the federated task</p> required <code>algorithm</code> <code>module|class</code> <p>the algorithm will be used to optimize the model in federated manner, which must contain pre-defined attributions (e.g. algorithm.Server and algorithm.Client for horizontal federated learning)</p> required <code>option</code> <code>dict | str</code> <p>the configurations of training, environment, algorithm, logger and simulator</p> <code>{}</code> <code>model</code> <code>module|class</code> <p>the model module that contains two methods: model.init_local_module(object) and model.init_global_module(object)</p> <code>None</code> <code>Logger</code> <code>flgo.experiment.logger.BasicLogger</code> <p>the class of the logger inherited from flgo.experiment.logger.BasicLogger</p> <code>None</code> <code>Simulator</code> <code>flgo.simulator.base.BasicSimulator</code> <p>the class of the simulator inherited from flgo.simulator.BasicSimulator</p> <code>flgo.simulator.DefaultSimulator</code> <code>scene</code> <code>str</code> <p>'horizontal' or 'vertical' in current version of FLGo</p> <code>'horizontal'</code> <p>Returns:</p> Name Type Description <code>runner</code> <p>the object instance that has the method runner.run()</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; import flgo\n    &gt;&gt;&gt; from flgo.algorithm import fedavg\n    &gt;&gt;&gt; from flgo.experiment.logger.simple_logger import SimpleLogger\n    &gt;&gt;&gt; # create task 'mnist_iid' by flgo.gen_task('gen_config.yml', 'mnist_iid') if there exists no such task\n    &gt;&gt;&gt; if os.path.exists('mnist_iid'): flgo.gen_task({'benchmark':{'name':'flgo.benchmark.mnist_classification'}, 'partitioner':{'name':'IIDPartitioner','para':{'num_clients':100}}}, 'mnist_iid')\n    &gt;&gt;&gt; # create runner\n    &gt;&gt;&gt; fedavg_runner = flgo.init('mnist_iid', algorithm=fedavg, option = {'num_rounds':20, 'gpu':[0], 'learning_rate':0.1})\n    &gt;&gt;&gt; fedavg_runner.run()\n    ... # the training will start after runner.run() was called, and the running-time results will be recorded by Logger into the task dictionary\n</code></pre> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def init(task: str, algorithm, option = {}, model=None, Logger: flgo.experiment.logger.BasicLogger = None, Simulator: BasicSimulator=flgo.simulator.DefaultSimulator, scene='horizontal'):\nr\"\"\"\n    Initialize a runner in FLGo, which is to optimize a model on a specific task (i.e. IID-mnist-of-100-clients) by the selected federated algorithm.\n\n    Args:\n        task (str): the dictionary of the federated task\n        algorithm (module|class): the algorithm will be used to optimize the model in federated manner, which must contain pre-defined attributions (e.g. algorithm.Server and algorithm.Client for horizontal federated learning)\n        option (dict|str): the configurations of training, environment, algorithm, logger and simulator\n        model (module|class): the model module that contains two methods: model.init_local_module(object) and model.init_global_module(object)\n        Logger (flgo.experiment.logger.BasicLogger): the class of the logger inherited from flgo.experiment.logger.BasicLogger\n        Simulator (flgo.simulator.base.BasicSimulator): the class of the simulator inherited from flgo.simulator.BasicSimulator\n        scene (str): 'horizontal' or 'vertical' in current version of FLGo\n\n    Returns:\n        runner: the object instance that has the method runner.run()\n\n    Example:\n    ```python\n        &gt;&gt;&gt; import flgo\n        &gt;&gt;&gt; from flgo.algorithm import fedavg\n        &gt;&gt;&gt; from flgo.experiment.logger.simple_logger import SimpleLogger\n        &gt;&gt;&gt; # create task 'mnist_iid' by flgo.gen_task('gen_config.yml', 'mnist_iid') if there exists no such task\n        &gt;&gt;&gt; if os.path.exists('mnist_iid'): flgo.gen_task({'benchmark':{'name':'flgo.benchmark.mnist_classification'}, 'partitioner':{'name':'IIDPartitioner','para':{'num_clients':100}}}, 'mnist_iid')\n        &gt;&gt;&gt; # create runner\n        &gt;&gt;&gt; fedavg_runner = flgo.init('mnist_iid', algorithm=fedavg, option = {'num_rounds':20, 'gpu':[0], 'learning_rate':0.1})\n        &gt;&gt;&gt; fedavg_runner.run()\n        ... # the training will start after runner.run() was called, and the running-time results will be recorded by Logger into the task dictionary\n    ```\n    \"\"\"\n\n    # init option\n    option = load_configuration(option)\n    default_option = read_option_from_command()\n    for op_key in option:\n        if op_key in default_option.keys():\n            op_type = type(default_option[op_key])\n            if op_type == type(option[op_key]):\n                default_option[op_key] = option[op_key]\n            else:\n                if op_type is list:\n                    default_option[op_key]=list(option[op_key]) if hasattr(option[op_key], '__iter__') else [option[op_key]]\n                elif op_type is tuple:\n                    default_option[op_key] = tuple(option[op_key]) if hasattr(option[op_key], '__iter__') else (option[op_key])\n                else:\n                    default_option[op_key] = op_type(option[op_key])\n        else:\n            default_option[op_key] = option[op_key]\n    option = default_option\n    setup_seed(seed=option['seed'])\n    option['task'] = task\n    option['algorithm'] = (algorithm.__name__).split('.')[-1]\n    # option['server_with_cpu'] = True if (option['num_parallels']&gt;1 and len(option['gpu'])&gt;1) else option['server_with_cpu']\n    # init task info\n    if not os.path.exists(task):\n        raise FileExistsError(\"Fedtask '{}' doesn't exist. Please generate the specified task by flgo.gen_task().\")\n    with open(os.path.join(task, 'info'), 'r') as inf:\n        task_info = json.load(inf)\n    benchmark = task_info['benchmark']\n    if model== None:\n        bmk_module = importlib.import_module(benchmark)\n        if hasattr(bmk_module, 'default_model'):\n            model = getattr(bmk_module, 'default_model')\n        else:\n            model = algorithm\n    option['model'] = (model.__name__).split('.')[-1]\n    # create global variable\n    gv = GlobalVariable()\n    # init logger\n    if Logger is None:\n        if scene=='horizontal':\n            Logger = flgo.experiment.logger.simple_logger.SimpleLogger\n        elif scene=='vertical':\n            Logger = flgo.experiment.logger.vertical_logger.VerticalLogger\n        elif scene=='decentralized':\n            Logger = flgo.experiment.logger.dec_logger.DecLogger\n        elif scene=='hierarchical':\n            Logger = flgo.experiment.logger.hier_logger.HierLogger\n    gv.logger = Logger(task=task, option=option, name=str(id(gv))+str(Logger), level=option['log_level'])\n    # init device\n    gv.dev_list = [torch.device('cpu')] if (option['gpu'] is None or len(option['gpu'])==0) else [torch.device('cuda:{}'.format(gpu_id)) for gpu_id in option['gpu']]\n    gv.logger.info('Initializing devices: '+','.join([str(dev) for dev in gv.dev_list])+' will be used for this running.')\n    # init task\n    gv.logger.info('BENCHMARK:\\t{}'.format(benchmark))\n    gv.logger.info('TASK:\\t\\t\\t{}'.format(task))\n    gv.logger.info('MODEL:\\t\\t{}'.format(model.__name__))\n    gv.logger.info('ALGORITHM:\\t{}'.format(option['algorithm']))\n    core_module = '.'.join([benchmark, 'core'])\n    gv.TaskPipe = getattr(importlib.import_module(core_module), 'TaskPipe')\n    task_pipe = gv.TaskPipe(task)\n    gv.TaskCalculator = getattr(importlib.import_module(core_module), 'TaskCalculator')\n    task_data = task_pipe.load_data(option)\n\n    # init objects\n    obj_class = [c for c in dir(algorithm) if not c.startswith('__')]\n    tmp = []\n    for c in obj_class:\n        try:\n            C = getattr(algorithm, c)\n            setattr(C, 'gv', gv)\n            tmp.append(c)\n        except:\n            continue\n    # init simulator\n    if scene=='horizontal':\n        for c in obj_class:\n            if 'Client' in c:\n                class_client = getattr(algorithm, c)\n                class_client.train = flgo.simulator.base.with_completeness(class_client.train)\n            elif 'Server' in c:\n                class_server = getattr(algorithm, c)\n                class_server.sample = flgo.simulator.base.with_availability(class_server.sample)\n                class_server.communicate_with = flgo.simulator.base.with_latency(class_server.communicate_with)\n                class_server.communicate = flgo.simulator.base.with_dropout(class_server.communicate)\n    objects = task_pipe.generate_objects(option, algorithm, scene=scene)\n    obj_classes = collections.defaultdict(int)\n    for obj in objects: obj_classes[obj.__class__]+=1\n    creating_str = []\n    for k,v in obj_classes.items(): creating_str.append(\"{} {}\".format(v, k))\n    creating_str = ', '.join(creating_str)\n    gv.logger.info('SCENE:\\t\\t{} FL with '.format(scene)+creating_str)\n    task_pipe.distribute(task_data, objects)\n\n    # init model\n    if hasattr(model, 'init_local_module'):\n        for object in objects:\n            model.init_local_module(object)\n    if hasattr(model, 'init_global_module'):\n        for object in objects:\n            model.init_global_module(object)\n    if hasattr(model, 'init_dataset'):\n        for object in objects:\n            model.init_dataset(object)\n\n    # init communicator\n    gv.communicator = flgo.VirtualCommunicator(objects)\n\n    for ob in objects: ob.initialize()\n\n    # init virtual system environment\n    gv.logger.info('SIMULATOR:\\t{}'.format(str(Simulator)))\n    # flgo.simulator.base.random_seed_gen = flgo.simulator.base.seed_generator(option['seed'])\n\n    gv.clock = flgo.simulator.base.ElemClock()\n    gv.simulator = Simulator(objects, option) if scene == 'horizontal' else None\n    if gv.simulator is not None: gv.simulator.initialize()\n    gv.clock.register_simulator(simulator=gv.simulator)\n    gv.logger.register_variable(coordinator=objects[0], participants=objects[1:], option=option, clock=gv.clock, scene=scene, objects = objects, simulator=Simulator.__name__ if scene == 'horizontal' else 'None')\n    if scene=='horizontal':\n        gv.logger.register_variable(server=objects[0], clients=objects[1:])\n    gv.logger.initialize()\n    gv.logger.info('Ready to start.')\n\n    # register global variables for objects\n    for c in tmp:\n        try:\n            C = getattr(algorithm, c)\n            delattr(C, 'gv')\n        except:\n            continue\n    for ob in objects:\n        ob.gv = gv\n    if gv.simulator is not None:\n        gv.simulator.gv = gv\n    gv.clock.gv = gv\n    gv.logger.gv = gv\n    return objects[0]\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.load_configuration","title":"<code>load_configuration(config={})</code>","text":"<p>Load configurations from .yml file or dict.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict | str</code> <p>the configurations</p> <code>{}</code> <p>Returns:</p> Type Description <p>a dict of option (i.e. configuration)</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def load_configuration(config={}):\nr\"\"\"\n    Load configurations from .yml file or dict.\n\n    Args:\n        config (dict|str): the configurations\n\n    Returns:\n        a dict of option (i.e. configuration)\n    \"\"\"\n    if type(config) is str and config.endswith('.yml'):\n        with open(config) as f:\n            option = yaml.load(f, Loader=yaml.FullLoader)\n        return option\n    elif type(config) is dict:\n        return config\n    else:\n        raise TypeError('The input config should be either a dict or a filename.')\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.module2fmodule","title":"<code>module2fmodule(Model)</code>","text":"<p>Convert a class of torch.nn.Module into class flgo.utils.fmodule.FModule</p> <p>Parameters:</p> Name Type Description Default <code>Model</code> <code>class</code> <p>a class inherited from torch.nn.Module</p> required <p>Returns:</p> Name Type Description <code>TempModule</code> <code>class</code> <p>The same class but additionally inheriting from flgo.utils.fmodule.FModule</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def module2fmodule(Model):\n\"\"\"\n    Convert a class of torch.nn.Module into class flgo.utils.fmodule.FModule\n    Args:\n        Model (class): a class inherited from torch.nn.Module\n\n    Returns:\n        TempModule (class): The same class but additionally inheriting from flgo.utils.fmodule.FModule\n\n    \"\"\"\n    class TempFModule(Model, flgo.utils.fmodule.FModule):\n        def __init__(self, *args, **kwargs):\n            super(TempFModule, self).__init__(*args, **kwargs)\n    return TempFModule\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.multi_init_and_run","title":"<code>multi_init_and_run(runner_args, devices=[], scheduler=None)</code>","text":"<p>Create multiple runners and run in parallel</p> <p>Parameters:</p> Name Type Description Default <code>runner_args</code> <code>list</code> <p>each element in runner_args should be either a dict or a tuple or parameters</p> required <code>devices</code> <code>list</code> <p>a list of gpu id</p> <code>[]</code> <code>scheduler</code> <code>flgo.experiment.device_scheduler.BasicScheduler(...</code> <p>GPU scheduler</p> <code>None</code> <p>Returns:</p> Type Description <p>a list of output results of runners</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; from flgo.algorithm import fedavg, fedprox, scaffold\n    &gt;&gt;&gt; # create task 'mnist_iid' by flgo.gen_task if there exists no such task\n    &gt;&gt;&gt; task='./mnist_iid'\n    &gt;&gt;&gt; if os.path.exists(task): flgo.gen_task({'benchmark':{'name':'flgo.benchmark.mnist_classification'}, 'partitioner':{'name':'IIDPartitioner','para':{'num_clients':100}}}, task)\n    &gt;&gt;&gt; algos = [fedavg, fedprox, scaffold]\n    &gt;&gt;&gt; flgo.multi_init_and_run([{'task':task, 'algorithm':algo} for algo in algos], devices=[0])\n</code></pre> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def multi_init_and_run(runner_args:list, devices = [], scheduler=None):\nr\"\"\"\n    Create multiple runners and run in parallel\n\n    Args:\n        runner_args (list): each element in runner_args should be either a dict or a tuple or parameters\n        devices (list): a list of gpu id\n        scheduler (flgo.experiment.device_scheduler.BasicScheduler(...)): GPU scheduler\n\n    Returns:\n        a list of output results of runners\n\n    Example:\n    ```python\n        &gt;&gt;&gt; from flgo.algorithm import fedavg, fedprox, scaffold\n        &gt;&gt;&gt; # create task 'mnist_iid' by flgo.gen_task if there exists no such task\n        &gt;&gt;&gt; task='./mnist_iid'\n        &gt;&gt;&gt; if os.path.exists(task): flgo.gen_task({'benchmark':{'name':'flgo.benchmark.mnist_classification'}, 'partitioner':{'name':'IIDPartitioner','para':{'num_clients':100}}}, task)\n        &gt;&gt;&gt; algos = [fedavg, fedprox, scaffold]\n        &gt;&gt;&gt; flgo.multi_init_and_run([{'task':task, 'algorithm':algo} for algo in algos], devices=[0])\n    ```\n    \"\"\"\n    if len(runner_args)==0:return\n    args = []\n    if type(runner_args[0]) is dict:\n        keys = ['task', 'algorithm', 'option', 'model', 'Logger', 'Simulator', 'scene']\n        for a in runner_args:\n            tmp = collections.defaultdict(lambda:None, a)\n            if tmp['task'] is None or tmp['algorithm'] is None:\n                raise RuntimeError(\"keyword 'task' or 'algorithm' is of NoneType\")\n            algorithm = tmp['algorithm']\n            tmp['algorithm'] = algorithm.__name__ if (not hasattr(algorithm, '__module__') and hasattr(algorithm, '__name__')) else algorithm\n            if tmp['option'] is None:\n                tmp['option'] = default_option_dict\n            else:\n                option = tmp['option']\n                default_option = read_option_from_command()\n                for op_key in option:\n                    if op_key in default_option.keys():\n                        op_type = type(default_option[op_key])\n                        if op_type == type(option[op_key]):\n                            default_option[op_key] = option[op_key]\n                        else:\n                            if op_type is list:\n                                default_option[op_key] = list(option[op_key]) if hasattr(option[op_key],\n                                                                                         '__iter__') else [\n                                    option[op_key]]\n                            elif op_type is tuple:\n                                default_option[op_key] = tuple(option[op_key]) if hasattr(option[op_key],\n                                                                                          '__iter__') else (\n                                option[op_key])\n                            else:\n                                default_option[op_key] = op_type(option[op_key])\n                tmp['option'] = default_option\n            if tmp['model'] is None:\n                model_name = None\n            else:\n                if not hasattr(tmp['model'], '__module__') and hasattr(tmp['model'], '__name__'):\n                    model_name = tmp['model'].__name__\n                else:\n                    model_name = tmp['model']\n            tmp['model'] = model_name\n            if tmp['Logger'] is None:\n                tmp['Logger'] = flgo.experiment.logger.simple_logger.SimpleLogger\n            algorithm_name = tmp['algorithm'].__name__ if (not hasattr(tmp['algorithm'], '__module__') and hasattr(tmp['algorithm'], '__name__')) else tmp['algorithm']\n            if tmp['Simulator'] is None:\n                tmp['Simulator'] = flgo.simulator.DefaultSimulator\n            if tmp['scene'] is None:\n                tmp['scene'] = 'horizontal'\n            args.append([tmp[k] for k in keys])\n    elif type(runner_args[0]) is tuple or type(runner_args[0]) is list:\n        for a in runner_args:\n            if len(a)&lt;2: raise RuntimeError('the args of runner should at least contain task and algorithm.')\n            default_args = [None, None, default_option_dict, None, flgo.experiment.logger.simple_logger.SimpleLogger, flgo.simulator.DefaultSimulator, 'horizontal']\n            for aid in range(len(a)):\n                if aid==0:\n                    default_args[aid] = a[aid]\n                if aid==1:\n                    algorithm = a[aid]\n                    algorithm_name = algorithm.__name__ if (not hasattr(algorithm, '__module__') and hasattr(algorithm, '__name__')) else algorithm\n                    default_args[aid] = algorithm_name\n                elif aid==2:\n                    option = a[aid]\n                    default_option = read_option_from_command()\n                    for op_key in option:\n                        if op_key in default_option.keys():\n                            op_type = type(default_option[op_key])\n                            if op_type == type(option[op_key]):\n                                default_option[op_key] = option[op_key]\n                            else:\n                                if op_type is list:\n                                    default_option[op_key] = list(option[op_key]) if hasattr(option[op_key],\n                                                                                             '__iter__') else [\n                                        option[op_key]]\n                                elif op_type is tuple:\n                                    default_option[op_key] = tuple(option[op_key]) if hasattr(option[op_key],\n                                                                                              '__iter__') else (\n                                        option[op_key])\n                                else:\n                                    default_option[op_key] = op_type(option[op_key])\n                    default_args[aid] = default_option\n                elif aid==3:\n                    model = a[aid]\n                    if model is None:\n                        model_name = None\n                    else:\n                        if not hasattr(model, '__module__') and hasattr(model, '__name__'):\n                            model_name = model.__name__\n                        else:\n                            model_name = model\n                    default_args[aid] = model_name\n                else:\n                    default_args[aid] = a[aid]\n\n    runner_state = {rid: {'p': None, 'completed': False, 'output': None, 'runner_in_queue': False, 'recv': None, } for\n                    rid in range(len(args))}\n    if scheduler is None: scheduler = flgo.experiment.device_scheduler.BasicScheduler(devices)\n    while True:\n        for rid in range(len(args)):\n            current_arg = args[rid]\n            if runner_state[rid]['p'] is None:\n                if not runner_state[rid]['completed']:\n                    available_device = scheduler.get_available_device(current_arg)\n                    if available_device is None:\n                        continue\n                    else:\n                        list_current_arg = copy.deepcopy(current_arg)\n                        list_current_arg[2]['gpu'] = available_device\n                        recv_end, send_end = multiprocessing.Pipe(False)\n                        list_current_arg.append(send_end)\n                        runner_state[rid]['p'] = multiprocessing.Process(target=_call_by_process, args=tuple(list_current_arg))\n                        runner_state[rid]['recv'] = recv_end\n                        runner_state[rid]['p'].start()\n                        scheduler.add_process(runner_state[rid]['p'].pid)\n                        print('Process {} was created for args {}'.format(runner_state[rid]['p'].pid,current_arg))\n            else:\n                if runner_state[rid]['p'].exitcode is not None:\n                    tmp = runner_state[rid]['recv'].recv()\n                    scheduler.remove_process(tmp[-1])\n                    try:\n                        runner_state[rid]['p'].terminate()\n                    except:\n                        pass\n                    runner_state[rid]['p'] = None\n                    if len(tmp) == 2:\n                        runner_state[rid]['completed'] = True\n                        runner_state[rid]['output'] = tmp[0]\n                    else:\n                        print(tmp[1])\n        if all([v['completed'] for v in runner_state.values()]): break\n        time.sleep(1)\n    res = []\n    for rid in range(len(runner_state)):\n        rec_path = runner_state[rid]['output']\n        with open(rec_path, 'r') as inf:\n            s_inf = inf.read()\n            rec = json.loads(s_inf)\n        res.append(rec)\n    return res\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.read_option_from_command","title":"<code>read_option_from_command()</code>","text":"<p>Generate running-time configurations for flgo.init with default values from command lines</p> <p>Returns:</p> Type Description <p>a dict of option (i.e. configuration)</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def read_option_from_command():\nr\"\"\"\n    Generate running-time configurations for flgo.init with default values from command lines\n\n    Returns:\n        a dict of option (i.e. configuration)\n    \"\"\"\n\n    parser = argparse.ArgumentParser()\n\"\"\"Training Options\"\"\"\n    # basic settings\n    # methods of server side for sampling and aggregating\n    parser.add_argument('--sample', help='methods for sampling clients', type=str, choices=sample_list, default='uniform')\n    parser.add_argument('--aggregate', help='methods for aggregating models', type=str, choices=agg_list, default='other')\n    # hyper-parameters of training in server side\n    parser.add_argument('--num_rounds', help='number of communication rounds', type=int, default=20)\n    parser.add_argument('--proportion', help='proportion of clients sampled per round', type=float, default=0.2)\n    parser.add_argument('--learning_rate_decay', help='learning rate decay for the training process;', type=float, default=0.998)\n    parser.add_argument('--lr_scheduler', help='type of the global learning rate scheduler', type=int, default=-1)\n    parser.add_argument('--early_stop', help='stop training if there is no improvement for no smaller than the maximum rounds', type=int, default=-1)\n    # hyper-parameters of local_movielens_recommendation training\n    parser.add_argument('--num_epochs', help='number of epochs when clients locally train the model on data;', type=int, default=5)\n    parser.add_argument('--num_steps', help='the number of local steps, which dominate num_epochs when setting num_steps&gt;0', type=int, default=-1)\n    parser.add_argument('--learning_rate', help='learning rate for inner solver;', type=float, default=0.1)\n    parser.add_argument('--batch_size', help='batch size', type=float, default='64')\n    parser.add_argument('--optimizer', help='select the optimizer for gd', type=str, choices=optimizer_list, default='SGD')\n    parser.add_argument('--clip_grad', help='clipping gradients if the max norm of gradients ||g|| &gt; clip_norm &gt; 0', type=float, default=0.0)\n    parser.add_argument('--momentum', help='momentum of local training', type=float, default=0.0)\n    parser.add_argument('--weight_decay', help='weight decay of local training', type=float, default=0.0)\n    parser.add_argument('--num_edge_rounds', help='number of edge rounds in hierFL', type=int, default=5)\n    # algorithm-dependent hyper-parameters\n    parser.add_argument('--algo_para', help='algorithm-dependent hyper-parameters', nargs='*', type=float)\n\n\"\"\"Environment Options\"\"\"\n    # the ratio of the amount of the data used to train\n    parser.add_argument('--train_holdout', help='the rate of holding out the validation dataset from all the local training datasets', type=float, default=0.1)\n    parser.add_argument('--test_holdout', help='the rate of holding out the validation dataset from the testing datasets owned by the server', type=float, default=0.0)\n    parser.add_argument('--local_test', help='if this term is set True and train_holdout&gt;0, (0.5*train_holdout) of data will be set as client.test_data.', action=\"store_true\", default=False)\n    # realistic machine config\n    parser.add_argument('--seed', help='seed for random initialization;', type=int, default=0)\n    parser.add_argument('--gpu', nargs='*', help='GPU IDs and empty input is equal to using CPU', type=int)\n    parser.add_argument('--server_with_cpu', help='the model parameters will be stored in the memory if True', action=\"store_true\", default=False)\n    parser.add_argument('--num_parallels', help=\"the number of parallels in the clients computing session\", type=int, default=1)\n    parser.add_argument('--num_workers', help='the number of workers of DataLoader', type=int, default=0)\n    parser.add_argument('--pin_memory', help='pin_memory of DataLoader', action=\"store_true\", default=False)\n    parser.add_argument('--test_batch_size', help='the batch_size used in testing phase;', type=int, default=512)\n\n\"\"\"Simulator Options\"\"\"\n    # the simulating systemic configuration of clients and the server that helps constructing the heterogeity in the network condition &amp; computing power\n    parser.add_argument('--availability', help=\"client availability mode\", type=str, default = 'IDL')\n    parser.add_argument('--connectivity', help=\"client connectivity mode\", type=str, default = 'IDL')\n    parser.add_argument('--completeness', help=\"client completeness mode\", type=str, default = 'IDL')\n    parser.add_argument('--responsiveness', help=\"client responsiveness mode\", type=str, default='IDL')\n\n\"\"\"Logger Options\"\"\"\n    # logger setting\n    parser.add_argument('--log_level', help='the level of logger', type=str, default='INFO')\n    parser.add_argument('--log_file', help='bool controls whether log to file and default value is False', action=\"store_true\", default=False)\n    parser.add_argument('--no_log_console', help='bool controls whether log to screen and default value is True', action=\"store_true\", default=False)\n    parser.add_argument('--no_overwrite', help='bool controls whether to overwrite the old result', action=\"store_true\", default=False)\n    parser.add_argument('--eval_interval', help='evaluate every __ rounds;', type=int, default=1)\n    try: option = vars(parser.parse_known_args()[0])\n    except IOError as msg: parser.error(str(msg))\n    for key in option.keys():\n        if option[key] is None:\n            option[key]=[]\n    return option\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.run_in_parallel","title":"<code>run_in_parallel(task, algorithm, options=[], model=None, devices=[], Logger=flgo.experiment.logger.simple_logger.SimpleLogger, Simulator=flgo.simulator.DefaultSimulator, scene='horizontal', scheduler=None)</code>","text":"<p>Run different groups of hyper-parameters for one task and one algorithm in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>str</code> <p>the dictionary of the federated task</p> required <code>algorithm</code> <code>module|class</code> <p>the algorithm will be used to optimize the model in federated manner, which must contain pre-defined attributions (e.g. algorithm.Server and algorithm.Client for horizontal federated learning)</p> required <code>options</code> <code>list</code> <p>the configurations of different groups of hyper-parameters</p> <code>[]</code> <code>model</code> <code>module|class</code> <p>the model module that contains two methods: model.init_local_module(object) and model.init_global_module(object)</p> <code>None</code> <code>devices</code> <code>list</code> <p>the list of IDs of devices</p> <code>[]</code> <code>Logger</code> <code>class</code> <p>the class of the logger inherited from flgo.experiment.logger.BasicLogger</p> <code>flgo.experiment.logger.simple_logger.SimpleLogger</code> <code>Simulator</code> <code>class</code> <p>the class of the simulator inherited from flgo.simulator.BasicSimulator</p> <code>flgo.simulator.DefaultSimulator</code> <code>scene</code> <code>str</code> <p>'horizontal' or 'vertical' in current version of FLGo</p> <code>'horizontal'</code> <code>scheduler</code> <code>instance of flgo.experiment.device_scheduler.BasicScheduler</code> <p>GPU scheduler that schedules GPU by checking their availability</p> <code>None</code> <p>Returns:</p> Type Description <p>the returns of _call_by_process</p> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def run_in_parallel(task: str, algorithm, options:list = [], model=None, devices = [], Logger:flgo.experiment.logger.BasicLogger = flgo.experiment.logger.simple_logger.SimpleLogger, Simulator=flgo.simulator.DefaultSimulator, scene='horizontal', scheduler = None):\n\"\"\"\n    Run different groups of hyper-parameters for one task and one algorithm in parallel.\n\n    Args:\n        task (str): the dictionary of the federated task\n        algorithm (module|class): the algorithm will be used to optimize the model in federated manner, which must contain pre-defined attributions (e.g. algorithm.Server and algorithm.Client for horizontal federated learning)\n        options (list): the configurations of different groups of hyper-parameters\n        model (module|class): the model module that contains two methods: model.init_local_module(object) and model.init_global_module(object)\n        devices (list): the list of IDs of devices\n        Logger (class): the class of the logger inherited from flgo.experiment.logger.BasicLogger\n        Simulator (class): the class of the simulator inherited from flgo.simulator.BasicSimulator\n        scene (str): 'horizontal' or 'vertical' in current version of FLGo\n        scheduler (instance of flgo.experiment.device_scheduler.BasicScheduler): GPU scheduler that schedules GPU by checking their availability\n\n    Returns:\n        the returns of _call_by_process\n    \"\"\"\n    try:\n        # init multiprocess\n        torch.multiprocessing.set_start_method('spawn', force=True)\n        torch.multiprocessing.set_sharing_strategy('file_system')\n    except:\n        pass\n    if model is None:\n        model_name = None\n    else:\n        if not hasattr(model, '__module__') and hasattr(model, '__name__'):\n            model_name = model.__name__\n        else:\n            model_name = model\n    algorithm_name = algorithm.__name__ if (not hasattr(algorithm, '__module__') and hasattr(algorithm, '__name__')) else algorithm\n    option_state = {oid:{'p':None, 'completed':False, 'output':None, 'option_in_queue':False, 'recv':None, } for oid in range(len(options))}\n    if scheduler is None: scheduler = flgo.experiment.device_scheduler.BasicScheduler(devices)\n    while True:\n        for oid in range(len(options)):\n            opt = options[oid]\n            if option_state[oid]['p'] is None:\n                if not option_state[oid]['completed']:\n                    available_device = scheduler.get_available_device(opt)\n                    if available_device is None: continue\n                    else:\n                        opt['gpu'] = available_device\n                        recv_end, send_end = multiprocessing.Pipe(False)\n                        option_state[oid]['p'] = multiprocessing.Process(target=_call_by_process, args=(task, algorithm_name, opt, model_name, Logger, Simulator, scene, send_end))\n                        option_state[oid]['recv'] = recv_end\n                        option_state[oid]['p'].start()\n                        scheduler.add_process(option_state[oid]['p'].pid)\n                        print('Process {} was created for args {}'.format(option_state[oid]['p'].pid,(task, algorithm_name, opt, model_name, Logger, Simulator, scene)))\n            else:\n                if option_state[oid]['p'].exitcode is not None:\n                    tmp = option_state[oid]['recv'].recv()\n                    scheduler.remove_process(tmp[-1])\n                    try:\n                        option_state[oid]['p'].terminate()\n                    except:\n                        pass\n                    option_state[oid]['p'] = None\n                    if len(tmp)==2:\n                        option_state[oid]['completed'] = True\n                        option_state[oid]['output'] = tmp[0]\n                    else:\n                        print(tmp[1])\n        if all([v['completed'] for v in option_state.values()]):break\n        time.sleep(1)\n    res = []\n    for oid in range(len(options)):\n        rec_path = option_state[oid]['output']\n        with open(rec_path, 'r') as inf:\n            s_inf = inf.read()\n            rec = json.loads(s_inf)\n        res.append(rec)\n    return res\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.set_data_root","title":"<code>set_data_root(data_root=None)</code>","text":"<p>Set the root of data that stores all the raw data automatically</p> <p>Parameters:</p> Name Type Description Default <code>data_root</code> <code>str</code> <p>the path of a directory whose default value is None and will be set to os.getcwd() as default.</p> <code>None</code> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def set_data_root(data_root:str=None):\n\"\"\"\n    Set the root of data that stores all the raw data automatically\n    Args:\n        data_root (str): the path of a directory whose default value is None and will be set to os.getcwd() as default.\n    Returns:\n    \"\"\"\n    file_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'benchmark', '__init__.py')\n    default_root = os.path.abspath(os.path.join(flgo.benchmark.path, 'RAW_DATA'))\n    if data_root is None and os.path.abspath(flgo.benchmark.data_root)!=default_root:\n        crt_root = default_root.strip()\n        root_name = '\"'+default_root.strip()+'\"'\n    elif data_root == 'cwd':\n        crt_root = os.path.abspath(os.getcwd())\n        root_name = 'os.getcwd()'\n    else:\n        if not os.path.exists(data_root):\n            os.makedirs(data_root)\n        if not os.path.isdir(data_root):\n            raise TypeError('data_root must be a dir')\n        crt_root = os.path.abspath(data_root).strip()\n        root_name = '\"'+crt_root+'\"'\n    with open(file_path, 'r', encoding=sys.getfilesystemencoding()) as inf:\n        lines = inf.readlines()\n        idx = -1\n        for i,line in enumerate(lines):\n            if line.find('data_root')&gt;-1:\n                idx = i\n                break\n        if idx&gt;0:\n            lines[idx] = \"data_root = \"+ root_name\n    with open(file_path, 'w', encoding=sys.getfilesystemencoding()) as outf:\n        outf.writelines(lines)\n    flgo.benchmark.data_root = crt_root\n    print('Data root directory has successfully been changed to {}'.format(crt_root))\n    return\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.setup_seed","title":"<code>setup_seed(seed)</code>","text":"<p>Fix all the random seed used in numpy, torch and random module</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>int</code> <p>the random seed</p> required Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def setup_seed(seed):\nr\"\"\"\n    Fix all the random seed used in numpy, torch and random module\n\n    Args:\n        seed (int): the random seed\n    \"\"\"\n    if seed &lt;0:\n        torch.backends.cudnn.enabled = False\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n        torch.use_deterministic_algorithms(True)\n        seed = -seed\n    random.seed(1+seed)\n    np.random.seed(21+seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.manual_seed(12+seed)\n    torch.cuda.manual_seed_all(123+seed)\n</code></pre>"},{"location":"Docs/utils/fflow/#flgo.utils.fflow.tune","title":"<code>tune(task, algorithm, option={}, model=None, Logger=flgo.experiment.logger.tune_logger.TuneLogger, Simulator=flgo.simulator.DefaultSimulator, scene='horizontal', scheduler=None)</code>","text":"<p>Tune hyper-parameters for the specific (task, algorithm, model) in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>task</code> <code>str</code> <p>the dictionary of the federated task</p> required <code>algorithm</code> <code>module|class</code> <p>the algorithm will be used to optimize the model in federated manner, which must contain pre-defined attributions (e.g. algorithm.Server and algorithm.Client for horizontal federated learning)</p> required <code>option</code> <code>dict</code> <p>the dict whose values should be of type list to construct the combinations</p> <code>{}</code> <code>model</code> <code>module|class</code> <p>the model module that contains two methods: model.init_local_module(object) and model.init_global_module(object)</p> <code>None</code> <code>Logger</code> <code>class</code> <p>the class of the logger inherited from flgo.experiment.logger.BasicLogger</p> <code>flgo.experiment.logger.tune_logger.TuneLogger</code> <code>Simulator</code> <code>class</code> <p>the class of the simulator inherited from flgo.simulator.BasicSimulator</p> <code>flgo.simulator.DefaultSimulator</code> <code>scene</code> <code>str</code> <p>'horizontal' or 'vertical' in current version of FLGo</p> <code>'horizontal'</code> <code>scheduler</code> <code>instance of flgo.experiment.device_scheduler.BasicScheduler</code> <p>GPU scheduler that schedules GPU by checking their availability</p> <code>None</code> Source code in <code>flgo\\utils\\fflow.py</code> <pre><code>def tune(task: str, algorithm, option: dict = {}, model=None, Logger: flgo.experiment.logger.BasicLogger = flgo.experiment.logger.tune_logger.TuneLogger, Simulator: BasicSimulator=flgo.simulator.DefaultSimulator, scene='horizontal', scheduler=None):\n\"\"\"\n        Tune hyper-parameters for the specific (task, algorithm, model) in parallel.\n        Args:\n            task (str): the dictionary of the federated task\n            algorithm (module|class): the algorithm will be used to optimize the model in federated manner, which must contain pre-defined attributions (e.g. algorithm.Server and algorithm.Client for horizontal federated learning)\n            option (dict): the dict whose values should be of type list to construct the combinations\n            model (module|class): the model module that contains two methods: model.init_local_module(object) and model.init_global_module(object)\n            Logger (class): the class of the logger inherited from flgo.experiment.logger.BasicLogger\n            Simulator (class): the class of the simulator inherited from flgo.simulator.BasicSimulator\n            scene (str): 'horizontal' or 'vertical' in current version of FLGo\n            scheduler (instance of flgo.experiment.device_scheduler.BasicScheduler): GPU scheduler that schedules GPU by checking their availability\n        \"\"\"\n    # generate combinations of hyper-parameters\n    if 'gpu' in option.keys():\n        device_ids = option['gpu']\n        option.pop('gpu')\n        if not isinstance(device_ids, Iterable): device_ids = [device_ids]\n    else:\n        device_ids = [-1]\n    keys = list(option.keys())\n    for k in keys: option[k] = [option[k]] if (not isinstance(option[k], Iterable) or isinstance(option[k], str)) else option[k]\n    para_combs = [para_comb for para_comb in itertools.product(*(option[k] for k in keys))]\n    options = [{k:v for k,v in zip(keys, paras)} for paras in para_combs]\n    for op in options:op['log_file'] = True\n    if scheduler is None:\n        scheduler = flgo.experiment.device_scheduler.BasicScheduler(device_ids)\n    outputs = run_in_parallel(task, algorithm, options,model, devices=device_ids, Logger=Logger, Simulator=Simulator, scene=scene, scheduler=scheduler)\n    optimal_idx = int(np.argmin([min(output['val_loss']) for output in outputs]))\n    optimal_para = options[optimal_idx]\n    print(\"The optimal combination of hyper-parameters is:\")\n    print('-----------------------------------------------')\n    for k,v in optimal_para.items():\n        if k=='gpu': continue\n        print(\"{}\\t|{}\".format(k,v))\n    print('-----------------------------------------------')\n    op_round = np.argmin(outputs[optimal_idx]['val_loss'])\n    if 'eval_interval' in option.keys(): op_round = option['eval_interval']*op_round\n    print('The minimal validation loss occurs at the round {}'.format(op_round))\n</code></pre>"},{"location":"Docs/utils/fmodule/","title":"flgo.utils.fmodule","text":""},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule","title":"<code>FModule</code>","text":"<p>         Bases: <code>nn.Module</code></p> <p>This module implements commonly used model-level operators like add, sub, and so on.</p> <p>Example:</p> <pre><code>    &gt;&gt;&gt; class TestModel(FModule):\n    ...     def __init__(self):\n    ...         self.mlp = torch.nn.Linear(2,2, bias=False)\n    &gt;&gt;&gt; m1 = TestModel()\n    &gt;&gt;&gt; m2 = TestModel()\n    &gt;&gt;&gt; m3 = m1+m2\n    &gt;&gt;&gt; (m1.mlp.weight+m2.mlp.weight)==m3.mlp.weight\n</code></pre> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>class FModule(nn.Module):\nr\"\"\"\n    This module implements commonly used model-level operators like add, sub, and so on.\n\n    Example:\n    ```python\n        &gt;&gt;&gt; class TestModel(FModule):\n        ...     def __init__(self):\n        ...         self.mlp = torch.nn.Linear(2,2, bias=False)\n        &gt;&gt;&gt; m1 = TestModel()\n        &gt;&gt;&gt; m2 = TestModel()\n        &gt;&gt;&gt; m3 = m1+m2\n        &gt;&gt;&gt; (m1.mlp.weight+m2.mlp.weight)==m3.mlp.weight\n    ```\n    \"\"\"\n    def __init__(self):\n        super().__init__()\n        self.ingraph = False\n\n    def __add__(self, other):\n        if isinstance(other, int) and other == 0 : return self\n        if not isinstance(other, FModule): raise TypeError\n        return _model_add(self, other)\n\n    def __radd__(self, other):\n        return _model_add(self, other)\n\n    def __sub__(self, other):\n        if isinstance(other, int) and other == 0: return self\n        if not isinstance(other, FModule): raise TypeError\n        return _model_sub(self, other)\n\n    def __mul__(self, other):\n        return _model_scale(self, other)\n\n    def __rmul__(self, other):\n        return self*other\n\n    def __truediv__(self, other):\n        return self*(1.0/other)\n\n    def __pow__(self, power, modulo=None):\n        return _model_norm(self, power)\n\n    def __neg__(self):\n        return _model_scale(self, -1.0)\n\n    def __sizeof__(self):\n        if not hasattr(self, '__size'):\n            param_size = 0\n            param_sum = 0\n            for param in self.parameters():\n                param_size += param.nelement() * param.element_size()\n                param_sum += param.nelement()\n            buffer_size = 0\n            buffer_sum = 0\n            for buffer in self.buffers():\n                buffer_size += buffer.nelement() * buffer.element_size()\n                buffer_sum += buffer.nelement()\n            self.__size = param_size + buffer_size\n        return self.__size\n\n    def norm(self, p=2):\nr\"\"\"\n        Args:\n            p (float): p-norm\n\n        Returns:\n            the scale value of the p-norm of vectorized model parameters\n        \"\"\"\n        return self**p\n\n    def zeros_like(self):\nr\"\"\"\n        Returns:\n             a new model with the same architecture and all the parameters being set zero\n        \"\"\"\n        return self*0\n\n    def dot(self, other):\nr\"\"\"\n        Args:\n            other (Fmodule): the model with the same architecture of self\n\n        Returns:\n            the dot value of the two vectorized models\n        \"\"\"\n        return _model_dot(self, other)\n\n    def cos_sim(self, other):\nr\"\"\"\n        Args:\n            other (Fmodule): the model with the same architecture of self\n\n        Returns:\n            the cosine similarity value of the two vectorized models\n        \"\"\"\n        return _model_cossim(self, other)\n\n    def op_with_graph(self):\n        self.ingraph = True\n\n    def op_without_graph(self):\n        self.ingraph = False\n\n    def load(self, other):\nr\"\"\"\n        Set the values of model parameters the same as the values of another model\n        Args:\n            other (Fmodule): the model with the same architecture of self\n        \"\"\"\n        self.op_without_graph()\n        self.load_state_dict(other.state_dict())\n        return\n\n    def freeze_grad(self):\nr\"\"\"\n        All the gradients of the model parameters won't be computed after calling this method\n        \"\"\"\n        for p in self.parameters():\n            p.requires_grad = False\n\n    def enable_grad(self):\nr\"\"\"\n        All the gradients of the model parameters will be computed after calling this method\n        \"\"\"\n        for p in self.parameters():\n            p.requires_grad = True\n\n    def zero_dict(self):\nr\"\"\"\n        Set all the values of model parameters to be zero\n        \"\"\"\n        self.op_without_graph()\n        for p in self.parameters():\n            p.data.zero_()\n\n    def normalize(self):\nr\"\"\"\n        Normalize the parameters of self to enable self.norm(2)=1\n        \"\"\"\n        self.op_without_graph()\n        self.load_state_dict((self/(self**2)).state_dict())\n\n    def get_device(self):\nr\"\"\"\n        Returns:\n            the device of the tensors of this model\n        \"\"\"\n        return next(self.parameters()).device\n\n    def count_parameters(self, output=True):\nr\"\"\"\n        Count the parameters for this model\n\n        Args:\n            output (bool): whether to output the information to the stdin (i.e. console)\n        Returns:\n            the number of all the parameters in this model\n        \"\"\"\n        # table = pt.PrettyTable([\"Modules\", \"Parameters\"])\n        total_params = 0\n        for name, parameter in self.named_parameters():\n            if not parameter.requires_grad:\n                # table.add_row([name, 0])\n                continue\n            params = parameter.numel()\n            # table.add_row([name, params])\n            total_params += params\n        # if output:\n        #     print(table)\n        #     print(f\"TotalTrainableParams: {total_params}\")\n        return total_params\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.cos_sim","title":"<code>cos_sim(other)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>other</code> <code>Fmodule</code> <p>the model with the same architecture of self</p> required <p>Returns:</p> Type Description <p>the cosine similarity value of the two vectorized models</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def cos_sim(self, other):\nr\"\"\"\n    Args:\n        other (Fmodule): the model with the same architecture of self\n\n    Returns:\n        the cosine similarity value of the two vectorized models\n    \"\"\"\n    return _model_cossim(self, other)\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.count_parameters","title":"<code>count_parameters(output=True)</code>","text":"<p>Count the parameters for this model</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>bool</code> <p>whether to output the information to the stdin (i.e. console)</p> <code>True</code> <p>Returns:</p> Type Description <p>the number of all the parameters in this model</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def count_parameters(self, output=True):\nr\"\"\"\n    Count the parameters for this model\n\n    Args:\n        output (bool): whether to output the information to the stdin (i.e. console)\n    Returns:\n        the number of all the parameters in this model\n    \"\"\"\n    # table = pt.PrettyTable([\"Modules\", \"Parameters\"])\n    total_params = 0\n    for name, parameter in self.named_parameters():\n        if not parameter.requires_grad:\n            # table.add_row([name, 0])\n            continue\n        params = parameter.numel()\n        # table.add_row([name, params])\n        total_params += params\n    # if output:\n    #     print(table)\n    #     print(f\"TotalTrainableParams: {total_params}\")\n    return total_params\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.dot","title":"<code>dot(other)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>other</code> <code>Fmodule</code> <p>the model with the same architecture of self</p> required <p>Returns:</p> Type Description <p>the dot value of the two vectorized models</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def dot(self, other):\nr\"\"\"\n    Args:\n        other (Fmodule): the model with the same architecture of self\n\n    Returns:\n        the dot value of the two vectorized models\n    \"\"\"\n    return _model_dot(self, other)\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.enable_grad","title":"<code>enable_grad()</code>","text":"<p>All the gradients of the model parameters will be computed after calling this method</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def enable_grad(self):\nr\"\"\"\n    All the gradients of the model parameters will be computed after calling this method\n    \"\"\"\n    for p in self.parameters():\n        p.requires_grad = True\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.freeze_grad","title":"<code>freeze_grad()</code>","text":"<p>All the gradients of the model parameters won't be computed after calling this method</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def freeze_grad(self):\nr\"\"\"\n    All the gradients of the model parameters won't be computed after calling this method\n    \"\"\"\n    for p in self.parameters():\n        p.requires_grad = False\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.get_device","title":"<code>get_device()</code>","text":"<p>Returns:</p> Type Description <p>the device of the tensors of this model</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def get_device(self):\nr\"\"\"\n    Returns:\n        the device of the tensors of this model\n    \"\"\"\n    return next(self.parameters()).device\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.load","title":"<code>load(other)</code>","text":"<p>Set the values of model parameters the same as the values of another model</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Fmodule</code> <p>the model with the same architecture of self</p> required Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def load(self, other):\nr\"\"\"\n    Set the values of model parameters the same as the values of another model\n    Args:\n        other (Fmodule): the model with the same architecture of self\n    \"\"\"\n    self.op_without_graph()\n    self.load_state_dict(other.state_dict())\n    return\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.norm","title":"<code>norm(p=2)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>p</code> <code>float</code> <p>p-norm</p> <code>2</code> <p>Returns:</p> Type Description <p>the scale value of the p-norm of vectorized model parameters</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def norm(self, p=2):\nr\"\"\"\n    Args:\n        p (float): p-norm\n\n    Returns:\n        the scale value of the p-norm of vectorized model parameters\n    \"\"\"\n    return self**p\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.normalize","title":"<code>normalize()</code>","text":"<p>Normalize the parameters of self to enable self.norm(2)=1</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def normalize(self):\nr\"\"\"\n    Normalize the parameters of self to enable self.norm(2)=1\n    \"\"\"\n    self.op_without_graph()\n    self.load_state_dict((self/(self**2)).state_dict())\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.zero_dict","title":"<code>zero_dict()</code>","text":"<p>Set all the values of model parameters to be zero</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def zero_dict(self):\nr\"\"\"\n    Set all the values of model parameters to be zero\n    \"\"\"\n    self.op_without_graph()\n    for p in self.parameters():\n        p.data.zero_()\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.FModule.zeros_like","title":"<code>zeros_like()</code>","text":"<p>Returns:</p> Type Description <p>a new model with the same architecture and all the parameters being set zero</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def zeros_like(self):\nr\"\"\"\n    Returns:\n         a new model with the same architecture and all the parameters being set zero\n    \"\"\"\n    return self*0\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.cos_sim","title":"<code>cos_sim(m1, m2)</code>","text":"<p>The cosine similarity value of the two models res=m1\u00b7m2/(||m1||*||m2||)</p> <p>Parameters:</p> Name Type Description Default <code>m1</code> <code>FModule</code> <p>model 1</p> required <code>m2</code> <code>FModule</code> <p>model 2</p> required <p>Returns:</p> Type Description <p>The cosine similarity value of the two models</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def cos_sim(m1, m2):\nr\"\"\"\n    The cosine similarity value of the two models res=m1\u00b7m2/(||m1||*||m2||)\n\n    Args:\n        m1 (FModule): model 1\n        m2 (FModule): model 2\n\n    Returns:\n        The cosine similarity value of the two models\n    \"\"\"\n    return m1.cos_sim(m2)\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.dot","title":"<code>dot(m1, m2)</code>","text":"<p>The dot value of the two models res = m1\u00b7m2</p> <p>Parameters:</p> Name Type Description Default <code>m1</code> <code>FModule</code> <p>model 1</p> required <code>m2</code> <code>FModule</code> <p>model 2</p> required <p>Returns:</p> Type Description <p>The dot value of the two models</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def dot(m1, m2):\nr\"\"\"\n    The dot value of the two models res = m1\u00b7m2\n\n    Args:\n        m1 (FModule): model 1\n        m2 (FModule): model 2\n\n    Returns:\n        The dot value of the two models\n    \"\"\"\n    return m1.dot(m2)\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.element_wise_func","title":"<code>element_wise_func(m, func)</code>","text":"<p>The element-wise function on this model</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>FModule</code> <p>the model</p> required <code>func</code> <p>element-wise function</p> required <p>Returns:</p> Type Description <p>The new model whose parameters satisfy mi=func(mi)</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def element_wise_func(m, func):\nr\"\"\"\n    The element-wise function on this model\n\n    Args:\n        m (FModule): the model\n        func: element-wise function\n\n    Returns:\n        The new model whose parameters satisfy mi=func(mi)\n    \"\"\"\n    if m is None: return None\n    res = m.__class__().to(m.get_device())\n    if m.ingraph:\n        res.op_with_graph()\n        ml = get_module_from_model(m)\n        for md in ml:\n            rd = _modeldict_element_wise(md._parameters, func)\n            for l in md._parameters.keys():\n                md._parameters[l] = rd[l]\n    else:\n        _modeldict_cp(res.state_dict(), _modeldict_element_wise(m.state_dict(), func))\n    return res\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.exp","title":"<code>exp(m)</code>","text":"<p>The element-wise res=exp(m) where all the model parameters satisfy mi=exp(mi)</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>FModule</code> <p>the model</p> required <p>Returns:</p> Type Description <p>The new model whose parameters satisfy mi=exp(mi)</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def exp(m):\nr\"\"\"\n    The element-wise res=exp(m) where all the model parameters satisfy mi=exp(mi)\n\n    Args:\n        m (FModule): the model\n\n    Returns:\n        The new model whose parameters satisfy mi=exp(mi)\n    \"\"\"\n    return element_wise_func(m, torch.exp)\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.get_module_from_model","title":"<code>get_module_from_model(model, res=None)</code>","text":"<p>Walk through all the sub modules of a model and return them as a list</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>FModule</code> <p>model</p> required <code>res</code> <code>None</code> <p>should be remained None</p> <code>None</code> <p>Returns:</p> Type Description <p>The list of all the sub-modules of a model</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def get_module_from_model(model, res = None):\nr\"\"\"\n    Walk through all the sub modules of a model and return them as a list\n\n    Args:\n        model (FModule): model\n        res (None): should be remained None\n\n    Returns:\n        The list of all the sub-modules of a model\n    \"\"\"\n    if res==None: res = []\n    ch_names = [item[0] for item in model.named_children()]\n    if ch_names==[]:\n        if model._parameters:\n            res.append(model)\n    else:\n        for name in ch_names:\n            get_module_from_model(model.__getattr__(name), res)\n    return res\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.log","title":"<code>log(m)</code>","text":"<p>The element-wise res=log(m) where all the model parameters satisfy mi=log(mi)</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>FModule</code> <p>the model</p> required <p>Returns:</p> Type Description <p>The new model whose parameters satisfy mi=log(mi)</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def log(m):\nr\"\"\"\n    The element-wise res=log(m) where all the model parameters satisfy mi=log(mi)\n\n    Args:\n        m (FModule): the model\n\n    Returns:\n        The new model whose parameters satisfy mi=log(mi)\n    \"\"\"\n    return element_wise_func(m, torch.log)\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.normalize","title":"<code>normalize(m)</code>","text":"<p>The new model that is the normalized version of the input model m=m/||m||_2</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>FModule</code> <p>the model</p> required <p>Returns:</p> Type Description <p>The new model that is the normalized version of the input model</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def normalize(m):\nr\"\"\"\n    The new model that is the normalized version of the input model m=m/||m||_2\n\n    Args:\n        m (FModule): the model\n\n    Returns:\n        The new model that is the normalized version of the input model\n    \"\"\"\n    return m/(m**2)\n</code></pre>"},{"location":"Docs/utils/fmodule/#flgo.utils.fmodule.with_multi_gpus","title":"<code>with_multi_gpus(func)</code>","text":"<p>Decorate functions whose first parameter is model to carry out all the operations on the same device</p> Source code in <code>flgo\\utils\\fmodule.py</code> <pre><code>def with_multi_gpus(func):\nr\"\"\"\n    Decorate functions whose first parameter is model to carry out all the operations on the same device\n    \"\"\"\n    def cal_on_personal_gpu(self, model, *args, **kargs):\n        origin_device = model.get_device()\n        # transfer to new device\n        new_args = []\n        new_kargs = {}\n        for arg in args:\n            narg = arg.to(self.device) if hasattr(arg, 'get_device') or hasattr(arg, 'device') else arg\n            new_args.append(narg)\n        for k,v in kargs.items():\n            nv = v.to(self.device) if hasattr(v, 'get_device') or hasattr(v, 'device') else v\n            new_kargs[k] = nv\n        model.to(self.device)\n        # calculating\n        res = func(self, model, *tuple(new_args), **new_kargs)\n        # transter to original device\n        model.to(origin_device)\n        if res is not None:\n            if type(res)==dict:\n                for k,v in res.items():\n                    nv = v.to(origin_device) if hasattr(v, 'get_device') or hasattr(v, 'device') else v\n                    res[k] = nv\n            elif type(res)==tuple or type(res)==list:\n                new_res = []\n                for v in res:\n                    nv = v.to(origin_device) if hasattr(v, 'get_device') or hasattr(v, 'device') else v\n                    new_res.append(nv)\n                if type(res)==tuple:\n                    res = tuple(new_res)\n            else:\n                res = res.to(origin_device) if hasattr(res, 'get_device') or hasattr(res, 'device') else res\n        return res\n    return cal_on_personal_gpu\n</code></pre>"},{"location":"Overview/","title":"Index","text":""},{"location":"Overview/#algorithm-integration","title":"Algorithm Integration","text":"<p>We have already implemented 10+ SOTA algorithms in recent years' top tiers conferences and tiers.</p> Method Reference Publication Tag FedAvg [McMahan et al., 2017] AISTATS' 2017 FedAsync [Cong Xie et al., 2019] Asynchronous FedBuff [John Nguyen et al., 2022] AISTATS 2022 Asynchronous TiFL [Zheng Chai et al., 2020] HPDC 2020 Communication-efficiency, responsiveness AFL [Mehryar Mohri et al., 2019] ICML 2019 Fairness FedFv [Zheng Wang et al., 2019] IJCAI 2021 Fairness FedMgda+ [Zeou Hu et al., 2022] IEEE TNSE 2022 Fairness, robustness FedProx [Tian Li et al., 2020] MLSys 2020 Non-I.I.D., Incomplete Training Mifa [Xinran Gu et al., 2021] NeurIPS 2021 Client Availability PowerofChoice [Yae Jee Cho et al., 2020] arxiv Biased Sampling, Fast-Convergence QFedAvg [Tian Li et al., 2020] ICLR 2020 Communication-efficient,fairness Scaffold [Sai Praneeth Karimireddy et al., 2020] ICML 2020 Non-I.I.D., Communication Capacity"},{"location":"Overview/#benchmark-gallary","title":"Benchmark Gallary","text":"Benchmark \u00a0 Type Scene \u00a0 \u00a0 Task \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 CIFAR100 image horizontal classification CIFAR10 \u00a0 image horizontal classification CiteSeer graph horizontal classification Cora \u00a0 \u00a0graph horizontal classification PubMed \u00a0 graph horizontal classification MNIST \u00a0 image horizontal classification EMNIST \u00a0 image horizontal classification FEMINIST image horizontal classification FashionMINIST \u00a0 image horizontal classification ENZYMES \u00a0 graph horizontal classification Reddit \u00a0 text horizontal classification Sentiment140 \u00a0 text horizontal classification MUTAG \u00a0 graph horizontal classification Shakespeare \u00a0 text horizontal classification Synthetic \u00a0 table horizontal classification"},{"location":"Overview/#asyncsync-supported","title":"Async/Sync Supported","text":"<p>We set a virtual global clock and a client-state machine to simulate a real-world scenario for comparison on asynchronous  and synchronous strategies. Here we provide a comprehensive example to help understand the difference  between the two strategies in FLGo.</p> <p> For synchronous algorithms, the server would wait for the slowest clients.  In round 1,the server select a subset of idle clients (i.e. client i,u,v)  to join in training and the slowest client v dominates the duration of this  round (i.e. four time units). If there is anyone suffering from  training failure (i.e. being dropped out), the duration of the current round  should be the longest time that the server will wait for it (e.g. round 2 takes  the maximum waiting time of six units to wait for response from client v). </p> <p>For asynchronous algorithms, the server usually periodically samples the idle  clients to update models, where the length of the period is set as two time  units in our example. After sampling the currently idle clients, the server will  immediately checks whether there are packages currently returned from clients  (e.g. the server selects client j and receives the package from client k at time 13). </p>"},{"location":"Overview/#experimental-tools","title":"Experimental Tools","text":"<p>For experimental purposes </p>"},{"location":"Overview/#automatical-tuning","title":"Automatical Tuning","text":""},{"location":"Overview/#multi-scene-horizontal-and-vertical","title":"Multi-Scene (Horizontal and Vertical)","text":""},{"location":"Overview/#accelerating-by-multi-process","title":"Accelerating by Multi-Process","text":""},{"location":"Overview/#references","title":"References","text":"<p>[McMahan. et al., 2017] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-Efficient Learning of Deep Networks from Decentralized Data. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2017.</p> <p>[Cong Xie. et al., 2019] Cong Xie, Sanmi Koyejo, Indranil Gupta. Asynchronous Federated Optimization. </p> <p>[John Nguyen. et al., 2022] John Nguyen, Kshitiz Malik, Hongyuan Zhan, Ashkan Yousefpour, Michael Rabbat, Mani Malek, Dzmitry Huba. Federated Learning with Buffered Asynchronous Aggregation. In International Conference on Artificial Intelligence and Statistics (AISTATS), 2022.</p> <p>[Zheng Chai. et al., 2020] Zheng Chai, Ahsan Ali, Syed Zawad, Stacey Truex, Ali Anwar, Nathalie Baracaldo, Yi Zhou, Heiko Ludwig, Feng Yan, Yue Cheng. TiFL: A Tier-based Federated Learning System.In International Symposium on High-Performance Parallel and Distributed Computing(HPDC), 2020</p> <p>[Mehryar Mohri. et al., 2019] Mehryar Mohri, Gary Sivek, Ananda Theertha Suresh. Agnostic Federated Learning.In International Conference on Machine Learning(ICML), 2019</p> <p>[Zheng Wang. et al., 2021] Zheng Wang, Xiaoliang Fan, Jianzhong Qi, Chenglu Wen, Cheng Wang, Rongshan Yu. Federated Learning with Fair Averaging. In International Joint Conference on Artificial Intelligence, 2021</p> <p>[Zeou Hu. et al., 2022] Zeou Hu, Kiarash Shaloudegi, Guojun Zhang, Yaoliang Yu. Federated Learning Meets Multi-objective Optimization. In IEEE Transactions on Network Science and Engineering, 2022</p> <p>[Tian Li. et al., 2020] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, Virginia Smith. Federated Optimization in Heterogeneous Networks. In Conference on Machine Learning and Systems, 2020</p> <p>[Xinran Gu. et al., 2021] Xinran Gu, Kaixuan Huang, Jingzhao Zhang, Longbo Huang. Fast Federated Learning in the Presence of Arbitrary Device Unavailability. In Neural Information Processing Systems(NeurIPS), 2021</p> <p>[Yae Jee Cho. et al., 2020] Yae Jee Cho, Jianyu Wang, Gauri Joshi. Client Selection in Federated Learning: Convergence Analysis and Power-of-Choice Selection Strategies. </p> <p>[Tian Li. et al., 2020] Tian Li, Maziar Sanjabi, Ahmad Beirami, Virginia Smith. Fair Resource Allocation in Federated Learning. In International Conference on Learning Representations, 2020</p>"},{"location":"Overview/Architecture/","title":"FLGo Framework","text":"<p>The whole workflow of FLGo is as shown in the above picture. FLGo framework mainly runs  by three steps. </p> <p>Firstly, given a ML task (i.e. dataset and model), FLGo converts it into a static federated  task through partitioning the original ML dataset into subsets of data owned by different  clients, and hide the task-specific details to the algorithms. </p> <p>Secondly, different federated algorithms can run on the fed static federated task to train  a particular model (e.g. CNN, MLP) . During training phase, the system simulator will create  a simulated environment where a virtual global clock can fairly measure the time and arbitrary  client behaviors can be modeled, which is also transparent to the implementation of algorithms. </p> <p>Finally, the experimental tracker in FLGo is responsible for tracing the running-time information  and organizing the results into tables or figures.</p> <p>The organization of all the modules is as below</p> <pre><code>\u251c\u2500 algorithm\n\u2502  \u251c\u2500 fedavg.py                   //fedavg algorithm\n\u2502  \u251c\u2500 ...\n\u2502  \u251c\u2500 fedasync.py                 //the base class for asynchronous federated algorithms\n\u2502  \u2514\u2500 fedbase.py                  //the base class for federated algorithms\n|\n\u251c\u2500 benchmark\n\u2502  \u251c\u2500 mnist_classification          //classification on mnist dataset\n\u2502  \u2502  \u251c\u2500 model                   //the corresponding model\n\u2502  |  \u2514\u2500 core.py                 //the core supporting for the dataset, and each contains three necessary classes(e.g. TaskGen, TaskReader, TaskCalculator)                         \n\u2502  \u251c\u2500 base.py                 // the base class for all fedtask\n\u2502  \u251c\u2500 ...\n\u2502  \u251c\u2500 RAW_DATA                   // storing the downloaded raw dataset\n\u2502  \u2514\u2500 toolkits                      //the basic tools for generating federated dataset\n\u2502     \u251c\u2500 cv                      // common federal division on cv\n\u2502     \u2502  \u251c\u2500 horizontal           // horizontal fedtask\n\u2502     \u2502  \u2502  \u2514\u2500 image_classification.py   // the base class for image classification\n\u2502     \u2502  \u2514\u2500 ...\n\u2502     \u251c\u2500 ...\n\u2502     \u251c\u2500 partition.py            // the parttion class for federal division\n\u2502     \u2514\u2500 visualization.py        // visualization after the data set is divided\n|\n\u251c\u2500 experiment\n\u2502  \u251c\u2500 logger                            //the class that records the experimental process\n\u2502  \u2502  \u251c\u2500 ...\n\u2502  |  \u2514\u2500 simple_logger.py               //a simple logger class\n\u2502  \u251c\u2500 analyzer.py                  //the class for analyzing and printing experimental results\n|  \u2514\u2500 device_scheduler.py                    // automatically schedule GPUs to run in parallel\n|\n\u251c\u2500 simulator                     //system heterogeneity simulation module\n\u2502  \u251c\u2500 base.py                           //the base class for simulate system heterogeneity\n\u2502  \u251c\u2500 default_simulator.py              //the default class for simulate system heterogeneity\n|  \u2514\u2500 ...\n|\n\u251c\u2500 utils\n\u2502  \u251c\u2500 fflow.py                          //option to read, initialize,...\n\u2502  \u2514\u2500 fmodule.py                        //model-level operators\n\u2514\u2500 requirements.txt \n</code></pre>"},{"location":"Overview/Architecture/algorithm/","title":"Algorithm","text":"<p>In FLGo, each algorithm is described by an independent file consisting of the objects  (i.e. server and clients in horizontal FL) with their actions. </p>"},{"location":"Overview/Architecture/algorithm/#horizontal-fl","title":"Horizontal FL","text":"<p> A classical procedure of FL training process is as shown in the figure above, where the server iteratively  broadcasts the global model to a subset of clients and aggregates the received locally  trained models from them. Following this scheme, a great number of FL algorithms can be  easily implemented by FLGo. For example, to implement methods that customize the local  training process (e.g. FedProx, MOON), developers only need to modify the function  <code>client.train(...)</code>. And a series of sampling strategies can be realized by only replacing  the function <code>server.sample()</code>. We also provide comprehensive tutorial for using FLGo  to implement the state of the art algorithms. In addition, asynchronous algorithms can  share the same scheme with synchronous algorithms in FLGo, where developers only need to  concern about the sampling strategy and how to deal with the currently received packages  from clients at each moment. </p>"},{"location":"Overview/Architecture/algorithm/#vertical-fl","title":"Vertical FL","text":"<p>To be completed.</p>"},{"location":"Overview/Architecture/benchmark/","title":"Benchmark","text":"<p>At the initialization phase, the original dataset is input to <code>TaskGenerator</code> that  accordingly and flexibly partitions the dataset into local sub-datasets owned by  clients and a testing dataset owned the server. And the local data is further divided  to training part and validation part for hyper-parameter tuning purpose. Then, all of  the division information on the original dataset will be stored by <code>TaskPipe</code> into  the disk as a static <code>fedtask</code>, where different federated algorithms can fairly  compare with each other on the same fedtask with a particular model. </p> <p>During the running-time phase,  <code>TaskPipe</code> first distributes the partitioned datasets  to clients and the server after loading the saved partition information and the original  dataset into memory. After the model training starts, Algorithm module can either use the  presetting <code>TaskCalculator</code> APIs to complement the task-specific calculations (i.e. loss  computation, transferring data across devices, evaluation, batching data) or optimize in  customized way. In this manner, the task-relevant details will be blinded to the algorithm  for most cases, which significantly eases the development of new algorithms. </p>"},{"location":"Overview/Architecture/experiment/","title":"Logger and analyzer","text":"<p> Although there are already several comprehensive experiment managers (e.g. wandb,  tensorboard), our <code>Experiment</code> module is compatible with them and enable  customizing experiments in a non-intrusive way to the codes, where users can create a  <code>logger</code> by modifying some APIs to track variables of interest and specify the customized  <code>logger</code> in optional parameters. </p> <p>After the <code>logger</code> stores the running-time information into records, the <code>analyzer</code> can read  them from the disk. A filter is designed to enable only selecting records of interest, and  several APIs are provided for quickly visualizing and analyzing the results by few codes.</p>"},{"location":"Overview/Architecture/experiment/#device-scheduler","title":"Device Scheduler","text":"<p>To be complete.</p>"},{"location":"Overview/Architecture/simulator/","title":"Simulator","text":""},{"location":"Overview/Architecture/simulator/#simulation-with-client-state-machine","title":"Simulation with Client-State Machine","text":"<p>We construct a client-state machine to simulate arbitrary system heterogeneiry. In  this state machine, a client's state will change as time goes by or some particular  actions were taken. For example, a client will be available with a probability at each  moment, and clients will be in state 'working' after they were selected if not dropping out. The transfer rules across states are described in the figure below</p> <p> We provide simple APIs for users to customize the system heterogeneity for simulation. Please see  Tutorial 5.1 for details.</p>"},{"location":"Resources/","title":"Index","text":"<p>This is a library for sharing the resources. You can contribute to this library by  uploading your personal algorithms, simulators, and benchmarks. All the resources here will be opened to the public to promote interaction among developers/researchers.</p>"},{"location":"Resources/#usages","title":"Usages","text":"<p>The usages of the three kinds of resources are respectively introduced in Usage Algorithm, Usage Benchmark, Usage Simulator</p>"},{"location":"Resources/#contribute-to-resources","title":"Contribute to Resources","text":"<p>We welcome researchers to contribute to this open-source library to share their own studies by introducing new benchmarks, novel algorithms, and more practical simulators, as we hope this can promoto the development of FL community. To simplify integrating different kinds of resources, we have also provided easy APIs and comprehensive tutorials. We will remark the contributors for the submitted resources in our website.</p>"},{"location":"Resources/#submit-contributions","title":"Submit Contributions","text":"<p>There are two ways to submit your contributions to this platform.</p>"},{"location":"Resources/#1-push-commits-to-the-github-repo","title":"(1) Push commits to the Github repo","text":"<ul> <li>Firstly, clone our github repo</li> </ul> <pre><code>git clone https://github.com/WwZzz/easyFL.git\n</code></pre> <ul> <li>Secondly, git add your resources in proper positions (i.e. benchmark, algorithm, or simulator) in easyFL/resources For example, </li> </ul> <pre><code>\u2514\u2500 resources\n   \u251c\u2500 algorithm  # algorithm files of .py should be placed here\n   \u2502  \u251c\u2500 fedavg.py  \n   \u2502  \u2514\u2500 ...\n   \u251c\u2500 benchmark  # benchmark files of .zip should be placed here\n   \u2502  \u251c\u2500 mnist_classification.zip \n   \u2502  \u2514\u2500 ...\n   \u2514\u2500 simulator  # simulator files of .py should be placed here\n      \u251c\u2500 ...\n      \u2514\u2500 ...\n\n</code></pre> <ul> <li>Thirdly, git commit your changes with necessary information and push it to our repo. The necessary contains</li> </ul>"},{"location":"Resources/#necessary-information-for-submission","title":"Necessary information for submission","text":"<ol> <li>algorithm: publishment, year, scene (e.g. horizontal, vertical or others)</li> <li>benchmark: the name of dataset, the type of data, the type of the ML task</li> <li>simulator: the name of simulator, synthetic-based or real-world-based</li> </ol>"},{"location":"Resources/#2-contact-us-through-email","title":"(2) Contact us through email","text":"<p>Send resources to me through E-mail. The necessacy information should also be contained.</p>"},{"location":"Resources/algorithm/","title":"Usage","text":""},{"location":"Resources/algorithm/#use-algorithm-as-a-module","title":"Use Algorithm as a Module","text":"<p>To use the algorithm, a general way is to create an algorithm file <code>algorithm_name.py</code> in the current working project directory, and then copy the source code into it.</p> <p>For example, we take next three steps to use FedAvg as a plugin. </p> <ol> <li> <p>Create a new file named 'my_fedavg.py'</p> </li> <li> <p>Copy the source code of FedAvg Here into <code>my_fedavg.py</code></p> </li> <li> <p>put the file into the currently working project directory and use it by</p> </li> </ol> <pre><code>import my_fedavg\nimport flgo\n\nflgo.init(.., algorithm=my_fedavg, ..).run()\n</code></pre>"},{"location":"Resources/algorithm/#use-algorithm-as-a-class","title":"Use Algorithm as a Class","text":"<p>Another way to use the algorithm as a plugin is to Create a class instead of a file. </p> <ol> <li>Copy the source code (i.e. the source code is as follows)</li> </ol> <pre><code># Example: source code of FedAvg\nfrom flgo.algorithm.fedbase import BasicServer as Server\nfrom flgo.algorithm..fedbase import BasicClient as Client\n</code></pre> <ol> <li>Create a new class like</li> </ol> <pre><code># Example: source code of FedAvg\n#---------------codes of FedAvg----------------\nimport flgo\nfrom flgo.algorithm.fedbase import BasicServer as Server\nfrom flgo.algorithm..fedbase import BasicClient as Client\n#----------------------end--------------------\n\nclass my_fedavg:\n    # copy the source code here\n    Server = Server\n    Client = Client\n\n# Run the algorithm\nflgo.init(.., algorithm=my_fedavg, ..).run()\n</code></pre>"},{"location":"Resources/algorithm/horizontal/","title":"Classical FL","text":"Name Download Publish Paper Link Remark FedAvg source code AISTAS 2017 Click FedProx source code MLSys 2020 Click Data Heterogeneity / Incomplete Updates FedNova source code NIPS 2020 Click Incomplete Updates Scaffold source code ICML 2020 Click Data Heterogeneity/ Client Dropout FedDyn source code ICLR 2021 Click Data Heterogeneity FedAvgM source code arxiv 2019 Click Data Heterogeneity AFL source code ICML 2019 Click Fairness qFedAvg source code ICLR 2020 Click Fairness FedMGDA+ source code IEEE TNSE 2022 Click Fairness / Robustness FedFV source code IJCAI 2021 Click Fairness FedFa source code Information Sciences 2022 Click Fairness MIFA source code NIPS 2021 Click Client Availability PowerOfChoice source code arxiv 2021 Click Data Heterogeneity / Client Availability FedGS source code AAAI 2023 Click Data Heterogeneity / Client Availability Clustered Sampling source code ICML 2021 Click Data Heterogeneity"},{"location":"Resources/algorithm/horizontal/#personalized-fl","title":"Personalized FL","text":"Name Download Publish Paper Link Remark Ditto source code ICML 2021 Click"},{"location":"Resources/benchmark/","title":"Usage","text":"<p>Each benchmark is compressed as a .zip file. To use benchmarks here, please follow the three steps below</p> <ol> <li> <p>Download the benchmark .zip file</p> </li> <li> <p>Decompress the .zip file into the currently working project directory</p> </li> <li> <p>Use the decompressed directory as a python module, and generate federated task from it</p> </li> </ol>"},{"location":"Resources/benchmark/#example-on-mnist","title":"Example on MNIST","text":"<ol> <li> <p>download mnist_classification.zip from here and decompress it into the currently working project directory.</p> </li> <li> <p>Write codes as follows to use it</p> </li> </ol> <pre><code>import flgo\nimport mnist_classification\n\ntask = './test_mnist_download'\nflgo.gen_task({'benchmark': mnist_classification}, task)\n\nimport flgo.algorithm.fedavg as fedavg\n\nflgo.init(task, fedavg, {'gpu':0}).run()\n\n</code></pre>"},{"location":"Resources/benchmark/Graph/graph_classification/","title":"Overview","text":"Name Dataset Description Scene Download Remark enzymes_graph_classification ENZYMES See here Horizontal FL Click Here - mutag_graph_classification MUTAG See here Horizontal FL Click Here"},{"location":"Resources/benchmark/Graph/graph_classification/#details","title":"Details","text":""},{"location":"Resources/benchmark/Graph/graph_classification/#enzymes_graph_classification","title":"enzymes_graph_classification","text":""},{"location":"Resources/benchmark/Graph/graph_classification/#model","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation GIN - -"},{"location":"Resources/benchmark/Graph/graph_classification/#supported-partitioner","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Graph/graph_classification/#mutag_graph_classification","title":"mutag_graph_classification","text":""},{"location":"Resources/benchmark/Graph/graph_classification/#model_1","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation GCN - -"},{"location":"Resources/benchmark/Graph/graph_classification/#supported-partitioner_1","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Graph/link_prediction/","title":"Overview","text":"Name Dataset Description Scene Download Remark citeseer_link_prediction Citeseer See here Horizontal FL Click Here cora_link_prediction Cora See here Horizontal FL Click Here - pubmed_link_prediction PubMed See here Horizontal FL Click Here"},{"location":"Resources/benchmark/Graph/link_prediction/#details","title":"Details","text":""},{"location":"Resources/benchmark/Graph/link_prediction/#citeseer_link_prediction","title":"citeseer_link_prediction","text":""},{"location":"Resources/benchmark/Graph/link_prediction/#model","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Graph/link_prediction/#supported-partitioner","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Graph/link_prediction/#cora_link_prediction","title":"cora_link_prediction","text":""},{"location":"Resources/benchmark/Graph/link_prediction/#model_1","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Graph/link_prediction/#supported-partitioner_1","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Graph/link_prediction/#pubmed_link_prediction","title":"pubmed_link_prediction","text":""},{"location":"Resources/benchmark/Graph/link_prediction/#model_2","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Graph/link_prediction/#supported-partitioner_2","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Graph/node_classification/","title":"Overview","text":"Name Dataset Description Scene Download Remark citeseer_node_classification Citeseer See here Horizontal FL Click Here cora_node_classification Cora See here Horizontal FL Click Here - pubmed_node_classification PubMed See here Horizontal FL Click Here"},{"location":"Resources/benchmark/Graph/node_classification/#details","title":"Details","text":""},{"location":"Resources/benchmark/Graph/node_classification/#citeseer_node_classification","title":"citeseer_node_classification","text":"<p>Federated CIFAR100 classification is a commonly used benchmark in FL. It assumes different virtual clients having non-overlapping samples from CIFAR100 dataset.</p>"},{"location":"Resources/benchmark/Graph/node_classification/#model","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Graph/node_classification/#supported-partitioner","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Graph/node_classification/#cora_node_classification","title":"cora_node_classification","text":"<p>Federated MNIST classification is a commonly used benchmark in FL. It assumes different virtual clients having non-overlapping samples from MNIST dataset.</p>"},{"location":"Resources/benchmark/Graph/node_classification/#model_1","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Graph/node_classification/#supported-partitioner_1","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Graph/node_classification/#pubmed_node_classification","title":"pubmed_node_classification","text":"<p>Federated CIFAR10 classification is a commonly used benchmark in FL. It assumes different virtual clients having non-overlapping samples from CIFAR10 dataset.</p>"},{"location":"Resources/benchmark/Graph/node_classification/#model_2","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Graph/node_classification/#supported-partitioner_2","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/","title":"Classification","text":""},{"location":"Resources/benchmark/Image/#detection","title":"Detection","text":""},{"location":"Resources/benchmark/Image/#segmentation","title":"Segmentation","text":""},{"location":"Resources/benchmark/Image/classification/","title":"Overview","text":"Name Dataset Description Scene Download Remark mnist_classification MNIST See here Horizontal FL Click Here - cifar10_classification CIFAR10 See here Horizontal FL Click Here cifar100_classification CIFAR100 See here Horizontal FL Click Here svhn_classification SVHN See here Horizontal FL Click Here - fashion_classification FASHION See here Horizontal FL Click Here -"},{"location":"Resources/benchmark/Image/classification/#details","title":"Details","text":""},{"location":"Resources/benchmark/Image/classification/#mnist_classification","title":"mnist_classification","text":"<p>Federated MNIST classification is a commonly used benchmark in FL. It assumes different virtual clients having non-overlapping samples from MNIST dataset.</p>"},{"location":"Resources/benchmark/Image/classification/#model","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Image/classification/#supported-partitioner","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/classification/#cifar10_classification","title":"cifar10_classification","text":"<p>Federated CIFAR10 classification is a commonly used benchmark in FL. It assumes different virtual clients having non-overlapping samples from CIFAR10 dataset.</p>"},{"location":"Resources/benchmark/Image/classification/#model_1","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Image/classification/#supported-partitioner_1","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/classification/#cifar100_classification","title":"cifar100_classification","text":"<p>Federated CIFAR100 classification is a commonly used benchmark in FL. It assumes different virtual clients having non-overlapping samples from CIFAR100 dataset.</p>"},{"location":"Resources/benchmark/Image/classification/#model_2","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Image/classification/#supported-partitioner_2","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/classification/#svhn_classification","title":"svhn_classification","text":"<p>Federated SVHN classification is a commonly used benchmark in FL. It assumes different virtual clients having non-overlapping samples from SVHN dataset.</p>"},{"location":"Resources/benchmark/Image/classification/#model_3","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation cnn - - mlp - -"},{"location":"Resources/benchmark/Image/classification/#supported-partitioner_3","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/classification/#fashion_classification","title":"fashion_classification","text":"<p>Federated Fashion classification is a commonly used benchmark in FL. It assumes different virtual clients having non-overlapping samples from FashionMNIST dataset.</p>"},{"location":"Resources/benchmark/Image/classification/#model_4","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation lr - -"},{"location":"Resources/benchmark/Image/classification/#supported-partitioner_4","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/detection/","title":"Overview","text":"Name Dataset Description Scene Download Remark coco_detection COCO See here Horizontal FL Click Here (under testing) voc_detection VOC See here Horizontal FL Click Here"},{"location":"Resources/benchmark/Image/detection/#details","title":"Details","text":""},{"location":"Resources/benchmark/Image/detection/#coco_detection","title":"coco_detection","text":"<p>coco</p>"},{"location":"Resources/benchmark/Image/detection/#model","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation FasterRCNN - -"},{"location":"Resources/benchmark/Image/detection/#supported-partitioner","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/detection/#voc_detection","title":"voc_detection","text":"<p>coco</p>"},{"location":"Resources/benchmark/Image/detection/#model_1","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation FasterRCNN - -"},{"location":"Resources/benchmark/Image/detection/#supported-partitioner_1","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/segmentation/","title":"Overview","text":"Name Dataset Description Scene Download Remark coco_segmentation COCO See here Horizontal FL Click Here (under testing) oxfordiiitpet_segmentation OxfordIIITPet See here Horizontal FL Click Here sbdataset_segmentation SBDataset See here Horizontal FL Click Here"},{"location":"Resources/benchmark/Image/segmentation/#details","title":"Details","text":""},{"location":"Resources/benchmark/Image/segmentation/#coco_segmentation","title":"coco_segmentation","text":"<p>coco</p>"},{"location":"Resources/benchmark/Image/segmentation/#model","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation FCN_ResNet50 - - UNet - -"},{"location":"Resources/benchmark/Image/segmentation/#supported-partitioner","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/segmentation/#oxfordiiitpet_segmentation","title":"oxfordiiitpet_segmentation","text":"<p>coco</p>"},{"location":"Resources/benchmark/Image/segmentation/#model_1","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation FCN_ResNet50 - -"},{"location":"Resources/benchmark/Image/segmentation/#supported-partitioner_1","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Image/segmentation/#sbdataset_segmentation","title":"sbdataset_segmentation","text":"<p>coco</p>"},{"location":"Resources/benchmark/Image/segmentation/#model_2","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation FCN_ResNet50 - - UNet - -"},{"location":"Resources/benchmark/Image/segmentation/#supported-partitioner_2","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Rec/","title":"coming soon...","text":""},{"location":"Resources/benchmark/Series/","title":"coming soon...","text":""},{"location":"Resources/benchmark/Text/classification/","title":"Overview","text":"Name Dataset Description Scene Download Remark agnews_classification AGNEWS See here Horizontal FL Click Here - imdb_classification IMDB See here Horizontal FL Click Here sst2_classification SST2 See here Horizontal FL Click Here"},{"location":"Resources/benchmark/Text/classification/#details","title":"Details","text":""},{"location":"Resources/benchmark/Text/classification/#agnews_classification","title":"agnews_classification","text":""},{"location":"Resources/benchmark/Text/classification/#model","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation TextClassificationModel - -"},{"location":"Resources/benchmark/Text/classification/#supported-partitioner","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Text/classification/#imdb_classification","title":"imdb_classification","text":"<p>-</p>"},{"location":"Resources/benchmark/Text/classification/#model_1","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation TextClassificationModel - -"},{"location":"Resources/benchmark/Text/classification/#supported-partitioner_1","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Text/classification/#sst2_classification","title":"sst2_classification","text":"<p>-</p>"},{"location":"Resources/benchmark/Text/classification/#model_2","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation TextClassificationModel - -"},{"location":"Resources/benchmark/Text/classification/#supported-partitioner_2","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Text/language_modeling/","title":"Overview","text":"Name Dataset Description Scene Download Remark penntreebank_modeling PennTreebank See here Horizontal FL Click Here - wikitext2_modeling WikiText2 See here Horizontal FL Click Here"},{"location":"Resources/benchmark/Text/language_modeling/#details","title":"Details","text":""},{"location":"Resources/benchmark/Text/language_modeling/#penntreebank_modeling","title":"penntreebank_modeling","text":""},{"location":"Resources/benchmark/Text/language_modeling/#model","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation Transformer - -"},{"location":"Resources/benchmark/Text/language_modeling/#supported-partitioner","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Text/language_modeling/#wikitext2_modeling","title":"wikitext2_modeling","text":"<p>-</p>"},{"location":"Resources/benchmark/Text/language_modeling/#model_1","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation Transformer - -"},{"location":"Resources/benchmark/Text/language_modeling/#supported-partitioner_1","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Resources/benchmark/Text/translation/","title":"Overview","text":"Name Dataset Description Scene Download Remark multi30k_translation Multi30k See here Horizontal FL Click Here -"},{"location":"Resources/benchmark/Text/translation/#details","title":"Details","text":""},{"location":"Resources/benchmark/Text/translation/#multi30k_translation","title":"multi30k_translation","text":""},{"location":"Resources/benchmark/Text/translation/#model","title":"model","text":"Model Name Non-Fed Performance NumPara Implementation Transformer - -"},{"location":"Resources/benchmark/Text/translation/#supported-partitioner","title":"supported partitioner","text":"Name IsDefault Comments IIDPartitioner yes DiversityPartitioner Partitioning according to label diversity DirichletPartitioner Partitioning according to dir. distribution of labels"},{"location":"Tutorials/","title":"Index","text":"<p>In this tutorial, we provide comprehensive examples to show how to use FLGo to help your researches.</p> <p>Following our instructions, you can do things like</p> <ul> <li>easily reproduce and compare the results of different state-of-the-art methods</li> <li>fast verify your ideas by converting them into runnable codes</li> <li>conduct experiments under various data heterogeneiry and system heterogeneity</li> <li>manage your experimental records and visualize them with few codes</li> </ul> <p>All of our examples can be run on jupyter notebook. The source of our notebooks are here.</p>"},{"location":"Tutorials/0_Quick_Start/","title":"Index","text":""},{"location":"Tutorials/0_Quick_Start/#install-flgo","title":"Install FLGo","text":"<p>Install FLGo through pip. </p> <pre><code>pip install flgo\n</code></pre> <p>If the package is not found, please use the command below to update pip</p> <pre><code>pip install --upgrade pip\n</code></pre>"},{"location":"Tutorials/0_Quick_Start/#create-your-first-federated-task","title":"Create Your First Federated Task","text":"<p>Here we take the classical federated benchmark, Federated MNIST [1], as the example, where the MNIST dataset is splitted into 100 parts identically and independently.</p> <pre><code>import flgo\nimport os\n\n# the target path of the task\ntask_path = './my_first_task'\n\n# create task configuration\ntask_config = {'benchmark':{'name': 'flgo.benchmark.mnist_classification'}, 'partitioner':{'name':'IIDPartitioner', 'para':{'num_clients':100}}}\n\n# generate the task if the task doesn't exist\nif not os.path.exist(task_path):\n    flgo.gen_task(task_config, task_path)\n</code></pre> <p>After running the codes above, a federated dataset is successfully created in the <code>task_path</code>. The visualization of the task is stored in <code>task_path/res.png</code> as below </p>"},{"location":"Tutorials/0_Quick_Start/#run-fedavg-to-train-your-model","title":"Run FedAvg to Train Your Model","text":"<p>Now we are going to run the classical federated optimization algorithm, FedAvg [1], on the task created by us to train a model.</p> <pre><code>import flgo.algorithm.fedavg as fedavg\n# create fedavg runner on the task\nrunner = flgo.init(task, fedavg, {'gpu':[0,],'log_file':True, 'num_steps':5})\nrunner.run()\n</code></pre>"},{"location":"Tutorials/0_Quick_Start/#show-training-result","title":"Show Training Result","text":"<p>The training result is saved as a record under the dictionary of the task <code>task_path/record</code>. We use the built-in analyzer to read and show it.</p> <pre><code>import flgo.experiment.analyzer\n# create the analysis plan\nanalysis_plan = {\n    'Selector':{'task': task_path, 'header':['fedavg',], },\n    'Painter':{'Curve':[{'args':{'x':'communication_round', 'y':'val_loss'}}]},\n    'Table':{'min_value':[{'x':'val_loss'}]},\n}\n\nflgo.experiment.analyzer.show(analysis_plan)\n</code></pre> <p></p>"},{"location":"Tutorials/1_Configuration/","title":"Index","text":"<p>This section introduces basic configurations in our framework (i.e. parameters of <code>flgo.init</code>).</p>"},{"location":"Tutorials/1_Configuration/1.1_FL_Descriptor/","title":"1.1 Descriptor of FL","text":"<p>We first introduce how we describe FL in our framework. We use the API <code>flgo.init</code> to create a federated runner to finish a run of FL, which is described as below:</p> <pre><code>def init(task: str, algorithm, option = {}, model=None, Logger: flgo.experiment.logger.BasicLogger = flgo.experiment.logger.simple_logger.SimpleLogger, Simulator: BasicSimulator=flgo.simulator.DefaultSimulator, scene='horizontal'):\n    r\"\"\"\n    Initialize a runner in FLGo, which is to optimize a model on a specific task (i.e. IID-mnist-of-100-clients) by the selected federated algorithm.\n    :param\n        task (str): the dictionary of the federated task\n        algorithm (module || class): the algorithm will be used to optimize the model in federated manner, which must contain pre-defined attributions (e.g. algorithm.Server and algorithm.Client for horizontal federated learning)\n        option (dict || str): the configurations of training, environment, algorithm, logger and simulator\n        model (module || class): the model module that contains two methods: model.init_local_module(object) and model.init_global_module(object)\n        Logger (class): the class of the logger inherited from flgo.experiment.logger.BasicLogger\n        Simulator (class): the class of the simulator inherited from flgo.simulator.BasicSimulator\n        scene (str): 'horizontal' or 'vertical' in current version of FLGo\n    :return\n        runner: the object instance that has the method runner.run()\n    \"\"\"\n    ...\n</code></pre> <p>Each run of a federated training process aims to optimize a given model on a specific task by using an algorithm with some hyper-parameter (i.e. option) under a particular environment (e.g. scene, hardware condition).</p> <p>The term model usually shares the same meaning with centralized ML. The term task describes how the datasets are distributed among clients and some task-specific configuration (e.g. the dataset information, the target). Algorithm is the used optimization strategy and option contains several running-time option like learning rate and the number of training rounds. The hardware condition is simulated by the Simulator. For example, different clients may have different computing power, network latency, communication bandwidth. Finally, the scene refers to the four main paradigm in FL: Horizontal FL, Vertical FL, Decentralized FL and Hierarchical FL, as shown in Figure 1. </p> <ul> <li>(a) Horizontal FL: a server coordinates different clients to collaboratively train the model. Particularly, each clients owns different samples, and each sample is with full features and labels.</li> <li>(b) Vertical FL: an active party (i.e. label owner) coordinates other passive parties to improve the model performance for its local objective. Particularly, different parties own different dimensions of the feature of each sample, and different data owners will shares a set of the same sample IDs. </li> <li>(c) Hierarchical FL: edge servers are responsible for coordinating their themselves clients, and a global server coordinates different edge servers to train the model.</li> <li>(d) Decentralized FL: clients directly communicates with other clients to collaboratively maintain a global model or improve their own local models under specific communication protocols (e.g. line, ring, full). </li> </ul> <p></p> <p>Finally, from the view of doing experiments, we add the term Logger to customizely log the variables of interest (e.g. model checkpoints, training-time performance). Some options of experiments (e.g. device, the number of processes) are also contained in the term option.</p>"},{"location":"Tutorials/1_Configuration/1.2_Option_Configuration/","title":"1.2 Option Configuration","text":"<p>The full options are shown as below</p> Category Name Type Description Default Value Comment Training Option num_rounds int number of communication rounds 20 proportion float proportion of clients sampled per round 0.2 learning_rate_decay float learning rate decay for the training process 0.998 effective if lr_scheduler&gt;-1 lr_scheduler int type of the global learning rate scheduler -1 effective if larger than -1 early_stop int stop training if there is no improvement  for no smaller than the maximum rounds -1 effective if larger than -1 num_epochs int number of epochs of local training 5 num_steps int number of steps of local training,  conflict with num_epochs -1 dominates num_epochs if larger than 0 learning_rate float learning rate of local training 0.1 batch_size int\\float batch size of local training 64 -1 means full batch, float value  means the ratio of the full datasets optimizer str to select the optimizer of local training 'sgd' 'sgd','adam','rmsprop','adagrad' clip_grad float clipping gradients if the max norm of  gradients ||g|| &gt; clip_norm &gt; 0 0.0 effective if larger than 0.0 momentum float momentum of local training 0.0 weight_decay float weight decay of local training 0.0 num_edge_rounds int number of edge rounds in hierFL 5 effective if scene is 'hierarchical' algo_para int\\list algorithm-specific hyper-parameters [] the order should be consistent with  the claim sample str to select sampling form 'uniform' 'uniform', 'md', 'full',  x+'_with_availability' aggregate str to select aggregation form 'other' 'uniform', 'weighted_com',  'weighted_scale', 'other' External Option train_holdout float the rate of holding out the validation  dataset from all the local training datasets 0.1 test_holdout float the rate of holding out the validation  dataset from the testing datasets owned by  the server 0.0 effective if the server has  no validation data local_test bool the local validation data will be equally  split into validation and testing parts  if True False seed int seed for all the random modules 0 gpu int\\list GPU IDs and empty input means using CPU [] server_with_cpu bool the model parameters will be stored in  the memory if True False num_parallels int the number of parallels during communications 1 num_workers int the number of workers of DataLoader 0 pin_memory bool 1)pin_memory of DataLoader, and 2) load  data directly into memory False test_batch_size int the batch_size used in testing phase 512 Simulator Option availability str to select client availability mode 'IDL' 'IDL','YMF','MDF','LDF','YFF', 'HOMO','LN','SLN','YC' connectivity str to select client connectivity mode 'IDL' 'IDL','HOMO' completeness str to select client completeness mode 'IDL' 'IDL','PDU','FSU','ADU','ASU' responsiveness str to select client responsiveness mode 'IDL' 'IDL','LN','UNI' Logger Option log_level str the level of logger 'INFO' 'INFO','DEBUG' log_file bool whether log to file and default  value is False False no_log_console bool whether log to screen and default  value is True True no_overwrite bool whether to overwrite the old result False eval_interval int evaluate every __ rounds; 1"},{"location":"Tutorials/1_Configuration/1.3_Task_Configuration/","title":"1.3 Task Configuration","text":"<p>This section introduces the definition of a federated task and how to run algorihms on different tasks in our frameworks. A federated task is defined as optimizing an objective on a given data distribution.</p> <p>Concretely, the objective is defined by the dataset, the objective function, and the evaluation metrics, and each benchmark module is consist of these three terms. For example, the benchmark <code>flgo.benchmark.mnist_classification</code> requires a model to perform correct classification on hand written digits images, which is evaluated by the accuracy.</p> <p>On the other hand, the data distribution suggests how the data is distributed among participants. For example, each participent may owns data that is identically and independently sampled from a global dataset, which is called the i.i.d. case. In our framework, <code>Paritioner</code> is responsible for creating such data distributions.</p> <p>In our framework, we use the configuration of <code>benchmark</code> and <code>partitioner</code> to generate federated tasks. We now take a example to show how to write configurations to generate different data distributions on the same given benchmark.</p>"},{"location":"Tutorials/1_Configuration/1.3_Task_Configuration/#131-example-mnist-classification-under-different-data-distributions","title":"1.3.1 Example: MNIST classification under different data distributions","text":"<p>Firstly, each config is of the type <code>dict</code> in python. The key 'benchmark' and 'partitioner' repsectively specify the information about the aforementioned benchmark and Partitioner.</p> <pre><code>import flgo\nflgo.set_data_root('cwd') # change the directory storing raw data to the current working directory\nimport flgo.benchmark.mnist_classification as mnist\nimport flgo.algorithm.fedavg as fedavg\nimport flgo.benchmark.partition\nimport os\n# DiversityPartitioner will allocate the data to clients w.r.t. data diversity (e.g. here is label diversity)\n# DirichletPartitioner will allocate the data to clients w.r.t. dirichlet distribution on specific attr. (e.g. here is also label)\nconfig_iid = {'benchmark':mnist,'partitioner':{'name': flgo.benchmark.partition.IIDPartitioner,'para':{'num_clients':100}}}\nconfig_div01 = {'benchmark':mnist,'partitioner':{'name': flgo.benchmark.partition.DiversityPartitioner,'para':{'num_clients':100, 'diversity':0.1}}}\nconfig_div05 = {'benchmark':mnist,'partitioner':{'name': flgo.benchmark.partition.DiversityPartitioner,'para':{'num_clients':100, 'diversity':0.5}}}\nconfig_div09 = {'benchmark':mnist,'partitioner':{'name': flgo.benchmark.partition.DiversityPartitioner,'para':{'num_clients':100, 'diversity':0.9}}}\nconfig_dir01 = {'benchmark':mnist,'partitioner':{'name': flgo.benchmark.partition.DirichletPartitioner,'para':{'num_clients':100, 'alpha':0.1}}}\nconfig_dir10 = {'benchmark':mnist,'partitioner':{'name': flgo.benchmark.partition.DirichletPartitioner,'para':{'num_clients':100, 'alpha':1.0}}}\nconfig_dir50 = {'benchmark':mnist,'partitioner':{'name': flgo.benchmark.partition.DirichletPartitioner,'para':{'num_clients':100, 'alpha':5.0}}}\ntask_dict = {\n    './mnist_iid': config_iid,\n    './mnist_div01': config_div01,\n    './mnist_div05': config_div05,\n    './mnist_div09': config_div09,\n    './mnist_dir01': config_dir01,\n    './mnist_dir10': config_dir10,\n    './mnist_dir50': config_dir50,\n}\n\nfor task in task_dict:\n    if not os.path.exists(task):\n        flgo.gen_task(task_dict[task], task)\n</code></pre> <pre><code>Data root directory has successfully been changed to /home/wz/xw_d2l/Jupyter\n</code></pre> <p>Secondly, use FedAvg to optimize these tasks with the same hyper-parameters. Note that each benchmark will be attached with a default model (e.g. a predefined CNN for mnist_classification), and initialization without specifying model will automatically load the default model.</p> <pre><code>import flgo.algorithm.fedavg as fedavg\noption = {'gpu':0, 'num_rounds':20, 'num_epochs':1, 'learning_rate':0.1, 'batch_size':64, 'eval_interval':2}\nrunners = [flgo.init(task, fedavg, option) for task in task_dict]\nfor runner in runners:\n    runner.run()\n</code></pre> <p>Thirdly, use <code>flgo.experiment.analyzer</code> to read the records and visuazlie the results.</p> <pre><code>import flgo.experiment.analyzer as al\nimport matplotlib.pyplot as plt\ndiv_recs = al.Selector({'task':[t for t in task_dict if 'iid' in t or 'div' in t], 'header':['fedavg']})\n\nplt.subplot(221)\nfor task in div_recs.tasks:\n    rec_list = div_recs.records[task]\n    for rec in rec_list:\n        plt.plot(rec.data['communication_round'], rec.data['test_accuracy'], label=task.split('/')[-1])\nplt.title('testing accuracy - diversity')\nplt.ylabel('test_accuracy')\nplt.xlabel('communication round')\nplt.legend()\n\nplt.subplot(222)\nfor task in div_recs.tasks:\n    rec_list = div_recs.records[task]\n    for rec in rec_list:\n        plt.plot(rec.data['communication_round'], rec.data['test_loss'], label=task.split('/')[-1])\nplt.title('testing loss - diversity')\nplt.ylabel('test_loss')\nplt.xlabel('communication round')\nplt.legend()\n\nplt.subplot(223)\ndir_recs = al.Selector({'task':[task for task in task_dict if 'iid' in task or 'dir' in task], 'header':['fedavg']})\nfor task in dir_recs.tasks:\n    rec_list = dir_recs.records[task]\n    for rec in rec_list:\n        plt.plot(rec.data['communication_round'], rec.data['test_accuracy'], label=task.split('/')[-1])\nplt.title('testing accuracy - Dirichlet')\nplt.ylabel('test_accuracy')\nplt.xlabel('communication round')\nplt.legend()\n\nplt.subplot(224)\ndir_recs = al.Selector({'task':[task for task in task_dict if 'iid' in task or 'dir' in task], 'header':['fedavg']})\nfor task in dir_recs.tasks:\n    rec_list = dir_recs.records[task]\n    for rec in rec_list:\n        plt.plot(rec.data['communication_round'], rec.data['test_loss'], label=task.split('/')[-1])\nplt.title('testing loss - Dirichlet')\nplt.ylabel('test_loss')\nplt.xlabel('communication round')\nplt.legend()\nplt.show()\n</code></pre> <p></p>"},{"location":"Tutorials/1_Configuration/1.4_Algorithm_Configuration/","title":"1.4 Algorithm Configuration","text":"<p>This section introduces how to change algorithms on the same federated task. In our framework, the algorithm object describes the behaviors of participants in the FL system. For example, the server of horizontal FL usually samples clients, broadcasts the global model to them, and aggregates the collected models from them, where there exist a plenty of different strategies to improve each step. Now we compare a heterogeneous-aware FL algorithm, FedProx, against FedAvg under the same task to show the usage of algorihm.</p>"},{"location":"Tutorials/1_Configuration/1.4_Algorithm_Configuration/#141-example-comparison-on-fedavg-and-fedprox","title":"1.4.1 Example: Comparison on FedAvg and FedProx","text":""},{"location":"Tutorials/1_Configuration/1.4_Algorithm_Configuration/#dataset-synthetic05-05","title":"Dataset: Synthetic(0.5, 0.5)","text":"<p>We conduct the experiments that shares the same setting in []. Firstly, we generate synthetic datasets with 30 clients. This dataset is generated by</p> \\[y_{k,i}=\\text{argmax}\\{softmax({W_k} x_{k,i}+ b_k)\\}\\] <p>where \\((x_{k,i}, y_{k,i})\\) is the \\(i\\)th example in the local data \\(D_k\\) of client \\(c_k\\). For each client \\(c_k\\), its local optimal model parameter \\((W_k, b_k)\\) is generated by \\(\\mu_k\\sim \\mathcal{N}(0,\\alpha)\\in \\mathbb{R},W_{k}[i,j]\\sim\\mathcal{N}(\\mu_k,1),  W_k\\in \\mathbb{R}^{10\\times 60}, b_{k}[i]\\sim\\mathcal{N}(\\mu_k,1), b_k\\in\\mathbb{R}^{10}\\), and its local data distribution is generated by \\(B_k\\sim\\mathcal{N}(0,\\beta),  v_k[i]\\sim\\mathcal{N}(B_k,1),  v_k\\in \\mathbb{R}^{60}, x_{k,i}\\sim\\mathcal{N}(v_k, \\Sigma)\\in \\mathbb{R}^{60},\\Sigma=\\text{diag}(\\{i^{-1.2}\\}_{i=1}^{60})\\). Here we conduct experiments on Synthetic(0.5,0.5) where \\(\\alpha=\\beta=0.5\\).</p> <pre><code>import os\nimport flgo\ntask = './test_synthetic'\nconfig = {'benchmark':{'name':'flgo.benchmark.synthetic_regression', 'para':{'alpha':0.5, 'beta':0.5, 'num_clients':30}}}\nif not os.path.exists(task): flgo.gen_task(config, task_path = task)\n</code></pre> <pre><code>Task ./test_synthetic has been successfully generated.\n</code></pre>"},{"location":"Tutorials/1_Configuration/1.4_Algorithm_Configuration/#running-two-algorithms","title":"Running two algorithms","text":"<pre><code>import flgo.algorithm.fedprox as fedprox\nimport flgo.algorithm.fedavg as fedavg\n\noption = {'num_rounds':200, 'num_epochs':5, 'batch_size':10, 'learning_rate':0.1, 'gpu':0}\nfedavg_runner = flgo.init(task, fedavg, option=option)\nfedprox_runner = flgo.init(task, fedprox, option=option)\nfedavg_runner.run()\nfedprox_runner.run()\n</code></pre>"},{"location":"Tutorials/1_Configuration/1.4_Algorithm_Configuration/#plot-the-results","title":"Plot the results","text":"<pre><code>import flgo.experiment.analyzer\nanalysis_plan = {\n    'Selector':{\n        'task': task,\n        'header':['fedavg', 'fedprox']\n    },\n    'Painter':{\n        'Curve':[\n            {'args':{'x': 'communication_round', 'y':'val_loss'}, 'fig_option':{'title':'valid loss on Synthetic'}},\n            {'args':{'x': 'communication_round', 'y':'val_accuracy'},  'fig_option':{'title':'valid accuracy on Synthetic'}},\n        ]\n    }\n}\nflgo.experiment.analyzer.show(analysis_plan)\n</code></pre> <p>The result tells that FedProx has superior performance than FedAvg under this setting of data heterogeneity.</p>"},{"location":"Tutorials/1_Configuration/1.5_Model_Configuration/","title":"1.5 Model Configuration","text":"<p>This section introduces how to change the model. Far now, we only train the default model for each benchmark (e.g. CNN for mnist_classification). For most of the benchmarks, we have provided several popular models that can be easily used by replacing the parameter model in <code>flgo.init</code>. We show the usage by the following example.</p>"},{"location":"Tutorials/1_Configuration/1.5_Model_Configuration/#151-example-select-model-for-mnist","title":"1.5.1 Example: Select model for MNIST","text":"<pre><code>import flgo.benchmark.mnist_classification.model.cnn as cnn\nimport flgo.benchmark.mnist_classification.model.mlp as mlp\nimport flgo.algorithm.fedavg as fedavg\ntask = './mnist_iid' # this task has been generated in Example 2.1\ncnn_runner = flgo.init(task, fedavg, option={'num_rounds':5, 'num_epochs':1, 'gpu':0}, model=cnn)\nmlp_runner = flgo.init(task, fedavg, option={'num_rounds':5, 'num_epochs':1, 'gpu':0}, model=mlp)\ncnn_runner.run()\nmlp_runner.run()\n\n# result analysis\nimport flgo.experiment.analyzer\nanalysis_plan = {\n    'Selector':{\n        'task': task,\n        'header':['fedavg'],\n        'filter':{'M':['cnn', 'mlp'], 'R':5}, # filter the result by the communication round R=5\n        'legend_with':['M']\n    },\n    'Painter':{\n        'Curve':[\n            {'args':{'x': 'communication_round', 'y':'val_loss'}, 'fig_option':{'title':'valid loss on MNIST'}},\n            {'args':{'x': 'communication_round', 'y':'val_accuracy'},  'fig_option':{'title':'valid accuracy on MNIST'}},\n        ]\n    }\n}\nflgo.experiment.analyzer.show(analysis_plan)\n</code></pre>"},{"location":"Tutorials/1_Configuration/1.5_Model_Configuration/#152-customization-on-models","title":"1.5.2 Customization on models","text":"<p>We now discuss the impletementation of models in our framework. Different from the centralized ML setting where there is only a model that transform the input to the output, the model in our framework should describe what and how the models are kept by different participants. This is because different parties in FL may have models with different architectures and paramters (e.g. personzalized FL, vertical FL, model-agnostic FL). In addition, the model sometimes could also be a significant part of particular methods. Therefore, we define the model as a class as follows:</p> <pre><code>class GeneralModel:\n    @classmethod\n    def init_local_module(cls, object):\n        \"\"\"init local models (e.g. personal models that cannot be shared) for the object according to its information\"\"\"\n        pass\n\n    @classmethod\n    def init_global_module(cls, object):\n        \"\"\"init global models (e.g. sharable models) for the object according to its information\"\"\"\n        pass\n</code></pre> <p>Now we construct a model and test it as the example.</p> <pre><code>from torch import nn\nimport torch.nn.functional as F\nfrom flgo.utils.fmodule import FModule\n\nclass CNNModel(FModule): # inherit from flgo.utils.fmodule.FModule instead of torch.nn.Module\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n        self.fc1 = nn.Linear(3136, 512)\n        self.fc2 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = x.view((x.shape[0],28,28))\n        x = x.unsqueeze(1)\n        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\ndef init_local_module(object):\n    pass\n\ndef init_global_module(object):\n    # In classical horizontal FL, only the server needs to trace the latest global and store it\n    if 'Server' in object.get_classname():\n        object.model = CNNModel().to(object.device)\n\nclass MyCNN:\n    init_local_module = init_local_module\n    init_global_module = init_global_module\n\nmycnn_runner = flgo.init(task, fedavg, option={'num_rounds':5, 'num_epochs':1, 'gpu':0}, model=MyCNN)\nmycnn_runner.run()\n\nanalysis_plan = {\n    'Selector':{\n        'task': task,\n        'header':['fedavg'],\n        'filter':{'M':['MyCNN', 'cnn'], 'R':5},\n        'legend_with':['M']\n    },\n    'Painter':{\n        'Curve':[\n            {'args':{'x': 'communication_round', 'y':'val_loss'}, 'fig_option':{'title':'valid loss on MNIST'}},\n            {'args':{'x': 'communication_round', 'y':'val_accuracy'},  'fig_option':{'title':'valid accuracy on MNIST'}},\n        ]\n    }\n}\nflgo.experiment.analyzer.show(analysis_plan)\n</code></pre> <p></p> <p></p> <p>The two CNNs of the same architecture has a similar performance in this example.</p>"},{"location":"Tutorials/1_Configuration/1.5_Model_Configuration/#153-what-is-fmodule","title":"1.5.3 What is FModule?","text":"<p><code>FModule</code> is a class that decorates the class <code>torch.nn.Module</code> to enable direct operations on models like add, sub. <code>FModule</code> directly inherits from <code>torch.nn.Module</code> and won't have any impact on its original characteristics. The only difference lies in that <code>FModule</code> allows the model-level operations by using operators +,-,* to obtain a new model. We show the usage of <code>FModule</code> by the following example.</p>"},{"location":"Tutorials/1_Configuration/1.5_Model_Configuration/#1531-example-model-level-operators","title":"1.5.3.1 Example: Model-level operators","text":"<pre><code>from torch import nn\nimport torch.nn.functional as F\nfrom flgo.utils.fmodule import FModule\n\nclass Model(FModule):\n    def __init__(self):\n        super().__init__()\n        self.fc = nn.Linear(3, 3, bias=False)\n\n    def forward(self, x):\n        return x\n\nA = Model()\nB = Model()\n</code></pre> <pre><code>print(\"model A: \", A.fc.weight)\nprint(\"model B: \", B.fc.weight)\n\n# add\nC = A+B # C is a new instance of class Model and changes on C won't have any impact on A or B\nprint(\"C=A+B: {}\", C.fc.weight)\nprint(\"Type of C:\",C)\n</code></pre> <pre><code>model A:  Parameter containing:\ntensor([[ 0.2429, -0.4990,  0.1843],\n        [-0.2553,  0.1664,  0.3536],\n        [ 0.5772,  0.0578, -0.0694]], requires_grad=True)\nmodel B:  Parameter containing:\ntensor([[-0.4220, -0.3707, -0.2508],\n        [-0.4888, -0.1267,  0.1310],\n        [ 0.5714, -0.2370,  0.3410]], requires_grad=True)\nC=A+B: {} Parameter containing:\ntensor([[-0.1790, -0.8697, -0.0665],\n        [-0.7441,  0.0397,  0.4845],\n        [ 1.1486, -0.1792,  0.2716]], requires_grad=True)\nType of C: Model(\n  (fc): Linear(in_features=3, out_features=3, bias=False)\n)\n</code></pre> <pre><code># sub\nprint('A-B: \\n', (A-B).fc.weight)\nprint('+++++++++++++++++++++++++++++++++++')\n# scale\nprint('2*A: \\n', (2*A).fc.weight)\nprint('+++++++++++++++++++++++++++++++++++')\n# div\nprint('A/2: \\n', (A/2).fc.weight)\nprint('+++++++++++++++++++++++++++++++++++')\n# norm\nprint('||A||_2: \\n', (A**2))\nprint('+++++++++++++++++++++++++++++++++++')\n# neg\nprint('-A: \\n', (-A).fc.weight)\nprint('+++++++++++++++++++++++++++++++++++')\n# zeros-copy\nprint('A.zeros_like(): \\n',A.zeros_like().fc.weight)\nprint('+++++++++++++++++++++++++++++++++++')\n# dot\nprint(\"dot(A,B):\\n\", A.dot(B))\nprint('+++++++++++++++++++++++++++++++++++')\n# cos-similarity\nprint(\"cos_sim(A,B):\\n\", A.cos_sim(B))\nprint('+++++++++++++++++++++++++++++++++++')\n# size\nprint(\"size(A):\\n\", A.count_parameters())\nprint('+++++++++++++++++++++++++++++++++++')\n</code></pre> <pre><code>A-B:\n Parameter containing:\ntensor([[ 0.6649, -0.1282,  0.4352],\n        [ 0.2336,  0.2932,  0.2226],\n        [ 0.0057,  0.2948, -0.4103]], requires_grad=True)\n+++++++++++++++++++++++++++++++++++\n2*A:\n Parameter containing:\ntensor([[ 0.4859, -0.9979,  0.3687],\n        [-0.5105,  0.3329,  0.7072],\n        [ 1.1543,  0.1156, -0.1388]], requires_grad=True)\n+++++++++++++++++++++++++++++++++++\nA/2:\n Parameter containing:\ntensor([[ 0.1215, -0.2495,  0.0922],\n        [-0.1276,  0.0832,  0.1768],\n        [ 0.2886,  0.0289, -0.0347]], requires_grad=True)\n+++++++++++++++++++++++++++++++++++\n||A||_2:\n tensor(0.9493)\n+++++++++++++++++++++++++++++++++++\n-A:\n Parameter containing:\ntensor([[-0.2429,  0.4990, -0.1843],\n        [ 0.2553, -0.1664, -0.3536],\n        [-0.5772, -0.0578,  0.0694]], requires_grad=True)\n+++++++++++++++++++++++++++++++++++\nA.zeros_like():\n Parameter containing:\ntensor([[0., -0., 0.],\n        [-0., 0., 0.],\n        [0., 0., -0.]], requires_grad=True)\n+++++++++++++++++++++++++++++++++++\ndot(A,B):\n tensor(0.4787)\n+++++++++++++++++++++++++++++++++++\ncos_sim(A,B):\n tensor(0.4703)\n+++++++++++++++++++++++++++++++++++\nsize(A):\n 9\n+++++++++++++++++++++++++++++++++++\n</code></pre> <p>Besides the model-level operators, we also implement some common functions on model-level.</p> <pre><code>import flgo.utils.fmodule as ff\n# exp(A)\nprint('exp(A):\\n', ff.exp(A).fc.weight)\nprint('+++++++++++++++++++++++++++++++++++')\n# log(A)\nprint('log(A):\\n', ff.log(A).fc.weight)\nprint('+++++++++++++++++++++++++++++++++++')\n# model to 1-D vector\na = ff._model_to_tensor(A)\nprint('a = Vec(A):\\n', a)\n# 1-D tensor to model\nprint('A from a: \\n',ff._model_from_tensor(a, A.__class__).fc.weight)\nprint('+++++++++++++++++++++++++++++++++++')\n# model averaging\nprint('AVERAGE([A,B]):\\n', ff._model_average([A,B]).fc.weight)\n# model sum\nprint('SUM([A,B]):\\n', ff._model_sum([A,B]).fc.weight)\n</code></pre> <pre><code>exp(A):\n Parameter containing:\ntensor([[1.2750, 0.6072, 1.2024],\n        [0.7747, 1.1811, 1.4242],\n        [1.7810, 1.0595, 0.9330]], requires_grad=True)\n+++++++++++++++++++++++++++++++++++\nlog(A):\n Parameter containing:\ntensor([[-1.4149,     nan, -1.6910],\n        [    nan, -1.7931, -1.0396],\n        [-0.5496, -2.8510,     nan]], requires_grad=True)\n+++++++++++++++++++++++++++++++++++\na = Vec(A):\n tensor([ 0.2429, -0.4990,  0.1843, -0.2553,  0.1664,  0.3536,  0.5772,  0.0578,\n        -0.0694])\nA from a:\n Parameter containing:\ntensor([[ 0.2429, -0.4990,  0.1843],\n        [-0.2553,  0.1664,  0.3536],\n        [ 0.5772,  0.0578, -0.0694]], requires_grad=True)\n+++++++++++++++++++++++++++++++++++\nAVERAGE([A,B]):\n Parameter containing:\ntensor([[-0.0895, -0.4348, -0.0333],\n        [-0.3721,  0.0199,  0.2423],\n        [ 0.5743, -0.0896,  0.1358]], requires_grad=True)\nSUM([A,B]):\n Parameter containing:\ntensor([[-0.1790, -0.8697, -0.0665],\n        [-0.7441,  0.0397,  0.4845],\n        [ 1.1486, -0.1792,  0.2716]], requires_grad=True)\n</code></pre>"},{"location":"Tutorials/1_Configuration/1.5_Model_Configuration/#154-fast-customization","title":"1.5.4 Fast Customization","text":"<p>We further provide fast API to convert a model into federated one by writing only one line code</p> <pre><code>from torch import nn\nimport torch.nn.functional as F\n\nclass NewModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n        self.fc1 = nn.Linear(3136, 512)\n        self.fc2 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = x.view((x.shape[0],28,28))\n        x = x.unsqueeze(1)\n        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nmodel = flgo.convert_model(NewModel) # the default value of model_name is 'anonymous'\nmycnn_runner2 = flgo.init(task, fedavg, option={'num_rounds':5, 'num_epochs':1, 'gpu':0}, model=model)\nmycnn_runner2.run()\n\nanalysis_plan = {\n    'Selector':{\n        'task': task,\n        'header':['fedavg'],\n        'filter':{'M':['MyCNN', 'anonymous'], 'R':5},\n        'legend_with':['M']\n    },\n    'Painter':{\n        'Curve':[\n            {'args':{'x': 'communication_round', 'y':'val_loss'}, 'fig_option':{'title':'valid loss on MNIST'}},\n            {'args':{'x': 'communication_round', 'y':'val_accuracy'},  'fig_option':{'title':'valid accuracy on MNIST'}},\n        ]\n    }\n}\nflgo.experiment.analyzer.show(analysis_plan)\n</code></pre> <p></p> <p></p>"},{"location":"Tutorials/1_Configuration/1.6_Logger_Configuration/","title":"1.6 Logger Customization","text":"<p>This section introduces the usage of <code>Logger</code>. <code>Logger</code> is responsble for recording running-time variables of interest that can be very dependent on personal usage. We offer three key APIs to support different experiment purposes.</p> <pre><code>import flgo.experiment.logger as fel\nclass Logger(fel.BasicLogger):\n    def initialize(self):\n        # initialize necessary variables BEFORE training starts\n        pass\n\n    def log_once(self):\n        # will be carried out every K communication rounds DURING training process\n        pass\n\n    def organize_output(self):\n        # organize output AFTER training ends\n        pass\n</code></pre> <p>The three APIs are respectively responsible for customized operations before\\during\\after training. All the variables of interest should be recorded into <code>self.output</code> that will be finally saved as .json file. <code>self.output</code> is of type collections.defaultdict, and the default value of each key is an empty list. Now we take the following example to show how to customize <code>Logger</code>.</p>"},{"location":"Tutorials/1_Configuration/1.6_Logger_Configuration/#161-example-customization-on-logger","title":"1.6.1 Example: Customization on Logger","text":"<pre><code>import collections\nimport numpy as np\nimport copy\n\nclass MyLogger(fel.BasicLogger):\n    def initialize(self, *args, **kwargs):\n        self.optimal_model = copy.deepcopy(self.coordinator.model)\n        self.optimal_test_loss = 9999\n\n    def log_once(self):\n        # evaluation on testing data\n        test_metric = self.coordinator.test()\n        for met_name, met_val in test_metric.items():\n            self.output['test_' + met_name].append(met_val)\n        # check whether the current model is the optimal\n        if test_metric['loss']&lt;self.optimal_test_loss:\n            self.optimal_test_loss = test_metric['loss']\n            self.optimal_model.load_state_dict(self.coordinator.model.state_dict())\n        self.show_current_output()\n\n    def organize_output(self):\n        super().organize_output()\n        # evaluation on clients' validation datasets\n        all_metrics = collections.defaultdict(list)\n        for c in self.participants:\n            client_metrics = c.test(self.optimal_model, 'val')\n            for met_name, met_val in client_metrics.items():\n                all_metrics[met_name].append(met_val)\n        for met_name, metval in all_metrics.items():\n            self.output[met_name] = metval\n        # compute the optimal\\worst 30% metrics on validation datasets\n        met_name = 'loss'\n        all_valid_losses = sorted(all_metrics[met_name])\n        k1 = int(0.3*len(self.participants))\n        k2 = int(0.7*len(self.participants))\n        self.output['worst_30_valid_loss'] = 1.0*sum(all_valid_losses[k2:])/k1\n        self.output['best_30_valid_loss']  = 1.0*sum(all_valid_losses[:k1])/k1\n\nimport flgo.algorithm.fedavg as fedavg\nimport flgo.algorithm.qfedavg as qfedavg\nimport os\ntask = './test_synthetic' # this task has been generated in Sec.1.3.1\n\n# running optimization\nop = {'num_rounds':30, 'num_epochs':1, 'batch_size':8, 'learning_rate':0.1, 'proportion':1.0 ,'gpu':0, 'algo_para':0.1}\nfedavg_runner = flgo.init(task, fedavg, option = op, Logger=MyLogger)\nqffl_runner = flgo.init(task, qfedavg, option=op, Logger=MyLogger)\nfedavg_runner.run()\nqffl_runner.run()\n\n# Result analysis\nimport flgo.experiment.analyzer as al\nrecords = al.Selector({'task':task, 'header':['fedavg', 'qfedavg_q0.1',], 'filter':{'R':30, 'E':1, 'B':8, 'LR':0.1,'P':1.0}}).records[task]\nfor rec in records:\n    wl = rec.data['worst_30_valid_loss']\n    bl = rec.data['best_30_valid_loss']\n    print('{}:(Worst is {}, Best is {})'.format(rec.data['option']['algorithm'], wl, bl))\n</code></pre> <pre><code>fedavg:(Worst is 1.5370861026975844, Best is 0.15324175854523978)\nqfedavg:(Worst is 1.5319330559836493, Best is 0.4078656468126509)\n</code></pre> <p>The results tells that qfedavg has a superior performance for the worst 30% clients but sacrifies model performance for the optimal 30% clients.</p>"},{"location":"Tutorials/2_Algorithm_Customization/","title":"Index","text":"<p>In this section, we first discuss the general paradigm of horizontal FL and the corresponding implementation.  Then, we take several existing federated algorithms as examples to demonstrate customization processes during different stages of training. We finally list other FL paradigm across scenes (e.g. vertical FL, decentralized FL, and hierarchical FL).</p>"},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/","title":"2.1 General Paradigm","text":"<p>In this section, we first introduce the general paradigm of horizontal FL and then discuss the corresponding implementation in FLGo.</p>"},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/#211-classical-paradigm","title":"2.1.1 Classical Paradigm","text":"<p>In a classical horizontal FL scene, there is a center server that coordinates clients to collaboratively train a global model iteratively. In each iteration, the server first samples a subset from all the clients. Then, the server broadcasts the global model the selected clients. After receiving the global model, the clients locally train it with local data. Finally, the clients send back the updated models to the server and the server aggregates the models into the new global model. The whole process is as shown in the figure above. Existing methods usually improve one or more of the five steps to realize various purposes like fairness and robustness.</p> <p></p> <p>The cooresponding implementation of the FL process is shown in Figure 2. We use <code>iterate</code> function to model the behaviors of the server and <code>reply</code> function to model the behaviors of clients when being selected.</p>"},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/#212-details-of-steps","title":"2.1.2 Details of Steps","text":""},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/#servers-behavior-serveriterate","title":"Server's Behavior: Server.iterate","text":"<p>The training process starts with <code>run</code> method of the server, which starts iterations (i.e. communication rounds) by using a loop. In each iteration of the loop, the server will call <code>iterate</code> to carry out each step. A standard implementation of <code>iterate</code> (i.e. <code>flgo.algorithm.fedbase.iterate</code>) is as below:</p> <pre><code>    def iterate(self):\n        \"\"\"\n        The standard iteration of each federated communication round that contains three\n        necessary procedure in FL: client selection, communication and model aggregation.\n\n        Returns:\n            False if the global model is not updated in this iteration\n        \"\"\"\n        # sample clients: Uniform sampling as default\n        self.selected_clients = self.sample()\n        # training\n        models = self.communicate(self.selected_clients)['model']\n        # aggregate: pk = ni/sum(ni) as default\n        self.model = self.aggregate(models)\n        return len(models) &gt; 0\n</code></pre>"},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/#1-serversample","title":"\u2460 Server.sample","text":"<p>During each iteration, the server first sample clients by calling <code>self.sample()</code>, which returns a list of clients' IDs. We implement three  sampling strategies in our preset sampling method as below. <code>full</code> sampling means selecting all the clients. <code>uniform</code> sampling means selecting clients uniformly without replacement. <code>md</code> sampling means selecting clients with replacement by probabilities w.r.t. the ratio of data sizes. Improvement on sampling strategies can be adapted here by overwriting <code>sample</code>.</p> <pre><code>    def sample(self):\n        r\"\"\"\n        Sample the clients. There are three types of sampling manners:\n        full sample, uniform sample without replacement, and MDSample\n        with replacement. Particularly, if 'available' is in self.sample_option,\n        the server will only sample from currently available clients.\n\n        Returns:\n            a list of the ids of the selected clients\n\n        Example:\n        ```python\n            &gt;&gt;&gt; selected_clients=self.sample()\n            &gt;&gt;&gt; selected_clients\n            &gt;&gt;&gt; # The selected_clients is a list of clients' ids\n        ```\n        \"\"\"\n        all_clients = self.available_clients if 'available' in self.sample_option else [cid for cid in\n                                                                                        range(self.num_clients)]\n        # full sampling with unlimited communication resources of the server\n        if 'full' in self.sample_option:\n            return all_clients\n        # sample clients\n        elif 'uniform' in self.sample_option:\n            # original sample proposed by fedavg\n            selected_clients = list(\n                np.random.choice(all_clients, min(self.clients_per_round, len(all_clients)), replace=False)) if len(\n                all_clients) &gt; 0 else []\n        elif 'md' in self.sample_option:\n            # the default setting that is introduced by FedProx, where the clients are sampled with the probability in proportion to their local_movielens_recommendation data sizes\n            local_data_vols = [self.clients[cid].datavol for cid in all_clients]\n            total_data_vol = sum(local_data_vols)\n            p = np.array(local_data_vols) / total_data_vol\n            selected_clients = list(np.random.choice(all_clients, self.clients_per_round, replace=True, p=p)) if len(\n                all_clients) &gt; 0 else []\n        return selected_clients\n</code></pre>"},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/#2-communication-broadcast-serverpack-clientunpack","title":"\u2461 Communication- Broadcast: Server.pack &amp; Client.unpack","text":"<p>The communication process is realized by the method <code>communicate(client_ids: list[int], mtype: str, asynchronous: bool)</code>, which contains a full ask&amp;reply process between the server and the clients. The second step only refers to the broadcast-communication, which only describes what the server transmitting to the clients. Therefore, we use two method, <code>Server.pack(client_id)</code> and <code>Client.unpack()</code> to model the broadcast-communication process</p> <pre><code>class Server:\n    def pack(self, client_id, mtype=0, *args, **kwargs):\n        \"\"\"\n        Pack the necessary information for the client's local training.\n        Any operations of compression or encryption should be done here.\n        :param\n            client_id: the id of the client to communicate with\n        :return\n            a dict that only contains the global model as default.\n        \"\"\"\n        return {\n            \"model\" : copy.deepcopy(self.model),\n        }\n\nclass Client:\n        def unpack(self, received_pkg):\n        \"\"\"\n        Unpack the package received from the server\n        :param\n            received_pkg: a dict contains the global model as default\n        :return:\n            the unpacked information that can be rewritten\n        \"\"\"\n        # unpack the received package\n        return received_pkg['model']\n</code></pre> <p>The transmitted package should be a <code>dict</code> in python. The server will send a copy of the global model, and the client will unpack the package to obtain the global model as default. Any changes on the content of the down-streaming packages should be implemented here.</p>"},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/#clients-behavior-clientreply","title":"Clients' Behavior: Client.reply","text":"<p>After clients receiving the global models, the method <code>Client.reply</code> will automatically be triggered to model the clients' behaviors. The implementation of <code>reply</code> is as follows:</p> <pre><code>    def reply(self, svr_pkg):\n        r\"\"\"\n        Reply a package to the server. The whole local_movielens_recommendation procedure should be defined here.\n        The standard form consists of three procedure: unpacking the\n        server_package to obtain the global model, training the global model,\n        and finally packing the updated model into client_package.\n\n        Args:\n            svr_pkg (dict): the package received from the server\n\n        Returns:\n            client_pkg (dict): the package to be send to the server\n        \"\"\"\n        model = self.unpack(svr_pkg)\n        self.train(model)\n        cpkg = self.pack(model)\n        return cpkg\n</code></pre>"},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/#3-local-training-clienttrain","title":"\u2462 Local Training: Client.train","text":"<p>The local training is made by the method <code>Client.train</code>, which receives a global model as the input and trains it with local data. Any modification on local training procedures should be implemented here. The default implementation is as follow:</p> <pre><code>    def train(self, model):\n        r\"\"\"\n        Standard local_movielens_recommendation training procedure. Train the transmitted model with\n        local_movielens_recommendation training dataset.\n\n        Args:\n            model (FModule): the global model\n        \"\"\"\n        model.train()\n        optimizer = self.calculator.get_optimizer(model, lr=self.learning_rate, weight_decay=self.weight_decay,\n                                                  momentum=self.momentum)\n        for iter in range(self.num_steps):\n            # get a batch of data\n            batch_data = self.get_batch_data()\n            model.zero_grad()\n            # calculate the loss of the model on batched dataset through task-specified calculator\n            loss = self.calculator.compute_loss(model, batch_data)['loss']\n            loss.backward()\n            if self.clip_grad&gt;0:torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=self.clip_grad)\n            optimizer.step()\n        return\n</code></pre> <p>Particularly, we let the task-spefific calculation be transparent to the optimization algorithms. Therefore, one algorithm (e.g. FedAvg) can be adapted to different types of tasks without any changes. <code>calculator</code> is responsible for all the task-specific calculations.</p>"},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/#4-communication-upload-clientpack-serverunpack","title":"\u2463 Communication - Upload: Client.pack &amp; Server.unpack","text":"<p>The communication of uploading models from clients is modeled by <code>Client.pack(*args, **kwargs)</code> and <code>Server.unpack(packages_list)</code>, which is similar to the step \u2461. Different from \u2461, the server as the receiver needs to simultaneously handle a list of packages from different clients. We let <code>Server.unpack</code> return the values in the uploaded packages as a dict that shares the same keys with each client's pakcage. Modification on the content of upload-communication should be implemented in <code>Client.pack</code> that returns a dict as a package each time.</p> <pre><code>class Server:\n    def unpack(self, packages_received_from_clients):\n        \"\"\"\n        Unpack the information from the received packages. Return models and losses as default.\n        :param\n            packages_received_from_clients:\n        :return:\n            res: collections.defaultdict that contains several lists of the clients' reply\n        \"\"\"\n        if len(packages_received_from_clients)==0: return collections.defaultdict(list)\n        res = {pname:[] for pname in packages_received_from_clients[0]}\n        for cpkg in packages_received_from_clients:\n            for pname, pval in cpkg.items():\n                res[pname].append(pval)\n        return res\n\nclass Client:\n    def pack(self, model, *args, **kwargs):\n        \"\"\"\n        Packing the package to be send to the server. The operations of compression\n        of encryption of the package should be done here.\n        :param\n            model: the locally trained model\n        :return\n            package: a dict that contains the necessary information for the server\n        \"\"\"\n        return {\n            \"model\" : model,\n            }\n</code></pre>"},{"location":"Tutorials/2_Algorithm_Customization/2.1_General_Paradigm/#5-model-aggregation-serveraggregate","title":"\u2464 Model Aggregation: Server.aggregate()","text":"<p>The server finally aggregates the received models into a new global model by the method <code>Server.aggregate(models: list)</code>. There are four preset aggregation modes in our implementation. And using the normalized ratios of local data sizes (i.e. FedAvg) is set the default aggregatino option.</p> <pre><code>def aggregate(self, models: list, *args, **kwargs):\n        \"\"\"\n        Aggregate the locally improved models.\n        :param\n            models: a list of local models\n        :return\n            the averaged result\n        pk = nk/n where n=self.data_vol\n        K = |S_t|\n        N = |S|\n        -------------------------------------------------------------------------------------------------------------------------\n         weighted_scale                 |uniform (default)          |weighted_com (original fedavg)   |other\n        ==========================================================================================================================\n        N/K * \u03a3pk * model_k             |1/K * \u03a3model_k             |(1-\u03a3pk) * w_old + \u03a3pk * model_k  |\u03a3(pk/\u03a3pk) * model_k\n        \"\"\"\n        if len(models) == 0: return self.model\n        local_data_vols = [c.datavol for c in self.clients]\n        total_data_vol = sum(local_data_vols)\n        if self.aggregation_option == 'weighted_scale':\n            p = [1.0 * local_data_vols[cid] /total_data_vol for cid in self.received_clients]\n            K = len(models)\n            N = self.num_clients\n            return fmodule._model_sum([model_k * pk for model_k, pk in zip(models, p)]) * N / K\n        elif self.aggregation_option == 'uniform':\n            return fmodule._model_average(models)\n        elif self.aggregation_option == 'weighted_com':\n            p = [1.0 * local_data_vols[cid] / total_data_vol for cid in self.received_clients]\n            w = fmodule._model_sum([model_k * pk for model_k, pk in zip(models, p)])\n            return (1.0-sum(p))*self.model + w\n        else:\n            p = [1.0 * local_data_vols[cid] / total_data_vol for cid in self.received_clients]\n            sump = sum(p)\n            p = [pk/sump for pk in p]\n            return fmodule._model_sum([model_k * pk for model_k, pk in zip(models, p)])\n</code></pre> <p>We will show how to modify each steps to realize different algorithms by the following sections.</p>"},{"location":"Tutorials/2_Algorithm_Customization/2.2_Local_Training_FedProx/","title":"2.2.1 Example: FedProx","text":"<p>In this section, we discuss how to realize ideas with modification on the local training phase in FL. We take the method FedProx as the example. FedProx is proposed by Li Tian in 2018 and accepted by MLSys2020. It addresses the data and system heterogeneity problem in FL, which has made two major improvements over FedAvg:</p> <ul> <li>Sample &amp; Aggregation:  sample clients by the probability w.r.t. the ratios of local data sizes (i.e. MD sampling) and uniformly aggregates the received models (i.e. uniform aggregation)</li> <li>Local Training: optimize a proxy \\(L'\\) of original local objective by additionally adding proximal term on it</li> </ul> \\[L'=L+\\frac{\\mu}{2}\\|w_{k,i}^t-w_{global}^t\\|_2^2\\] <p>where \\(k\\) denoting the \\(k\\)th client, \\(t\\) denoting the communication round, and \\(i\\) denoting the \\(i\\)th local training iterations. \\(\\mu\\) is the hyper-parameter of FedProx.</p>"},{"location":"Tutorials/2_Algorithm_Customization/2.2_Local_Training_FedProx/#222-implementation","title":"2.2.2 Implementation","text":"<p>Since we have already implemented MD sampling and uniform aggregation as preset options, we only consider how to customize the local training process here. </p>"},{"location":"Tutorials/2_Algorithm_Customization/2.2_Local_Training_FedProx/#2221-add-hyper-parameter","title":"2.2.2.1 Add hyper-parameter","text":"<p>We provide the API <code>Server.init_algo_para(algo_para: dict)</code> for adding additional algorightm-specific hyper-parameters. The definition of the method is as follows:</p> <pre><code> def init_algo_para(self, algo_para: dict):\n        \"\"\"\n        Initialize the algorithm-dependent hyper-parameters for the server and all the clients.\n\n        Args:\n            algo_paras (dict): the dict that defines the hyper-parameters (i.e. name, value and type) for the algorithm.\n\n        Example:\n        ```python\n            &gt;&gt;&gt; # s is an instance of Server and s.clients are instances of Client\n            &gt;&gt;&gt; s.u # will raise error\n            &gt;&gt;&gt; [c.u for c in s.clients] # will raise errors too\n            &gt;&gt;&gt; s.init_algo_para({'u': 0.1})\n            &gt;&gt;&gt; s.u # will be 0.1\n            &gt;&gt;&gt; [c.u for c in s.clients] # will be [0.1, 0.1,..., 0.1]\n        ```\n        Note:\n            Once `option['algo_para']` is not `None`, the value of the pre-defined hyperparameters will be replaced by the list of values in `option['algo_para']`,\n            which requires the length of `option['algo_para']` is equal to the length of `algo_paras`\n        \"\"\"\n        ...\n</code></pre> <p>The key-value pairs in <code>algo_para</code> corresponds to the names of the hyper-parameters and their defalut values. After calling this method, instances of both Server and Client can directly access the hyper-parameter by self.parameter_name. An example is as shown in the definition. This method is usually called in the <code>initialize</code> method of the server. Now we add the hyper-parameter \\(\\mu\\) for FedProx and set its default value as 0.1. </p> <pre><code>import flgo.algorithm.fedbase as fedbase\nimport flgo.utils.fmodule as fmodule\n\nclass Server(fedbase.BasicServer):\n    def initialize(self, *args, **kwargs):\n        # set hyper-parameters\n        self.init_algo_para({'mu':0.01})\n        # set sampling option and aggregation option\n        self.sample_option = 'md'\n        self.aggregation_option = 'uniform'\n</code></pre>"},{"location":"Tutorials/2_Algorithm_Customization/2.2_Local_Training_FedProx/#2222-modify-local-objective","title":"2.2.2.2 Modify local objective","text":"<pre><code>import copy\nimport torch\n\nclass Client(fedbase.BasicClient):\n    @fmodule.with_multi_gpus\n    def train(self, model):\n        # record the global parameters\n        src_model = copy.deepcopy(model)\n        # freeze gradients on the copy of global parameters\n        src_model.freeze_grad()\n        # start local training\n        model.train()\n        optimizer = self.calculator.get_optimizer(model, lr=self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)\n        for iter in range(self.num_steps):\n            # get a batch of data\n            batch_data = self.get_batch_data()\n            model.zero_grad()\n            # compute the loss of the model on batched dataset through task-specified calculator\n            loss = self.calculator.compute_loss(model, batch_data)['loss']\n            # compute the proximal term\n            loss_proximal = 0\n            for pm, ps in zip(model.parameters(), src_model.parameters()):\n                loss_proximal += torch.sum(torch.pow(pm - ps, 2))\n            loss = loss + 0.5 * self.mu * loss_proximal\n            loss.backward()\n            optimizer.step()\n        return\n</code></pre>"},{"location":"Tutorials/2_Algorithm_Customization/2.2_Local_Training_FedProx/#2223-create-new-class-fedprox","title":"2.2.2.3 Create new class fedprox","text":"<p>Implement FedProx as a new class like</p> <pre><code>class my_fedprox:\n    Server = Server\n    Client = Client\n</code></pre>"},{"location":"Tutorials/2_Algorithm_Customization/2.2_Local_Training_FedProx/#223-experiment","title":"2.2.3 Experiment","text":"<p>Now let's take a look on the experimental results on the <code>fedprox</code>. We consider the experimental settings in Sec.1.3.1. </p> <pre><code>import flgo\nimport os\n# generate federated task\ntask = './test_synthetic'\nconfig = {'benchmark':{'name':'flgo.benchmark.synthetic_regression', 'para':{'alpha':0.5, 'beta':0.5, 'num_clients':30}}}\nif not os.path.exists(task): flgo.gen_task(config, task_path = task)\n\n# running methods\nimport flgo.algorithm.fedavg as fedavg\noption = {'num_rounds':200, 'num_epochs':5, 'batch_size':10, 'learning_rate':0.1, 'gpu':0}\nfedavg_runner = flgo.init(task, fedavg, option=option)\nmy_fedprox_runner = flgo.init(task, my_fedprox, option=option)\nfedavg_runner.run()\nmy_fedprox_runner.run()\n\n# show results\nimport flgo.experiment.analyzer\nanalysis_plan = {\n    'Selector':{\n        'task': task,\n        'header':['fedavg', 'my_fedprox_mu0.01'],\n        'filter':{'R':200}\n    },\n    'Painter':{\n        'Curve':[\n            {'args':{'x': 'communication_round', 'y':'test_loss'}, 'fig_option':{'title':'test loss on Synthetic'}},\n            {'args':{'x': 'communication_round', 'y':'test_accuracy'},  'fig_option':{'title':'test accuracy on Synthetic'}},\n        ]\n    }\n}\nflgo.experiment.analyzer.show(analysis_plan)\n</code></pre> <p></p> <p></p>"},{"location":"Tutorials/2_Algorithm_Customization/2.2_Local_Training_FedProx/#2231-change-values-of-hyper-parameters","title":"2.2.3.1 Change values of hyper-parameters","text":"<p>We change the value of hyper-parameter \\(\\mu\\) by specifying the keyword <code>algo_para</code> in option</p> <pre><code>option01 = {'algo_para':0.1, 'num_rounds':200, 'num_epochs':5, 'batch_size':10, 'learning_rate':0.1, 'gpu':0}\noption10 = {'algo_para':10.0, 'num_rounds':200, 'num_epochs':5, 'batch_size':10, 'learning_rate':0.1, 'gpu':0}\nmy_fedprox001_runner = flgo.init(task, my_fedprox, option=option01)\nmy_fedprox001_runner.run()\nmy_fedprox100_runner = flgo.init(task, my_fedprox, option=option10)\nmy_fedprox100_runner.run()\nanalysis_plan = {\n    'Selector':{\n        'task': task,\n        'header':['fedavg', 'my_fedprox'],\n        'filter':{'R':200}\n    },\n    'Painter':{\n        'Curve':[\n            {'args':{'x': 'communication_round', 'y':'test_loss'}, 'fig_option':{'title':'test loss on Synthetic'}},\n            {'args':{'x': 'communication_round', 'y':'test_accuracy'},  'fig_option':{'title':'test accuracy on Synthetic'}},\n        ]\n    }\n}\nflgo.experiment.analyzer.show(analysis_plan)\n</code></pre> <p></p> <p></p> <p>The results suggest that increasing \\(\\mu\\) significantly improves the performance of FedProx on this task.</p>"}]}